{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "py19ioTOBqjB"
   },
   "outputs": [],
   "source": [
    "# importing python utility libraries\n",
    "import os, sys, random, io, urllib\n",
    "from datetime import datetime\n",
    "\n",
    "# importing pytorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# importing data science libraries\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import numpy as np\n",
    "\n",
    "# importing python plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-M08ndlBqjR"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdSSdufWBqjW"
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "rd.seed(seed_value) # set random seed\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU\n",
    "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
    "    torch.cuda.manual_seed(seed_value) # set pytorch seed GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiqmYgDiBqjZ"
   },
   "outputs": [],
   "source": [
    "# load the synthetic ERP dataset\n",
    "ori_dataset = pd.read_csv('./data/fraud_dataset_v2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NR6P7wLNBqjb"
   },
   "source": [
    "We augmented the dataset and renamed the attributes to appear more similar to a real-world dataset that one usually observes in SAP-ERP systems as part of SAP's Finance and Cost controlling (FICO) module. \n",
    "\n",
    "The dataset contains a subset of in total 7 categorical and 2 numerical attributes available in the FICO BKPF (containing the posted journal entry headers) and BSEG (containing the posted journal entry segments) tables. Please, find below a list of the individual attributes as well as a brief description of their respective semantics:\n",
    "\n",
    ">- `BELNR`: the accounting document number,\n",
    ">- `BUKRS`: the company code,\n",
    ">- `BSCHL`: the posting key,\n",
    ">- `HKONT`: the posted general ledger account,\n",
    ">- `PRCTR`: the posted profit center,\n",
    ">- `WAERS`: the currency key,\n",
    ">- `KTOSL`: the general ledger account key,\n",
    ">- `DMBTR`: the amount in local currency,\n",
    ">- `WRBTR`: the amount in document currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBFw8UPaBqje"
   },
   "outputs": [],
   "source": [
    "# remove the \"ground-truth\" label information for the following steps of the lab\n",
    "label = ori_dataset.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "mj6CSUQWBqjf",
    "outputId": "e50430a9-eb70-466d-9b36-61bb0c1a8fa7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare to plot posting key and general ledger account side by side\n",
    "fig, ax = plt.subplots(1,2, sharey='row')\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "plt.rc('font', size=18) \n",
    "# plot the distribution of the posting key attribute\n",
    "g = sns.countplot(x=ori_dataset.loc[label=='regular', 'BSCHL'], ax=ax[0], alpha=0.7)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=0, size=12)\n",
    "g.set_title('Posting Key', size=16)\n",
    "\n",
    "# plot the distribution of the general ledger account attribute\n",
    "g = sns.countplot(x=ori_dataset.loc[label=='regular', 'HKONT'], ax=ax[1], alpha=0.7)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=0, size=12)\n",
    "g.set_title('General Ledger Account', size=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXXEzhToBqjj"
   },
   "outputs": [],
   "source": [
    "# select categorical attributes to be \"one-hot\" encoded\n",
    "categorical_attr_names = ['KTOSL', 'PRCTR', 'BSCHL', 'HKONT', 'BUKRS', 'WAERS']\n",
    "\n",
    "# encode categorical attributes into a binary one-hot encoded representation \n",
    "ori_dataset_categ_transformed = pd.get_dummies(ori_dataset[categorical_attr_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "zLEXn828Bqjl",
    "outputId": "45613858-1b72-4919-da19-e8869378e93f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# init the plots\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "# plot distribution of the local amount attribute\n",
    "g = sns.distplot(ori_dataset['DMBTR'].tolist(), ax=ax[0])\n",
    "g.set_title('Distribution of DMBTR amount values')\n",
    "\n",
    "# set axis-labels \n",
    "ax[0].set_xlabel('DMBTR')\n",
    "ax[0].set_ylabel('density')\n",
    "\n",
    "# plot distribution of the document amount attribute\n",
    "g = sns.distplot(ori_dataset['WRBTR'].tolist(), ax=ax[1])\n",
    "g.set_title('Distribution of WRBTR amount values')\n",
    "\n",
    "# set axis-labels\n",
    "ax[1].set_xlabel('WRBTR')\n",
    "ax[1].set_ylabel('density');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeUp3ppdBqjn"
   },
   "outputs": [],
   "source": [
    "# select \"DMBTR\" vs. \"WRBTR\" attribute\n",
    "numeric_attr_names = ['DMBTR', 'WRBTR']\n",
    "\n",
    "# add a small epsilon to eliminate zero values from data for log scaling\n",
    "numeric_attr = ori_dataset[numeric_attr_names] + 1e-4\n",
    "numeric_attr = numeric_attr.apply(np.log)\n",
    "\n",
    "# normalize all numeric attributes to the range [0,1]\n",
    "ori_dataset_numeric_attr = (numeric_attr - numeric_attr.min()) / (numeric_attr.max() - numeric_attr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "id": "TJZQ5oCUBqjp",
    "outputId": "821dee60-3602-4820-8b51-04408fda0b13"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# init the plots\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "# plot distribution of the local amount attribute\n",
    "g = sns.distplot(ori_dataset_numeric_attr['DMBTR'].tolist(), ax=ax[0])\n",
    "g.set_title('Distribution of scaled DMBTR amount values')\n",
    "\n",
    "# set axis-labels \n",
    "ax[0].set_xlabel('DMBTR')\n",
    "ax[0].set_ylabel('density')\n",
    "\n",
    "# plot distribution of the local amount attribute\n",
    "g = sns.distplot(ori_dataset_numeric_attr['WRBTR'].tolist(), ax=ax[1])\n",
    "g.set_title('Distribution of scaled WRBTR amount values')\n",
    "\n",
    "# set axis-labels\n",
    "ax[1].set_xlabel('WRBTR')\n",
    "ax[1].set_ylabel('density');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "PrKpgWQ6Bqjp",
    "outputId": "4e08325e-16ba-4909-b944-88970c5eb869"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# append 'label' attribute \n",
    "numeric_attr_vis = ori_dataset_numeric_attr.copy()\n",
    "numeric_attr_vis['label'] = label\n",
    "plt.rc('font', size=12) \n",
    "# plot the log-scaled and min-max normalized numeric attributes\n",
    "g = sns.pairplot(data=numeric_attr_vis, vars=numeric_attr_names, hue='label', palette={'regular': 'C0', 'local': 'C3', 'global': 'C1'}, markers=['o', 'x', 'x'])\n",
    "\n",
    "# set figure title\n",
    "g.fig.suptitle('Distribution of DMBTR vs. WRBTR amount values', y=1.02)\n",
    "\n",
    "# set figure size\n",
    "g.fig.set_size_inches(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWOWVEs0Bqjr"
   },
   "outputs": [],
   "source": [
    "# merge categorical and numeric subsets\n",
    "ori_subset_transformed = pd.concat([ori_dataset_categ_transformed, ori_dataset_numeric_attr], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "t-VRrGxqBqjr",
    "outputId": "e6246df6-eb12-4aed-cb0b-9b4a81e1661d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533009, 618)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect final dimensions of pre-processed transactional data\n",
    "ori_subset_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W_I8259HBqjt"
   },
   "outputs": [],
   "source": [
    "# define encoder class\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    # define class constructor\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "\n",
    "        # call super class constructor\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        # specify first layer - in 618, out 256\n",
    "        self.map_L1 = nn.Linear(input_size, hidden_size[0], bias=True) # init linearity\n",
    "        nn.init.xavier_uniform_(self.map_L1.weight) # init weights according to [9]\n",
    "        nn.init.constant_(self.map_L1.bias, 0.0) # constant initialization of the bias\n",
    "        self.map_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
    "\n",
    "        # specify second layer - in 256, out 64\n",
    "        self.map_L2 = nn.Linear(hidden_size[0], hidden_size[1], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L2.weight)\n",
    "        nn.init.constant_(self.map_L2.bias, 0.0)\n",
    "        self.map_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify third layer - in 64, out 16\n",
    "        self.map_L3 = nn.Linear(hidden_size[1], hidden_size[2], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L3.weight)\n",
    "        nn.init.constant_(self.map_L3.bias, 0.0)\n",
    "        self.map_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify fourth layer - in 16, out 4\n",
    "        self.map_L4 = nn.Linear(hidden_size[2], hidden_size[3], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L4.weight)\n",
    "        nn.init.constant_(self.map_L4.bias, 0.0)\n",
    "        self.map_R4 = torch.nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "        \n",
    "        '''\n",
    "        # specify fifth layer - in 4, out 2\n",
    "        self.map_L5 = nn.Linear(hidden_size[3], hidden_size[4], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L5.weight)\n",
    "        nn.init.constant_(self.map_L5.bias, 0.0)\n",
    "        self.map_R5 = torch.nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "        '''\n",
    "        \n",
    "        # define forward layer for mu and var\n",
    "        self.map_mu = nn.Linear(hidden_size[3], hidden_size[4], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_mu.weight)\n",
    "        nn.init.constant_(self.map_mu.weight, 0.0)\n",
    "        self.map_var = nn.Linear(hidden_size[3], hidden_size[4], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_var.weight)\n",
    "        nn.init.constant_(self.map_var.weight, 0.0)        \n",
    "        \n",
    "        \n",
    "    # define reparameterize method\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        x = self.map_R1(self.map_L1(x))\n",
    "        x = self.map_R2(self.map_L2(x))\n",
    "        x = self.map_R3(self.map_L3(x))\n",
    "        x = self.map_R4(self.map_L4(x))\n",
    "        #x = self.map_R5(self.map_L5(x))\n",
    "        \n",
    "        # Calculate mu, logvar and pass to reparameterize method\n",
    "        mu, logvar = self.map_mu(x), self.map_var(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        \n",
    "        # return result\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QyTFqrqSBqju"
   },
   "outputs": [],
   "source": [
    "# init training network classes / architectures\n",
    "encoder_train = Encoder(input_size=ori_subset_transformed.shape[1], hidden_size=[256, 64, 16, 4, 2])\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
    "    encoder_train = encoder_train.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "mWXGUOsWBqjv",
    "outputId": "fb3d3686-7a9a-41d0-813a-723d0cd28bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG 20200407-20:34:10] variational-encoder-generator architecture:\n",
      "\n",
      "Encoder(\n",
      "  (map_L1): Linear(in_features=618, out_features=256, bias=True)\n",
      "  (map_R1): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_L2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (map_R2): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_L3): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (map_R3): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_L4): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (map_R4): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_mu): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (map_var): Linear(in_features=4, out_features=2, bias=True)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the initialized architectures\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] variational-encoder-generator architecture:\\n\\n{}\\n'.format(now, encoder_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FjnC8eTXBqjw"
   },
   "outputs": [],
   "source": [
    "# define decoder class\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    # define class constructor\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "\n",
    "        # call super class constructor\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # specify first layer - in 2, out 4\n",
    "        self.map_L1 = nn.Linear(hidden_size[0], hidden_size[1], bias=True) # init linearity\n",
    "        nn.init.xavier_uniform_(self.map_L1.weight) # init weights according to [9]\n",
    "        nn.init.constant_(self.map_L1.bias, 0.0) # constant initialization of the bias\n",
    "        self.map_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
    "\n",
    "        # specify second layer - in 4, out 16\n",
    "        self.map_L2 = nn.Linear(hidden_size[1], hidden_size[2], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L2.weight)\n",
    "        nn.init.constant_(self.map_L2.bias, 0.0)\n",
    "        self.map_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify third layer - in 16, out 64\n",
    "        self.map_L3 = nn.Linear(hidden_size[2], hidden_size[3], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L3.weight)\n",
    "        nn.init.constant_(self.map_L3.bias, 0.0)\n",
    "        self.map_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify fourth layer - in 64, out 256\n",
    "        self.map_L4 = nn.Linear(hidden_size[3], hidden_size[4], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L4.weight)\n",
    "        nn.init.constant_(self.map_L4.bias, 0.0)\n",
    "        self.map_R4 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "        \n",
    "        # specify fifth layer - in 256, out 618\n",
    "        self.map_L5 = nn.Linear(hidden_size[4], output_size, bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L5.weight)\n",
    "        nn.init.constant_(self.map_L5.bias, 0.0)\n",
    "        self.map_S5 = torch.nn.Sigmoid()\n",
    "\n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        x = self.map_R1(self.map_L1(x))\n",
    "        x = self.map_R2(self.map_L2(x))\n",
    "        x = self.map_R3(self.map_L3(x))\n",
    "        x = self.map_R4(self.map_L4(x))\n",
    "        x = self.map_S5(self.map_L5(x))\n",
    "\n",
    "        # return result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "dfME7m7fBqjw",
    "outputId": "df5e22ac-7eeb-43a2-e489-552db3f82d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG 20200407-20:34:15] decoder architecture:\n",
      "\n",
      "Decoder(\n",
      "  (map_L1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (map_R1): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_L2): Linear(in_features=4, out_features=16, bias=True)\n",
      "  (map_R2): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_L3): Linear(in_features=16, out_features=64, bias=True)\n",
      "  (map_R3): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_L4): Linear(in_features=64, out_features=256, bias=True)\n",
      "  (map_R4): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_L5): Linear(in_features=256, out_features=618, bias=True)\n",
      "  (map_S5): Sigmoid()\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# init training network classes / architectures\n",
    "decoder_train = Decoder(output_size=ori_subset_transformed.shape[1], hidden_size=[2, 4, 16, 64, 256])\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "    decoder_train = decoder_train.cuda()\n",
    "    \n",
    "# print the initialized architectures\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] decoder architecture:\\n\\n{}\\n'.format(now, decoder_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xLZxg0hBqjx"
   },
   "outputs": [],
   "source": [
    "# define discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    # define class constructor\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "\n",
    "        # call super class constructor\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # specify first layer - in 2, out 256\n",
    "        self.map_L1 = nn.Linear(input_size, hidden_size[0], bias=True) # init linearity\n",
    "        nn.init.xavier_uniform_(self.map_L1.weight) # init weights according to [9]\n",
    "        nn.init.constant_(self.map_L1.bias, 0.0) # constant initialization of the bias\n",
    "        self.map_R1 = nn.LeakyReLU(negative_slope=0.4, inplace=True) # add non-linearity according to [10]\n",
    "\n",
    "        # specify second layer - in 256, out 16\n",
    "        self.map_L2 = nn.Linear(hidden_size[0], hidden_size[1], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L2.weight)\n",
    "        nn.init.constant_(self.map_L2.bias, 0.0)\n",
    "        self.map_R2 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # specify third layer - in 16, out 4\n",
    "        self.map_L3 = nn.Linear(hidden_size[1], hidden_size[2], bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L3.weight)\n",
    "        nn.init.constant_(self.map_L3.bias, 0.0)\n",
    "        self.map_R3 = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "        \n",
    "        # specify fourth layer - in 4, out 2\n",
    "        self.map_L4 = nn.Linear(hidden_size[2], output_size, bias=True)\n",
    "        nn.init.xavier_uniform_(self.map_L4.weight)\n",
    "        nn.init.constant_(self.map_L4.bias, 0.0)\n",
    "        self.map_S4 = torch.nn.Sigmoid()\n",
    "\n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        x = self.map_R1(self.map_L1(x))\n",
    "        x = self.map_R2(self.map_L2(x))\n",
    "        x = self.map_R3(self.map_L3(x))\n",
    "        x = self.map_S4(self.map_L4(x))\n",
    "\n",
    "        # return result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "C2ktcdrpBqjz",
    "outputId": "e63c0a1c-7793-4e2c-cbcc-e6a88f34fd73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG 20200407-20:34:25] discriminator architecture:\n",
      "\n",
      "Discriminator(\n",
      "  (map_L1): Linear(in_features=2, out_features=256, bias=True)\n",
      "  (map_R1): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_L2): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (map_R2): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_L3): Linear(in_features=16, out_features=4, bias=True)\n",
      "  (map_R3): LeakyReLU(negative_slope=0.4, inplace=True)\n",
      "  (map_L4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (map_S4): Sigmoid()\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# init training network classes / architectures\n",
    "discriminator_train = Discriminator(input_size=2, hidden_size=[256, 16, 4, 2], output_size=1)\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "    discriminator_train = discriminator_train.cuda()\n",
    "    \n",
    "# print the initialized architectures\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "print('[LOG {}] discriminator architecture:\\n\\n{}\\n'.format(now, discriminator_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLZkO1D1Bqj0"
   },
   "outputs": [],
   "source": [
    "# define the optimization criterion / loss function\n",
    "reconstruction_criterion_categorical = nn.BCELoss(reduction='mean')\n",
    "reconstruction_criterion_numeric = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
    "    reconstruction_criterion_categorical = reconstruction_criterion_categorical.cuda()\n",
    "    reconstruction_criterion_numeric = reconstruction_criterion_numeric.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJ7dte_JBqj1"
   },
   "outputs": [],
   "source": [
    "# define encoder and decoded learning rate\n",
    "learning_rate_enc = 1e-3\n",
    "learning_rate_dec = 1e-3\n",
    "\n",
    "# define encoder and decoder optimization strategy\n",
    "encoder_optimizer = optim.Adam(encoder_train.parameters(), lr=learning_rate_enc)\n",
    "decoder_optimizer = optim.Adam(decoder_train.parameters(), lr=learning_rate_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbijUiDQBqj1"
   },
   "outputs": [],
   "source": [
    "# init the discriminator losses\n",
    "discriminator_criterion = nn.BCELoss()\n",
    "\n",
    "# push to cuda if cudnn is available\n",
    "if (torch.backends.cudnn.version() != None and USE_CUDA == True):\n",
    "    discriminator_criterion = discriminator_criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6a1kOzS2Bqj3"
   },
   "outputs": [],
   "source": [
    "# define generator and discriminator learning rate\n",
    "learning_rate_dis_z = 1e-5\n",
    "\n",
    "# define generator and discriminator optimization strategy\n",
    "discriminator_optimizer = optim.Adam(discriminator_train.parameters(), lr=learning_rate_dis_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMVs7_FvBqj5"
   },
   "outputs": [],
   "source": [
    "# define the number of gaussians\n",
    "tau = 5 \n",
    "\n",
    "# define radius of each gaussian\n",
    "radius = 0.8\n",
    "\n",
    "# define the sigma of each gaussian\n",
    "sigma = 0.01\n",
    "\n",
    "# define the dimensionality of each gaussian\n",
    "dim = 2\n",
    "\n",
    "# determine x and y coordinates of the target mixture of gaussians\n",
    "x_centroid = (radius * np.sin(np.linspace(0, 2 * np.pi, tau, endpoint=False)) + 1) / 2\n",
    "y_centroid = (radius * np.cos(np.linspace(0, 2 * np.pi, tau, endpoint=False)) + 1) / 2\n",
    "\n",
    "# determine each gaussians mean (centroid) and standard deviation\n",
    "mu_gauss = np.vstack([x_centroid, y_centroid]).T\n",
    "\n",
    "# determine the number of samples to be created per gaussian\n",
    "samples_per_gaussian = 100000\n",
    "\n",
    "# iterate over the number of distinct gaussians\n",
    "for i, mu in enumerate(mu_gauss):\n",
    "\n",
    "    # case: first gaussian\n",
    "    if i == 0:\n",
    "\n",
    "        # randomly sample from gaussion distribution \n",
    "        z_continous_samples_all = np.random.normal(mu, sigma, size=(samples_per_gaussian, dim))\n",
    "\n",
    "    # case: non-first gaussian\n",
    "    else:\n",
    "\n",
    "        # randomly sample from gaussian distribution\n",
    "        z_continous_samples = np.random.normal(mu, sigma, size=(samples_per_gaussian, dim))\n",
    "\n",
    "        # collect and stack new samples\n",
    "        z_continous_samples_all = np.vstack([z_continous_samples_all, z_continous_samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fT0CgtXSBqj7"
   },
   "source": [
    "Let's visually inspect the generated prior distribution $p(z)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "FozilkQNBqj8",
    "outputId": "f44fbd9b-d585-408a-943a-33745de73bd6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# init the plot\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plot reconstruction error scatter plot\n",
    "ax.scatter(z_continous_samples_all[:, 0], z_continous_samples_all[:, 1], c='C0', marker=\"o\", edgecolors='w', linewidth=0.5) \n",
    "ax.set_xlabel('$z_1$')\n",
    "ax.set_ylabel('$z_2$')\n",
    "\n",
    "# add plot title\n",
    "ax.set_title('Prior Latent Space Distribution $p(z)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VXom63JBqj9"
   },
   "outputs": [],
   "source": [
    "# specify training parameters\n",
    "num_epochs = 5000\n",
    "mini_batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNeHachtBqj9"
   },
   "outputs": [],
   "source": [
    "# convert pre-processed data to pytorch tensor\n",
    "torch_dataset = torch.from_numpy(ori_subset_transformed.values).float()\n",
    "\n",
    "# convert to pytorch tensor - none cuda enabled\n",
    "dataloader = DataLoader(torch_dataset, batch_size=mini_batch_size, shuffle=True, num_workers=0)\n",
    "# note: we set num_workers to zero to retrieve deterministic results\n",
    "\n",
    "# determine if CUDA is available at compute node\n",
    "if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "    dataloader = DataLoader(torch_dataset.cuda(), batch_size=mini_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SaInCIZCBqj-"
   },
   "outputs": [],
   "source": [
    "# init collection of training losses\n",
    "epoch_reconstruction_losses = []\n",
    "#epoch_vae_losses = []\n",
    "epoch_discriminator_losses = []\n",
    "epoch_generator_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ZqwzewXBqj_"
   },
   "outputs": [],
   "source": [
    "mini_batch_verbose_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "nq5Ba-2bBqkA",
    "outputId": "9dd806be-7b21-4edb-c884-04537c6fd593",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:03:11] epoch: 0001/5000, reconstruction loss: 0.7813\n",
      "[LOG TRAIN 20200404-19:03:11] epoch: 0001/5000, discriminator loss: 1.3943\n",
      "[LOG TRAIN 20200404-19:03:11] epoch: 0001/5000, generator loss: 0.7082\n",
      "[LOG TRAIN 20200404-19:03:15] epoch: 0002/5000, reconstruction loss: 0.7373\n",
      "[LOG TRAIN 20200404-19:03:15] epoch: 0002/5000, discriminator loss: 1.3937\n",
      "[LOG TRAIN 20200404-19:03:15] epoch: 0002/5000, generator loss: 0.7083\n",
      "[LOG TRAIN 20200404-19:03:19] epoch: 0003/5000, reconstruction loss: 0.6562\n",
      "[LOG TRAIN 20200404-19:03:19] epoch: 0003/5000, discriminator loss: 1.3956\n",
      "[LOG TRAIN 20200404-19:03:19] epoch: 0003/5000, generator loss: 0.7059\n",
      "[LOG TRAIN 20200404-19:03:23] epoch: 0004/5000, reconstruction loss: 0.4748\n",
      "[LOG TRAIN 20200404-19:03:23] epoch: 0004/5000, discriminator loss: 1.3982\n",
      "[LOG TRAIN 20200404-19:03:23] epoch: 0004/5000, generator loss: 0.7031\n",
      "[LOG TRAIN 20200404-19:03:27] epoch: 0005/5000, reconstruction loss: 0.2489\n",
      "[LOG TRAIN 20200404-19:03:27] epoch: 0005/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-19:03:27] epoch: 0005/5000, generator loss: 0.7189\n",
      "[LOG TRAIN 20200404-19:03:30] epoch: 0006/5000, reconstruction loss: 0.1751\n",
      "[LOG TRAIN 20200404-19:03:30] epoch: 0006/5000, discriminator loss: 1.3627\n",
      "[LOG TRAIN 20200404-19:03:30] epoch: 0006/5000, generator loss: 0.7415\n",
      "[LOG TRAIN 20200404-19:03:34] epoch: 0007/5000, reconstruction loss: 0.1314\n",
      "[LOG TRAIN 20200404-19:03:34] epoch: 0007/5000, discriminator loss: 1.3662\n",
      "[LOG TRAIN 20200404-19:03:34] epoch: 0007/5000, generator loss: 0.7363\n",
      "[LOG TRAIN 20200404-19:03:38] epoch: 0008/5000, reconstruction loss: 0.1221\n",
      "[LOG TRAIN 20200404-19:03:38] epoch: 0008/5000, discriminator loss: 1.3696\n",
      "[LOG TRAIN 20200404-19:03:38] epoch: 0008/5000, generator loss: 0.7314\n",
      "[LOG TRAIN 20200404-19:03:42] epoch: 0009/5000, reconstruction loss: 0.1200\n",
      "[LOG TRAIN 20200404-19:03:42] epoch: 0009/5000, discriminator loss: 1.3678\n",
      "[LOG TRAIN 20200404-19:03:42] epoch: 0009/5000, generator loss: 0.7325\n",
      "[LOG TRAIN 20200404-19:03:45] epoch: 0010/5000, reconstruction loss: 0.1145\n",
      "[LOG TRAIN 20200404-19:03:45] epoch: 0010/5000, discriminator loss: 1.3676\n",
      "[LOG TRAIN 20200404-19:03:45] epoch: 0010/5000, generator loss: 0.7321\n",
      "[LOG TRAIN 20200404-19:03:49] epoch: 0011/5000, reconstruction loss: 0.1083\n",
      "[LOG TRAIN 20200404-19:03:49] epoch: 0011/5000, discriminator loss: 1.3665\n",
      "[LOG TRAIN 20200404-19:03:49] epoch: 0011/5000, generator loss: 0.7326\n",
      "[LOG TRAIN 20200404-19:03:53] epoch: 0012/5000, reconstruction loss: 0.1051\n",
      "[LOG TRAIN 20200404-19:03:53] epoch: 0012/5000, discriminator loss: 1.3654\n",
      "[LOG TRAIN 20200404-19:03:53] epoch: 0012/5000, generator loss: 0.7334\n",
      "[LOG TRAIN 20200404-19:03:57] epoch: 0013/5000, reconstruction loss: 0.1033\n",
      "[LOG TRAIN 20200404-19:03:57] epoch: 0013/5000, discriminator loss: 1.3667\n",
      "[LOG TRAIN 20200404-19:03:57] epoch: 0013/5000, generator loss: 0.7313\n",
      "[LOG TRAIN 20200404-19:04:01] epoch: 0014/5000, reconstruction loss: 0.1039\n",
      "[LOG TRAIN 20200404-19:04:01] epoch: 0014/5000, discriminator loss: 1.3693\n",
      "[LOG TRAIN 20200404-19:04:01] epoch: 0014/5000, generator loss: 0.7277\n",
      "[LOG TRAIN 20200404-19:04:04] epoch: 0015/5000, reconstruction loss: 0.1030\n",
      "[LOG TRAIN 20200404-19:04:04] epoch: 0015/5000, discriminator loss: 1.3707\n",
      "[LOG TRAIN 20200404-19:04:04] epoch: 0015/5000, generator loss: 0.7258\n",
      "[LOG TRAIN 20200404-19:04:08] epoch: 0016/5000, reconstruction loss: 0.1012\n",
      "[LOG TRAIN 20200404-19:04:08] epoch: 0016/5000, discriminator loss: 1.3717\n",
      "[LOG TRAIN 20200404-19:04:08] epoch: 0016/5000, generator loss: 0.7244\n",
      "[LOG TRAIN 20200404-19:04:12] epoch: 0017/5000, reconstruction loss: 0.0998\n",
      "[LOG TRAIN 20200404-19:04:12] epoch: 0017/5000, discriminator loss: 1.3731\n",
      "[LOG TRAIN 20200404-19:04:12] epoch: 0017/5000, generator loss: 0.7220\n",
      "[LOG TRAIN 20200404-19:04:16] epoch: 0018/5000, reconstruction loss: 0.0988\n",
      "[LOG TRAIN 20200404-19:04:16] epoch: 0018/5000, discriminator loss: 1.3754\n",
      "[LOG TRAIN 20200404-19:04:16] epoch: 0018/5000, generator loss: 0.7192\n",
      "[LOG TRAIN 20200404-19:04:20] epoch: 0019/5000, reconstruction loss: 0.0979\n",
      "[LOG TRAIN 20200404-19:04:20] epoch: 0019/5000, discriminator loss: 1.3782\n",
      "[LOG TRAIN 20200404-19:04:20] epoch: 0019/5000, generator loss: 0.7155\n",
      "[LOG TRAIN 20200404-19:04:23] epoch: 0020/5000, reconstruction loss: 0.0967\n",
      "[LOG TRAIN 20200404-19:04:23] epoch: 0020/5000, discriminator loss: 1.3821\n",
      "[LOG TRAIN 20200404-19:04:23] epoch: 0020/5000, generator loss: 0.7111\n",
      "[LOG TRAIN 20200404-19:04:27] epoch: 0021/5000, reconstruction loss: 0.0957\n",
      "[LOG TRAIN 20200404-19:04:27] epoch: 0021/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:04:27] epoch: 0021/5000, generator loss: 0.7054\n",
      "[LOG TRAIN 20200404-19:04:31] epoch: 0022/5000, reconstruction loss: 0.0948\n",
      "[LOG TRAIN 20200404-19:04:31] epoch: 0022/5000, discriminator loss: 1.3919\n",
      "[LOG TRAIN 20200404-19:04:31] epoch: 0022/5000, generator loss: 0.6999\n",
      "[LOG TRAIN 20200404-19:04:35] epoch: 0023/5000, reconstruction loss: 0.0941\n",
      "[LOG TRAIN 20200404-19:04:35] epoch: 0023/5000, discriminator loss: 1.3939\n",
      "[LOG TRAIN 20200404-19:04:35] epoch: 0023/5000, generator loss: 0.6975\n",
      "[LOG TRAIN 20200404-19:04:38] epoch: 0024/5000, reconstruction loss: 0.0931\n",
      "[LOG TRAIN 20200404-19:04:38] epoch: 0024/5000, discriminator loss: 1.3932\n",
      "[LOG TRAIN 20200404-19:04:38] epoch: 0024/5000, generator loss: 0.6980\n",
      "[LOG TRAIN 20200404-19:04:42] epoch: 0025/5000, reconstruction loss: 0.0919\n",
      "[LOG TRAIN 20200404-19:04:42] epoch: 0025/5000, discriminator loss: 1.3914\n",
      "[LOG TRAIN 20200404-19:04:42] epoch: 0025/5000, generator loss: 0.6995\n",
      "[LOG TRAIN 20200404-19:04:46] epoch: 0026/5000, reconstruction loss: 0.0905\n",
      "[LOG TRAIN 20200404-19:04:46] epoch: 0026/5000, discriminator loss: 1.3896\n",
      "[LOG TRAIN 20200404-19:04:46] epoch: 0026/5000, generator loss: 0.7011\n",
      "[LOG TRAIN 20200404-19:04:50] epoch: 0027/5000, reconstruction loss: 0.0894\n",
      "[LOG TRAIN 20200404-19:04:50] epoch: 0027/5000, discriminator loss: 1.3879\n",
      "[LOG TRAIN 20200404-19:04:50] epoch: 0027/5000, generator loss: 0.7026\n",
      "[LOG TRAIN 20200404-19:04:53] epoch: 0028/5000, reconstruction loss: 0.0881\n",
      "[LOG TRAIN 20200404-19:04:53] epoch: 0028/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:04:53] epoch: 0028/5000, generator loss: 0.7039\n",
      "[LOG TRAIN 20200404-19:04:57] epoch: 0029/5000, reconstruction loss: 0.0867\n",
      "[LOG TRAIN 20200404-19:04:57] epoch: 0029/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-19:04:57] epoch: 0029/5000, generator loss: 0.7053\n",
      "[LOG TRAIN 20200404-19:05:01] epoch: 0030/5000, reconstruction loss: 0.0851\n",
      "[LOG TRAIN 20200404-19:05:01] epoch: 0030/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-19:05:01] epoch: 0030/5000, generator loss: 0.7066\n",
      "[LOG TRAIN 20200404-19:05:05] epoch: 0031/5000, reconstruction loss: 0.0830\n",
      "[LOG TRAIN 20200404-19:05:05] epoch: 0031/5000, discriminator loss: 1.3818\n",
      "[LOG TRAIN 20200404-19:05:05] epoch: 0031/5000, generator loss: 0.7078\n",
      "[LOG TRAIN 20200404-19:05:08] epoch: 0032/5000, reconstruction loss: 0.0806\n",
      "[LOG TRAIN 20200404-19:05:08] epoch: 0032/5000, discriminator loss: 1.3804\n",
      "[LOG TRAIN 20200404-19:05:08] epoch: 0032/5000, generator loss: 0.7091\n",
      "[LOG TRAIN 20200404-19:05:12] epoch: 0033/5000, reconstruction loss: 0.0782\n",
      "[LOG TRAIN 20200404-19:05:12] epoch: 0033/5000, discriminator loss: 1.3790\n",
      "[LOG TRAIN 20200404-19:05:12] epoch: 0033/5000, generator loss: 0.7103\n",
      "[LOG TRAIN 20200404-19:05:16] epoch: 0034/5000, reconstruction loss: 0.0753\n",
      "[LOG TRAIN 20200404-19:05:16] epoch: 0034/5000, discriminator loss: 1.3776\n",
      "[LOG TRAIN 20200404-19:05:16] epoch: 0034/5000, generator loss: 0.7115\n",
      "[LOG TRAIN 20200404-19:05:20] epoch: 0035/5000, reconstruction loss: 0.0723\n",
      "[LOG TRAIN 20200404-19:05:20] epoch: 0035/5000, discriminator loss: 1.3764\n",
      "[LOG TRAIN 20200404-19:05:20] epoch: 0035/5000, generator loss: 0.7125\n",
      "[LOG TRAIN 20200404-19:05:24] epoch: 0036/5000, reconstruction loss: 0.0691\n",
      "[LOG TRAIN 20200404-19:05:24] epoch: 0036/5000, discriminator loss: 1.3753\n",
      "[LOG TRAIN 20200404-19:05:24] epoch: 0036/5000, generator loss: 0.7133\n",
      "[LOG TRAIN 20200404-19:05:27] epoch: 0037/5000, reconstruction loss: 0.0659\n",
      "[LOG TRAIN 20200404-19:05:27] epoch: 0037/5000, discriminator loss: 1.3746\n",
      "[LOG TRAIN 20200404-19:05:27] epoch: 0037/5000, generator loss: 0.7138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:05:31] epoch: 0038/5000, reconstruction loss: 0.0626\n",
      "[LOG TRAIN 20200404-19:05:31] epoch: 0038/5000, discriminator loss: 1.3739\n",
      "[LOG TRAIN 20200404-19:05:31] epoch: 0038/5000, generator loss: 0.7142\n",
      "[LOG TRAIN 20200404-19:05:35] epoch: 0039/5000, reconstruction loss: 0.0593\n",
      "[LOG TRAIN 20200404-19:05:35] epoch: 0039/5000, discriminator loss: 1.3736\n",
      "[LOG TRAIN 20200404-19:05:35] epoch: 0039/5000, generator loss: 0.7142\n",
      "[LOG TRAIN 20200404-19:05:38] epoch: 0040/5000, reconstruction loss: 0.0562\n",
      "[LOG TRAIN 20200404-19:05:38] epoch: 0040/5000, discriminator loss: 1.3738\n",
      "[LOG TRAIN 20200404-19:05:38] epoch: 0040/5000, generator loss: 0.7138\n",
      "[LOG TRAIN 20200404-19:05:42] epoch: 0041/5000, reconstruction loss: 0.0531\n",
      "[LOG TRAIN 20200404-19:05:42] epoch: 0041/5000, discriminator loss: 1.3744\n",
      "[LOG TRAIN 20200404-19:05:42] epoch: 0041/5000, generator loss: 0.7129\n",
      "[LOG TRAIN 20200404-19:05:46] epoch: 0042/5000, reconstruction loss: 0.0499\n",
      "[LOG TRAIN 20200404-19:05:46] epoch: 0042/5000, discriminator loss: 1.3751\n",
      "[LOG TRAIN 20200404-19:05:46] epoch: 0042/5000, generator loss: 0.7118\n",
      "[LOG TRAIN 20200404-19:05:50] epoch: 0043/5000, reconstruction loss: 0.0467\n",
      "[LOG TRAIN 20200404-19:05:50] epoch: 0043/5000, discriminator loss: 1.3759\n",
      "[LOG TRAIN 20200404-19:05:50] epoch: 0043/5000, generator loss: 0.7106\n",
      "[LOG TRAIN 20200404-19:05:54] epoch: 0044/5000, reconstruction loss: 0.0437\n",
      "[LOG TRAIN 20200404-19:05:54] epoch: 0044/5000, discriminator loss: 1.3770\n",
      "[LOG TRAIN 20200404-19:05:54] epoch: 0044/5000, generator loss: 0.7092\n",
      "[LOG TRAIN 20200404-19:05:57] epoch: 0045/5000, reconstruction loss: 0.0412\n",
      "[LOG TRAIN 20200404-19:05:57] epoch: 0045/5000, discriminator loss: 1.3783\n",
      "[LOG TRAIN 20200404-19:05:57] epoch: 0045/5000, generator loss: 0.7076\n",
      "[LOG TRAIN 20200404-19:06:01] epoch: 0046/5000, reconstruction loss: 0.0392\n",
      "[LOG TRAIN 20200404-19:06:01] epoch: 0046/5000, discriminator loss: 1.3794\n",
      "[LOG TRAIN 20200404-19:06:01] epoch: 0046/5000, generator loss: 0.7061\n",
      "[LOG TRAIN 20200404-19:06:05] epoch: 0047/5000, reconstruction loss: 0.0378\n",
      "[LOG TRAIN 20200404-19:06:05] epoch: 0047/5000, discriminator loss: 1.3804\n",
      "[LOG TRAIN 20200404-19:06:05] epoch: 0047/5000, generator loss: 0.7048\n",
      "[LOG TRAIN 20200404-19:06:09] epoch: 0048/5000, reconstruction loss: 0.0369\n",
      "[LOG TRAIN 20200404-19:06:09] epoch: 0048/5000, discriminator loss: 1.3819\n",
      "[LOG TRAIN 20200404-19:06:09] epoch: 0048/5000, generator loss: 0.7030\n",
      "[LOG TRAIN 20200404-19:06:13] epoch: 0049/5000, reconstruction loss: 0.0367\n",
      "[LOG TRAIN 20200404-19:06:13] epoch: 0049/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-19:06:13] epoch: 0049/5000, generator loss: 0.7007\n",
      "[LOG TRAIN 20200404-19:06:16] epoch: 0050/5000, reconstruction loss: 0.0361\n",
      "[LOG TRAIN 20200404-19:06:16] epoch: 0050/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-19:06:16] epoch: 0050/5000, generator loss: 0.6994\n",
      "[LOG TRAIN 20200404-19:06:20] epoch: 0051/5000, reconstruction loss: 0.0355\n",
      "[LOG TRAIN 20200404-19:06:20] epoch: 0051/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:06:20] epoch: 0051/5000, generator loss: 0.6984\n",
      "[LOG TRAIN 20200404-19:06:24] epoch: 0052/5000, reconstruction loss: 0.0349\n",
      "[LOG TRAIN 20200404-19:06:24] epoch: 0052/5000, discriminator loss: 1.3866\n",
      "[LOG TRAIN 20200404-19:06:24] epoch: 0052/5000, generator loss: 0.6977\n",
      "[LOG TRAIN 20200404-19:06:28] epoch: 0053/5000, reconstruction loss: 0.0345\n",
      "[LOG TRAIN 20200404-19:06:28] epoch: 0053/5000, discriminator loss: 1.3874\n",
      "[LOG TRAIN 20200404-19:06:28] epoch: 0053/5000, generator loss: 0.6968\n",
      "[LOG TRAIN 20200404-19:06:31] epoch: 0054/5000, reconstruction loss: 0.0343\n",
      "[LOG TRAIN 20200404-19:06:31] epoch: 0054/5000, discriminator loss: 1.3882\n",
      "[LOG TRAIN 20200404-19:06:31] epoch: 0054/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200404-19:06:35] epoch: 0055/5000, reconstruction loss: 0.0339\n",
      "[LOG TRAIN 20200404-19:06:35] epoch: 0055/5000, discriminator loss: 1.3890\n",
      "[LOG TRAIN 20200404-19:06:35] epoch: 0055/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-19:06:39] epoch: 0056/5000, reconstruction loss: 0.0337\n",
      "[LOG TRAIN 20200404-19:06:39] epoch: 0056/5000, discriminator loss: 1.3897\n",
      "[LOG TRAIN 20200404-19:06:39] epoch: 0056/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-19:06:43] epoch: 0057/5000, reconstruction loss: 0.0335\n",
      "[LOG TRAIN 20200404-19:06:43] epoch: 0057/5000, discriminator loss: 1.3900\n",
      "[LOG TRAIN 20200404-19:06:43] epoch: 0057/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:06:46] epoch: 0058/5000, reconstruction loss: 0.0332\n",
      "[LOG TRAIN 20200404-19:06:46] epoch: 0058/5000, discriminator loss: 1.3901\n",
      "[LOG TRAIN 20200404-19:06:46] epoch: 0058/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:06:50] epoch: 0059/5000, reconstruction loss: 0.0330\n",
      "[LOG TRAIN 20200404-19:06:50] epoch: 0059/5000, discriminator loss: 1.3900\n",
      "[LOG TRAIN 20200404-19:06:50] epoch: 0059/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-19:06:54] epoch: 0060/5000, reconstruction loss: 0.0328\n",
      "[LOG TRAIN 20200404-19:06:54] epoch: 0060/5000, discriminator loss: 1.3901\n",
      "[LOG TRAIN 20200404-19:06:54] epoch: 0060/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:06:58] epoch: 0061/5000, reconstruction loss: 0.0327\n",
      "[LOG TRAIN 20200404-19:06:58] epoch: 0061/5000, discriminator loss: 1.3901\n",
      "[LOG TRAIN 20200404-19:06:58] epoch: 0061/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:07:01] epoch: 0062/5000, reconstruction loss: 0.0327\n",
      "[LOG TRAIN 20200404-19:07:01] epoch: 0062/5000, discriminator loss: 1.3900\n",
      "[LOG TRAIN 20200404-19:07:01] epoch: 0062/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:07:05] epoch: 0063/5000, reconstruction loss: 0.0326\n",
      "[LOG TRAIN 20200404-19:07:05] epoch: 0063/5000, discriminator loss: 1.3900\n",
      "[LOG TRAIN 20200404-19:07:05] epoch: 0063/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:07:09] epoch: 0064/5000, reconstruction loss: 0.0326\n",
      "[LOG TRAIN 20200404-19:07:09] epoch: 0064/5000, discriminator loss: 1.3899\n",
      "[LOG TRAIN 20200404-19:07:09] epoch: 0064/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:07:13] epoch: 0065/5000, reconstruction loss: 0.0325\n",
      "[LOG TRAIN 20200404-19:07:13] epoch: 0065/5000, discriminator loss: 1.3899\n",
      "[LOG TRAIN 20200404-19:07:13] epoch: 0065/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:07:17] epoch: 0066/5000, reconstruction loss: 0.0345\n",
      "[LOG TRAIN 20200404-19:07:17] epoch: 0066/5000, discriminator loss: 1.3898\n",
      "[LOG TRAIN 20200404-19:07:17] epoch: 0066/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:07:21] epoch: 0067/5000, reconstruction loss: 0.0674\n",
      "[LOG TRAIN 20200404-19:07:21] epoch: 0067/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:07:21] epoch: 0067/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-19:07:24] epoch: 0068/5000, reconstruction loss: 0.0485\n",
      "[LOG TRAIN 20200404-19:07:24] epoch: 0068/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:07:24] epoch: 0068/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200404-19:07:28] epoch: 0069/5000, reconstruction loss: 0.0478\n",
      "[LOG TRAIN 20200404-19:07:28] epoch: 0069/5000, discriminator loss: 1.3885\n",
      "[LOG TRAIN 20200404-19:07:28] epoch: 0069/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:07:32] epoch: 0070/5000, reconstruction loss: 0.0418\n",
      "[LOG TRAIN 20200404-19:07:32] epoch: 0070/5000, discriminator loss: 1.3869\n",
      "[LOG TRAIN 20200404-19:07:32] epoch: 0070/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-19:07:36] epoch: 0071/5000, reconstruction loss: 0.0343\n",
      "[LOG TRAIN 20200404-19:07:36] epoch: 0071/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:07:36] epoch: 0071/5000, generator loss: 0.6961\n",
      "[LOG TRAIN 20200404-19:07:39] epoch: 0072/5000, reconstruction loss: 0.0332\n",
      "[LOG TRAIN 20200404-19:07:39] epoch: 0072/5000, discriminator loss: 1.3873\n",
      "[LOG TRAIN 20200404-19:07:39] epoch: 0072/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-19:07:43] epoch: 0073/5000, reconstruction loss: 0.0333\n",
      "[LOG TRAIN 20200404-19:07:43] epoch: 0073/5000, discriminator loss: 1.3882\n",
      "[LOG TRAIN 20200404-19:07:43] epoch: 0073/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:07:47] epoch: 0074/5000, reconstruction loss: 0.0335\n",
      "[LOG TRAIN 20200404-19:07:47] epoch: 0074/5000, discriminator loss: 1.3888\n",
      "[LOG TRAIN 20200404-19:07:47] epoch: 0074/5000, generator loss: 0.6929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:07:51] epoch: 0075/5000, reconstruction loss: 0.0334\n",
      "[LOG TRAIN 20200404-19:07:51] epoch: 0075/5000, discriminator loss: 1.3887\n",
      "[LOG TRAIN 20200404-19:07:51] epoch: 0075/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:07:54] epoch: 0076/5000, reconstruction loss: 0.0330\n",
      "[LOG TRAIN 20200404-19:07:54] epoch: 0076/5000, discriminator loss: 1.3885\n",
      "[LOG TRAIN 20200404-19:07:54] epoch: 0076/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:07:58] epoch: 0077/5000, reconstruction loss: 0.0328\n",
      "[LOG TRAIN 20200404-19:07:58] epoch: 0077/5000, discriminator loss: 1.3884\n",
      "[LOG TRAIN 20200404-19:07:58] epoch: 0077/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:08:02] epoch: 0078/5000, reconstruction loss: 0.0328\n",
      "[LOG TRAIN 20200404-19:08:02] epoch: 0078/5000, discriminator loss: 1.3884\n",
      "[LOG TRAIN 20200404-19:08:02] epoch: 0078/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:08:06] epoch: 0079/5000, reconstruction loss: 0.0328\n",
      "[LOG TRAIN 20200404-19:08:06] epoch: 0079/5000, discriminator loss: 1.3883\n",
      "[LOG TRAIN 20200404-19:08:06] epoch: 0079/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:08:10] epoch: 0080/5000, reconstruction loss: 0.0326\n",
      "[LOG TRAIN 20200404-19:08:10] epoch: 0080/5000, discriminator loss: 1.3883\n",
      "[LOG TRAIN 20200404-19:08:10] epoch: 0080/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:08:13] epoch: 0081/5000, reconstruction loss: 0.0326\n",
      "[LOG TRAIN 20200404-19:08:13] epoch: 0081/5000, discriminator loss: 1.3882\n",
      "[LOG TRAIN 20200404-19:08:13] epoch: 0081/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:08:17] epoch: 0082/5000, reconstruction loss: 0.0326\n",
      "[LOG TRAIN 20200404-19:08:17] epoch: 0082/5000, discriminator loss: 1.3881\n",
      "[LOG TRAIN 20200404-19:08:17] epoch: 0082/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:08:21] epoch: 0083/5000, reconstruction loss: 0.0325\n",
      "[LOG TRAIN 20200404-19:08:21] epoch: 0083/5000, discriminator loss: 1.3881\n",
      "[LOG TRAIN 20200404-19:08:21] epoch: 0083/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:08:25] epoch: 0084/5000, reconstruction loss: 0.0325\n",
      "[LOG TRAIN 20200404-19:08:25] epoch: 0084/5000, discriminator loss: 1.3881\n",
      "[LOG TRAIN 20200404-19:08:25] epoch: 0084/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:08:29] epoch: 0085/5000, reconstruction loss: 0.0325\n",
      "[LOG TRAIN 20200404-19:08:29] epoch: 0085/5000, discriminator loss: 1.3881\n",
      "[LOG TRAIN 20200404-19:08:29] epoch: 0085/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:08:32] epoch: 0086/5000, reconstruction loss: 0.0325\n",
      "[LOG TRAIN 20200404-19:08:32] epoch: 0086/5000, discriminator loss: 1.3882\n",
      "[LOG TRAIN 20200404-19:08:32] epoch: 0086/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:08:36] epoch: 0087/5000, reconstruction loss: 0.0325\n",
      "[LOG TRAIN 20200404-19:08:36] epoch: 0087/5000, discriminator loss: 1.3882\n",
      "[LOG TRAIN 20200404-19:08:36] epoch: 0087/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:08:40] epoch: 0088/5000, reconstruction loss: 0.0324\n",
      "[LOG TRAIN 20200404-19:08:40] epoch: 0088/5000, discriminator loss: 1.3881\n",
      "[LOG TRAIN 20200404-19:08:40] epoch: 0088/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:08:44] epoch: 0089/5000, reconstruction loss: 0.0324\n",
      "[LOG TRAIN 20200404-19:08:44] epoch: 0089/5000, discriminator loss: 1.3881\n",
      "[LOG TRAIN 20200404-19:08:44] epoch: 0089/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:08:48] epoch: 0090/5000, reconstruction loss: 0.0324\n",
      "[LOG TRAIN 20200404-19:08:48] epoch: 0090/5000, discriminator loss: 1.3881\n",
      "[LOG TRAIN 20200404-19:08:48] epoch: 0090/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:08:51] epoch: 0091/5000, reconstruction loss: 0.0323\n",
      "[LOG TRAIN 20200404-19:08:51] epoch: 0091/5000, discriminator loss: 1.3880\n",
      "[LOG TRAIN 20200404-19:08:51] epoch: 0091/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:08:55] epoch: 0092/5000, reconstruction loss: 0.0323\n",
      "[LOG TRAIN 20200404-19:08:55] epoch: 0092/5000, discriminator loss: 1.3879\n",
      "[LOG TRAIN 20200404-19:08:55] epoch: 0092/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:08:59] epoch: 0093/5000, reconstruction loss: 0.0322\n",
      "[LOG TRAIN 20200404-19:08:59] epoch: 0093/5000, discriminator loss: 1.3879\n",
      "[LOG TRAIN 20200404-19:08:59] epoch: 0093/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:09:03] epoch: 0094/5000, reconstruction loss: 0.0322\n",
      "[LOG TRAIN 20200404-19:09:03] epoch: 0094/5000, discriminator loss: 1.3878\n",
      "[LOG TRAIN 20200404-19:09:03] epoch: 0094/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:09:07] epoch: 0095/5000, reconstruction loss: 0.0322\n",
      "[LOG TRAIN 20200404-19:09:07] epoch: 0095/5000, discriminator loss: 1.3877\n",
      "[LOG TRAIN 20200404-19:09:07] epoch: 0095/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:09:10] epoch: 0096/5000, reconstruction loss: 0.0322\n",
      "[LOG TRAIN 20200404-19:09:10] epoch: 0096/5000, discriminator loss: 1.3876\n",
      "[LOG TRAIN 20200404-19:09:10] epoch: 0096/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:09:14] epoch: 0097/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:09:14] epoch: 0097/5000, discriminator loss: 1.3876\n",
      "[LOG TRAIN 20200404-19:09:14] epoch: 0097/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:09:18] epoch: 0098/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:09:18] epoch: 0098/5000, discriminator loss: 1.3875\n",
      "[LOG TRAIN 20200404-19:09:18] epoch: 0098/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:09:22] epoch: 0099/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:09:22] epoch: 0099/5000, discriminator loss: 1.3874\n",
      "[LOG TRAIN 20200404-19:09:22] epoch: 0099/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:09:25] epoch: 0100/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:09:25] epoch: 0100/5000, discriminator loss: 1.3874\n",
      "[LOG TRAIN 20200404-19:09:25] epoch: 0100/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:09:29] epoch: 0101/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:09:29] epoch: 0101/5000, discriminator loss: 1.3873\n",
      "[LOG TRAIN 20200404-19:09:29] epoch: 0101/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:09:33] epoch: 0102/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:09:33] epoch: 0102/5000, discriminator loss: 1.3872\n",
      "[LOG TRAIN 20200404-19:09:33] epoch: 0102/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:09:37] epoch: 0103/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:09:37] epoch: 0103/5000, discriminator loss: 1.3872\n",
      "[LOG TRAIN 20200404-19:09:37] epoch: 0103/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:09:41] epoch: 0104/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:09:41] epoch: 0104/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:09:41] epoch: 0104/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:09:44] epoch: 0105/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:09:44] epoch: 0105/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:09:44] epoch: 0105/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:09:48] epoch: 0106/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:09:48] epoch: 0106/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:09:48] epoch: 0106/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:09:52] epoch: 0107/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:09:52] epoch: 0107/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:09:52] epoch: 0107/5000, generator loss: 0.6917\n",
      "[LOG TRAIN 20200404-19:09:56] epoch: 0108/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:09:56] epoch: 0108/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:09:56] epoch: 0108/5000, generator loss: 0.6917\n",
      "[LOG TRAIN 20200404-19:09:59] epoch: 0109/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:09:59] epoch: 0109/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:09:59] epoch: 0109/5000, generator loss: 0.6916\n",
      "[LOG TRAIN 20200404-19:10:03] epoch: 0110/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:03] epoch: 0110/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:10:03] epoch: 0110/5000, generator loss: 0.6916\n",
      "[LOG TRAIN 20200404-19:10:07] epoch: 0111/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:07] epoch: 0111/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:10:07] epoch: 0111/5000, generator loss: 0.6916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:10:11] epoch: 0112/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:11] epoch: 0112/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:10:11] epoch: 0112/5000, generator loss: 0.6915\n",
      "[LOG TRAIN 20200404-19:10:15] epoch: 0113/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:15] epoch: 0113/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:10:15] epoch: 0113/5000, generator loss: 0.6915\n",
      "[LOG TRAIN 20200404-19:10:18] epoch: 0114/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:18] epoch: 0114/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:10:18] epoch: 0114/5000, generator loss: 0.6914\n",
      "[LOG TRAIN 20200404-19:10:22] epoch: 0115/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:22] epoch: 0115/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:10:22] epoch: 0115/5000, generator loss: 0.6914\n",
      "[LOG TRAIN 20200404-19:10:26] epoch: 0116/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:26] epoch: 0116/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:10:26] epoch: 0116/5000, generator loss: 0.6914\n",
      "[LOG TRAIN 20200404-19:10:30] epoch: 0117/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:30] epoch: 0117/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:10:30] epoch: 0117/5000, generator loss: 0.6914\n",
      "[LOG TRAIN 20200404-19:10:34] epoch: 0118/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:34] epoch: 0118/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:10:34] epoch: 0118/5000, generator loss: 0.6913\n",
      "[LOG TRAIN 20200404-19:10:37] epoch: 0119/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:37] epoch: 0119/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:10:37] epoch: 0119/5000, generator loss: 0.6913\n",
      "[LOG TRAIN 20200404-19:10:41] epoch: 0120/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:10:41] epoch: 0120/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:10:41] epoch: 0120/5000, generator loss: 0.6913\n",
      "[LOG TRAIN 20200404-19:10:45] epoch: 0121/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:10:45] epoch: 0121/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:10:45] epoch: 0121/5000, generator loss: 0.6913\n",
      "[LOG TRAIN 20200404-19:10:49] epoch: 0122/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:10:49] epoch: 0122/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:10:49] epoch: 0122/5000, generator loss: 0.6913\n",
      "[LOG TRAIN 20200404-19:10:53] epoch: 0123/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:10:53] epoch: 0123/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:10:53] epoch: 0123/5000, generator loss: 0.6913\n",
      "[LOG TRAIN 20200404-19:10:56] epoch: 0124/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:10:56] epoch: 0124/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:10:56] epoch: 0124/5000, generator loss: 0.6914\n",
      "[LOG TRAIN 20200404-19:11:00] epoch: 0125/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:00] epoch: 0125/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:11:00] epoch: 0125/5000, generator loss: 0.6914\n",
      "[LOG TRAIN 20200404-19:11:04] epoch: 0126/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:04] epoch: 0126/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:11:04] epoch: 0126/5000, generator loss: 0.6914\n",
      "[LOG TRAIN 20200404-19:11:08] epoch: 0127/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:08] epoch: 0127/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:11:08] epoch: 0127/5000, generator loss: 0.6914\n",
      "[LOG TRAIN 20200404-19:11:11] epoch: 0128/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:11] epoch: 0128/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:11:11] epoch: 0128/5000, generator loss: 0.6915\n",
      "[LOG TRAIN 20200404-19:11:15] epoch: 0129/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:11:15] epoch: 0129/5000, discriminator loss: 1.3871\n",
      "[LOG TRAIN 20200404-19:11:15] epoch: 0129/5000, generator loss: 0.6915\n",
      "[LOG TRAIN 20200404-19:11:19] epoch: 0130/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:11:19] epoch: 0130/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:19] epoch: 0130/5000, generator loss: 0.6915\n",
      "[LOG TRAIN 20200404-19:11:23] epoch: 0131/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:23] epoch: 0131/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:23] epoch: 0131/5000, generator loss: 0.6916\n",
      "[LOG TRAIN 20200404-19:11:26] epoch: 0132/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:26] epoch: 0132/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:26] epoch: 0132/5000, generator loss: 0.6916\n",
      "[LOG TRAIN 20200404-19:11:30] epoch: 0133/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:11:30] epoch: 0133/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:30] epoch: 0133/5000, generator loss: 0.6916\n",
      "[LOG TRAIN 20200404-19:11:34] epoch: 0134/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:34] epoch: 0134/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:34] epoch: 0134/5000, generator loss: 0.6917\n",
      "[LOG TRAIN 20200404-19:11:38] epoch: 0135/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:11:38] epoch: 0135/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:38] epoch: 0135/5000, generator loss: 0.6917\n",
      "[LOG TRAIN 20200404-19:11:42] epoch: 0136/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:42] epoch: 0136/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:42] epoch: 0136/5000, generator loss: 0.6917\n",
      "[LOG TRAIN 20200404-19:11:45] epoch: 0137/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:45] epoch: 0137/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:45] epoch: 0137/5000, generator loss: 0.6917\n",
      "[LOG TRAIN 20200404-19:11:49] epoch: 0138/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:49] epoch: 0138/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:49] epoch: 0138/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:11:53] epoch: 0139/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:11:53] epoch: 0139/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:53] epoch: 0139/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:11:57] epoch: 0140/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:11:57] epoch: 0140/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:11:57] epoch: 0140/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:12:00] epoch: 0141/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:12:00] epoch: 0141/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:12:00] epoch: 0141/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:12:04] epoch: 0142/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:12:04] epoch: 0142/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:12:04] epoch: 0142/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:12:08] epoch: 0143/5000, reconstruction loss: 0.0322\n",
      "[LOG TRAIN 20200404-19:12:08] epoch: 0143/5000, discriminator loss: 1.3870\n",
      "[LOG TRAIN 20200404-19:12:08] epoch: 0143/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:12:12] epoch: 0144/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:12:12] epoch: 0144/5000, discriminator loss: 1.3869\n",
      "[LOG TRAIN 20200404-19:12:12] epoch: 0144/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:12:16] epoch: 0145/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:12:16] epoch: 0145/5000, discriminator loss: 1.3869\n",
      "[LOG TRAIN 20200404-19:12:16] epoch: 0145/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:12:19] epoch: 0146/5000, reconstruction loss: 0.0322\n",
      "[LOG TRAIN 20200404-19:12:19] epoch: 0146/5000, discriminator loss: 1.3869\n",
      "[LOG TRAIN 20200404-19:12:19] epoch: 0146/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:12:23] epoch: 0147/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:12:23] epoch: 0147/5000, discriminator loss: 1.3869\n",
      "[LOG TRAIN 20200404-19:12:23] epoch: 0147/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:12:27] epoch: 0148/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:12:27] epoch: 0148/5000, discriminator loss: 1.3869\n",
      "[LOG TRAIN 20200404-19:12:27] epoch: 0148/5000, generator loss: 0.6920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:12:31] epoch: 0149/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:12:31] epoch: 0149/5000, discriminator loss: 1.3869\n",
      "[LOG TRAIN 20200404-19:12:31] epoch: 0149/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:12:35] epoch: 0150/5000, reconstruction loss: 0.0324\n",
      "[LOG TRAIN 20200404-19:12:35] epoch: 0150/5000, discriminator loss: 1.3869\n",
      "[LOG TRAIN 20200404-19:12:35] epoch: 0150/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:12:38] epoch: 0151/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:12:38] epoch: 0151/5000, discriminator loss: 1.3869\n",
      "[LOG TRAIN 20200404-19:12:38] epoch: 0151/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:12:42] epoch: 0152/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:12:42] epoch: 0152/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:12:42] epoch: 0152/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:12:46] epoch: 0153/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:12:46] epoch: 0153/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:12:46] epoch: 0153/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:12:50] epoch: 0154/5000, reconstruction loss: 0.0323\n",
      "[LOG TRAIN 20200404-19:12:50] epoch: 0154/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:12:50] epoch: 0154/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:12:53] epoch: 0155/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:12:53] epoch: 0155/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:12:53] epoch: 0155/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:12:57] epoch: 0156/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:12:57] epoch: 0156/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:12:57] epoch: 0156/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:13:01] epoch: 0157/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:13:01] epoch: 0157/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:13:01] epoch: 0157/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:13:05] epoch: 0158/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:13:05] epoch: 0158/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:13:05] epoch: 0158/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:13:09] epoch: 0159/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:13:09] epoch: 0159/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:13:09] epoch: 0159/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:13:12] epoch: 0160/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:13:12] epoch: 0160/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:13:12] epoch: 0160/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:13:16] epoch: 0161/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:13:16] epoch: 0161/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:13:16] epoch: 0161/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:13:20] epoch: 0162/5000, reconstruction loss: 0.0322\n",
      "[LOG TRAIN 20200404-19:13:20] epoch: 0162/5000, discriminator loss: 1.3868\n",
      "[LOG TRAIN 20200404-19:13:20] epoch: 0162/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:13:24] epoch: 0163/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:13:24] epoch: 0163/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:13:24] epoch: 0163/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:13:27] epoch: 0164/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:13:27] epoch: 0164/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:13:27] epoch: 0164/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:13:31] epoch: 0165/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:13:31] epoch: 0165/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:13:31] epoch: 0165/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:13:35] epoch: 0166/5000, reconstruction loss: 0.0323\n",
      "[LOG TRAIN 20200404-19:13:35] epoch: 0166/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:13:35] epoch: 0166/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:13:39] epoch: 0167/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:13:39] epoch: 0167/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:13:39] epoch: 0167/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:13:42] epoch: 0168/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:13:42] epoch: 0168/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:13:42] epoch: 0168/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:13:46] epoch: 0169/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:13:46] epoch: 0169/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:13:46] epoch: 0169/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:13:50] epoch: 0170/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:13:50] epoch: 0170/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:13:50] epoch: 0170/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:13:54] epoch: 0171/5000, reconstruction loss: 0.0329\n",
      "[LOG TRAIN 20200404-19:13:54] epoch: 0171/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:13:54] epoch: 0171/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:13:58] epoch: 0172/5000, reconstruction loss: 0.0322\n",
      "[LOG TRAIN 20200404-19:13:58] epoch: 0172/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:13:58] epoch: 0172/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:14:01] epoch: 0173/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:14:01] epoch: 0173/5000, discriminator loss: 1.3866\n",
      "[LOG TRAIN 20200404-19:14:01] epoch: 0173/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:14:05] epoch: 0174/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:14:05] epoch: 0174/5000, discriminator loss: 1.3866\n",
      "[LOG TRAIN 20200404-19:14:05] epoch: 0174/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:14:09] epoch: 0175/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:14:09] epoch: 0175/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:14:09] epoch: 0175/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:14:13] epoch: 0176/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:14:13] epoch: 0176/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:14:13] epoch: 0176/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:14:17] epoch: 0177/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:14:17] epoch: 0177/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:14:17] epoch: 0177/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:14:20] epoch: 0178/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:14:20] epoch: 0178/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:14:20] epoch: 0178/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:14:24] epoch: 0179/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:14:24] epoch: 0179/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:14:24] epoch: 0179/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:14:28] epoch: 0180/5000, reconstruction loss: 0.0322\n",
      "[LOG TRAIN 20200404-19:14:28] epoch: 0180/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:14:28] epoch: 0180/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:14:32] epoch: 0181/5000, reconstruction loss: 0.0350\n",
      "[LOG TRAIN 20200404-19:14:32] epoch: 0181/5000, discriminator loss: 1.3866\n",
      "[LOG TRAIN 20200404-19:14:32] epoch: 0181/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:14:36] epoch: 0182/5000, reconstruction loss: 0.1466\n",
      "[LOG TRAIN 20200404-19:14:36] epoch: 0182/5000, discriminator loss: 1.3789\n",
      "[LOG TRAIN 20200404-19:14:36] epoch: 0182/5000, generator loss: 0.7006\n",
      "[LOG TRAIN 20200404-19:14:39] epoch: 0183/5000, reconstruction loss: 0.1822\n",
      "[LOG TRAIN 20200404-19:14:39] epoch: 0183/5000, discriminator loss: 1.3706\n",
      "[LOG TRAIN 20200404-19:14:39] epoch: 0183/5000, generator loss: 0.7093\n",
      "[LOG TRAIN 20200404-19:14:43] epoch: 0184/5000, reconstruction loss: 0.1653\n",
      "[LOG TRAIN 20200404-19:14:43] epoch: 0184/5000, discriminator loss: 1.3796\n",
      "[LOG TRAIN 20200404-19:14:43] epoch: 0184/5000, generator loss: 0.6999\n",
      "[LOG TRAIN 20200404-19:14:47] epoch: 0185/5000, reconstruction loss: 0.1216\n",
      "[LOG TRAIN 20200404-19:14:47] epoch: 0185/5000, discriminator loss: 1.3784\n",
      "[LOG TRAIN 20200404-19:14:47] epoch: 0185/5000, generator loss: 0.7013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:14:51] epoch: 0186/5000, reconstruction loss: 0.0903\n",
      "[LOG TRAIN 20200404-19:14:51] epoch: 0186/5000, discriminator loss: 1.3778\n",
      "[LOG TRAIN 20200404-19:14:51] epoch: 0186/5000, generator loss: 0.7018\n",
      "[LOG TRAIN 20200404-19:14:55] epoch: 0187/5000, reconstruction loss: 0.0692\n",
      "[LOG TRAIN 20200404-19:14:55] epoch: 0187/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-19:14:55] epoch: 0187/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200404-19:14:59] epoch: 0188/5000, reconstruction loss: 0.0422\n",
      "[LOG TRAIN 20200404-19:14:59] epoch: 0188/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-19:14:59] epoch: 0188/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-19:15:02] epoch: 0189/5000, reconstruction loss: 0.0353\n",
      "[LOG TRAIN 20200404-19:15:02] epoch: 0189/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:15:02] epoch: 0189/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:15:06] epoch: 0190/5000, reconstruction loss: 0.0336\n",
      "[LOG TRAIN 20200404-19:15:06] epoch: 0190/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:15:06] epoch: 0190/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:15:10] epoch: 0191/5000, reconstruction loss: 0.0326\n",
      "[LOG TRAIN 20200404-19:15:10] epoch: 0191/5000, discriminator loss: 1.3866\n",
      "[LOG TRAIN 20200404-19:15:10] epoch: 0191/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:15:14] epoch: 0192/5000, reconstruction loss: 0.0323\n",
      "[LOG TRAIN 20200404-19:15:14] epoch: 0192/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:15:14] epoch: 0192/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:15:17] epoch: 0193/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:15:17] epoch: 0193/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:15:17] epoch: 0193/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:15:21] epoch: 0194/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:15:21] epoch: 0194/5000, discriminator loss: 1.3867\n",
      "[LOG TRAIN 20200404-19:15:21] epoch: 0194/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:15:25] epoch: 0195/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:15:25] epoch: 0195/5000, discriminator loss: 1.3866\n",
      "[LOG TRAIN 20200404-19:15:25] epoch: 0195/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:15:29] epoch: 0196/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:15:29] epoch: 0196/5000, discriminator loss: 1.3866\n",
      "[LOG TRAIN 20200404-19:15:29] epoch: 0196/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:15:32] epoch: 0197/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:15:32] epoch: 0197/5000, discriminator loss: 1.3866\n",
      "[LOG TRAIN 20200404-19:15:32] epoch: 0197/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:15:36] epoch: 0198/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:15:36] epoch: 0198/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:15:36] epoch: 0198/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:15:40] epoch: 0199/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:15:40] epoch: 0199/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:15:40] epoch: 0199/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:15:44] epoch: 0200/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:15:44] epoch: 0200/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:15:44] epoch: 0200/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:15:48] epoch: 0201/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:15:48] epoch: 0201/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:15:48] epoch: 0201/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:15:51] epoch: 0202/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:15:51] epoch: 0202/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:15:51] epoch: 0202/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:15:55] epoch: 0203/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:15:55] epoch: 0203/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:15:55] epoch: 0203/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:15:59] epoch: 0204/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:15:59] epoch: 0204/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:15:59] epoch: 0204/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:16:03] epoch: 0205/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:16:03] epoch: 0205/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:16:03] epoch: 0205/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:16:06] epoch: 0206/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:16:06] epoch: 0206/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:16:06] epoch: 0206/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:16:10] epoch: 0207/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:16:10] epoch: 0207/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:16:10] epoch: 0207/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:16:14] epoch: 0208/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:16:14] epoch: 0208/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:16:14] epoch: 0208/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:16:18] epoch: 0209/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:16:18] epoch: 0209/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:16:18] epoch: 0209/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:16:22] epoch: 0210/5000, reconstruction loss: 0.0321\n",
      "[LOG TRAIN 20200404-19:16:22] epoch: 0210/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:16:22] epoch: 0210/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:16:26] epoch: 0211/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:16:26] epoch: 0211/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:16:26] epoch: 0211/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:16:29] epoch: 0212/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:16:29] epoch: 0212/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:16:29] epoch: 0212/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:16:33] epoch: 0213/5000, reconstruction loss: 0.0320\n",
      "[LOG TRAIN 20200404-19:16:33] epoch: 0213/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:16:33] epoch: 0213/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:16:37] epoch: 0214/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:16:37] epoch: 0214/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:16:37] epoch: 0214/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:16:41] epoch: 0215/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:16:41] epoch: 0215/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:16:41] epoch: 0215/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:16:44] epoch: 0216/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:16:44] epoch: 0216/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:16:44] epoch: 0216/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:16:48] epoch: 0217/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:16:48] epoch: 0217/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:16:48] epoch: 0217/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:16:52] epoch: 0218/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:16:52] epoch: 0218/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:16:52] epoch: 0218/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:16:56] epoch: 0219/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:16:56] epoch: 0219/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:16:56] epoch: 0219/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:16:59] epoch: 0220/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:16:59] epoch: 0220/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:16:59] epoch: 0220/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:17:03] epoch: 0221/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:17:03] epoch: 0221/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:17:03] epoch: 0221/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:17:07] epoch: 0222/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:17:07] epoch: 0222/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:17:07] epoch: 0222/5000, generator loss: 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:17:11] epoch: 0223/5000, reconstruction loss: 0.0319\n",
      "[LOG TRAIN 20200404-19:17:11] epoch: 0223/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:17:11] epoch: 0223/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:17:14] epoch: 0224/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:17:14] epoch: 0224/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:17:14] epoch: 0224/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:17:18] epoch: 0225/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:17:18] epoch: 0225/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:17:18] epoch: 0225/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:17:22] epoch: 0226/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:17:22] epoch: 0226/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:17:22] epoch: 0226/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:17:26] epoch: 0227/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:17:26] epoch: 0227/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:17:26] epoch: 0227/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:17:29] epoch: 0228/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:17:29] epoch: 0228/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:17:29] epoch: 0228/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:17:33] epoch: 0229/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:17:33] epoch: 0229/5000, discriminator loss: 1.3865\n",
      "[LOG TRAIN 20200404-19:17:33] epoch: 0229/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:17:37] epoch: 0230/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:17:37] epoch: 0230/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:17:37] epoch: 0230/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:17:41] epoch: 0231/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:17:41] epoch: 0231/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:17:41] epoch: 0231/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:17:45] epoch: 0232/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:17:45] epoch: 0232/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:17:45] epoch: 0232/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:17:48] epoch: 0233/5000, reconstruction loss: 0.0318\n",
      "[LOG TRAIN 20200404-19:17:48] epoch: 0233/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:17:48] epoch: 0233/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:17:52] epoch: 0234/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:17:52] epoch: 0234/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:17:52] epoch: 0234/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:17:56] epoch: 0235/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:17:56] epoch: 0235/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:17:56] epoch: 0235/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:18:00] epoch: 0236/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:18:00] epoch: 0236/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:18:00] epoch: 0236/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:18:04] epoch: 0237/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:18:04] epoch: 0237/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:18:04] epoch: 0237/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:18:07] epoch: 0238/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:18:07] epoch: 0238/5000, discriminator loss: 1.3864\n",
      "[LOG TRAIN 20200404-19:18:07] epoch: 0238/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:18:11] epoch: 0239/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:18:11] epoch: 0239/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:11] epoch: 0239/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:18:15] epoch: 0240/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:18:15] epoch: 0240/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:15] epoch: 0240/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:18:19] epoch: 0241/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:18:19] epoch: 0241/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:19] epoch: 0241/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:18:23] epoch: 0242/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:18:23] epoch: 0242/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:23] epoch: 0242/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:18:26] epoch: 0243/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:18:26] epoch: 0243/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:26] epoch: 0243/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:18:30] epoch: 0244/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:18:30] epoch: 0244/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:30] epoch: 0244/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:18:34] epoch: 0245/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:18:34] epoch: 0245/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:34] epoch: 0245/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:18:38] epoch: 0246/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:18:38] epoch: 0246/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:38] epoch: 0246/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:18:42] epoch: 0247/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:18:42] epoch: 0247/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:42] epoch: 0247/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:18:45] epoch: 0248/5000, reconstruction loss: 0.0317\n",
      "[LOG TRAIN 20200404-19:18:45] epoch: 0248/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:45] epoch: 0248/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:18:49] epoch: 0249/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:18:49] epoch: 0249/5000, discriminator loss: 1.3863\n",
      "[LOG TRAIN 20200404-19:18:49] epoch: 0249/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:18:53] epoch: 0250/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:18:53] epoch: 0250/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:18:53] epoch: 0250/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:18:57] epoch: 0251/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:18:57] epoch: 0251/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:18:57] epoch: 0251/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:19:01] epoch: 0252/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:19:01] epoch: 0252/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:01] epoch: 0252/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:19:05] epoch: 0253/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:05] epoch: 0253/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:05] epoch: 0253/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:19:08] epoch: 0254/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:19:08] epoch: 0254/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:08] epoch: 0254/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:19:12] epoch: 0255/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:19:12] epoch: 0255/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:12] epoch: 0255/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:19:16] epoch: 0256/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:16] epoch: 0256/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:16] epoch: 0256/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:19:20] epoch: 0257/5000, reconstruction loss: 0.0316\n",
      "[LOG TRAIN 20200404-19:19:20] epoch: 0257/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:20] epoch: 0257/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:19:23] epoch: 0258/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:23] epoch: 0258/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:23] epoch: 0258/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:19:27] epoch: 0259/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:27] epoch: 0259/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:27] epoch: 0259/5000, generator loss: 0.6927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:19:31] epoch: 0260/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:31] epoch: 0260/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:31] epoch: 0260/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:19:35] epoch: 0261/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:35] epoch: 0261/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:35] epoch: 0261/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:19:39] epoch: 0262/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:39] epoch: 0262/5000, discriminator loss: 1.3862\n",
      "[LOG TRAIN 20200404-19:19:39] epoch: 0262/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:19:42] epoch: 0263/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:42] epoch: 0263/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:19:42] epoch: 0263/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:19:46] epoch: 0264/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:46] epoch: 0264/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:19:46] epoch: 0264/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:19:50] epoch: 0265/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:50] epoch: 0265/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:19:50] epoch: 0265/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:19:54] epoch: 0266/5000, reconstruction loss: 0.0314\n",
      "[LOG TRAIN 20200404-19:19:54] epoch: 0266/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:19:54] epoch: 0266/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:19:58] epoch: 0267/5000, reconstruction loss: 0.0315\n",
      "[LOG TRAIN 20200404-19:19:58] epoch: 0267/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:19:58] epoch: 0267/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:20:02] epoch: 0268/5000, reconstruction loss: 0.0314\n",
      "[LOG TRAIN 20200404-19:20:02] epoch: 0268/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:02] epoch: 0268/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:20:07] epoch: 0269/5000, reconstruction loss: 0.0314\n",
      "[LOG TRAIN 20200404-19:20:07] epoch: 0269/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:07] epoch: 0269/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:20:11] epoch: 0270/5000, reconstruction loss: 0.0314\n",
      "[LOG TRAIN 20200404-19:20:11] epoch: 0270/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:11] epoch: 0270/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:20:15] epoch: 0271/5000, reconstruction loss: 0.0314\n",
      "[LOG TRAIN 20200404-19:20:15] epoch: 0271/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:15] epoch: 0271/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:20:19] epoch: 0272/5000, reconstruction loss: 0.0314\n",
      "[LOG TRAIN 20200404-19:20:19] epoch: 0272/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:19] epoch: 0272/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:20:23] epoch: 0273/5000, reconstruction loss: 0.0314\n",
      "[LOG TRAIN 20200404-19:20:23] epoch: 0273/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:23] epoch: 0273/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:20:27] epoch: 0274/5000, reconstruction loss: 0.0313\n",
      "[LOG TRAIN 20200404-19:20:27] epoch: 0274/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:27] epoch: 0274/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:20:31] epoch: 0275/5000, reconstruction loss: 0.0313\n",
      "[LOG TRAIN 20200404-19:20:31] epoch: 0275/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:31] epoch: 0275/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:20:35] epoch: 0276/5000, reconstruction loss: 0.0313\n",
      "[LOG TRAIN 20200404-19:20:35] epoch: 0276/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:35] epoch: 0276/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:20:39] epoch: 0277/5000, reconstruction loss: 0.0313\n",
      "[LOG TRAIN 20200404-19:20:39] epoch: 0277/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:39] epoch: 0277/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:20:43] epoch: 0278/5000, reconstruction loss: 0.0313\n",
      "[LOG TRAIN 20200404-19:20:43] epoch: 0278/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:43] epoch: 0278/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:20:47] epoch: 0279/5000, reconstruction loss: 0.0313\n",
      "[LOG TRAIN 20200404-19:20:47] epoch: 0279/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:47] epoch: 0279/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:20:51] epoch: 0280/5000, reconstruction loss: 0.0313\n",
      "[LOG TRAIN 20200404-19:20:51] epoch: 0280/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:51] epoch: 0280/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:20:56] epoch: 0281/5000, reconstruction loss: 0.0312\n",
      "[LOG TRAIN 20200404-19:20:56] epoch: 0281/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:20:56] epoch: 0281/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:21:01] epoch: 0282/5000, reconstruction loss: 0.0312\n",
      "[LOG TRAIN 20200404-19:21:01] epoch: 0282/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:01] epoch: 0282/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:21:05] epoch: 0283/5000, reconstruction loss: 0.0312\n",
      "[LOG TRAIN 20200404-19:21:05] epoch: 0283/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:05] epoch: 0283/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:21:10] epoch: 0284/5000, reconstruction loss: 0.0311\n",
      "[LOG TRAIN 20200404-19:21:10] epoch: 0284/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:10] epoch: 0284/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:21:14] epoch: 0285/5000, reconstruction loss: 0.0312\n",
      "[LOG TRAIN 20200404-19:21:14] epoch: 0285/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:14] epoch: 0285/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:21:19] epoch: 0286/5000, reconstruction loss: 0.0311\n",
      "[LOG TRAIN 20200404-19:21:19] epoch: 0286/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:19] epoch: 0286/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:21:23] epoch: 0287/5000, reconstruction loss: 0.0311\n",
      "[LOG TRAIN 20200404-19:21:23] epoch: 0287/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:23] epoch: 0287/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:21:27] epoch: 0288/5000, reconstruction loss: 0.0311\n",
      "[LOG TRAIN 20200404-19:21:27] epoch: 0288/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:27] epoch: 0288/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:21:31] epoch: 0289/5000, reconstruction loss: 0.0311\n",
      "[LOG TRAIN 20200404-19:21:31] epoch: 0289/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:31] epoch: 0289/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:21:35] epoch: 0290/5000, reconstruction loss: 0.0311\n",
      "[LOG TRAIN 20200404-19:21:35] epoch: 0290/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:35] epoch: 0290/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:21:39] epoch: 0291/5000, reconstruction loss: 0.0310\n",
      "[LOG TRAIN 20200404-19:21:39] epoch: 0291/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:39] epoch: 0291/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:21:42] epoch: 0292/5000, reconstruction loss: 0.0310\n",
      "[LOG TRAIN 20200404-19:21:42] epoch: 0292/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:42] epoch: 0292/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:21:46] epoch: 0293/5000, reconstruction loss: 0.0310\n",
      "[LOG TRAIN 20200404-19:21:46] epoch: 0293/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:46] epoch: 0293/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:21:50] epoch: 0294/5000, reconstruction loss: 0.0310\n",
      "[LOG TRAIN 20200404-19:21:50] epoch: 0294/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:50] epoch: 0294/5000, generator loss: 0.6918\n",
      "[LOG TRAIN 20200404-19:21:54] epoch: 0295/5000, reconstruction loss: 0.0309\n",
      "[LOG TRAIN 20200404-19:21:54] epoch: 0295/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:54] epoch: 0295/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:21:57] epoch: 0296/5000, reconstruction loss: 0.0309\n",
      "[LOG TRAIN 20200404-19:21:57] epoch: 0296/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:21:57] epoch: 0296/5000, generator loss: 0.6919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:22:01] epoch: 0297/5000, reconstruction loss: 0.0309\n",
      "[LOG TRAIN 20200404-19:22:01] epoch: 0297/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:22:01] epoch: 0297/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:22:05] epoch: 0298/5000, reconstruction loss: 0.0309\n",
      "[LOG TRAIN 20200404-19:22:05] epoch: 0298/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:22:05] epoch: 0298/5000, generator loss: 0.6919\n",
      "[LOG TRAIN 20200404-19:22:09] epoch: 0299/5000, reconstruction loss: 0.0308\n",
      "[LOG TRAIN 20200404-19:22:09] epoch: 0299/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:22:09] epoch: 0299/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:22:12] epoch: 0300/5000, reconstruction loss: 0.0308\n",
      "[LOG TRAIN 20200404-19:22:12] epoch: 0300/5000, discriminator loss: 1.3861\n",
      "[LOG TRAIN 20200404-19:22:12] epoch: 0300/5000, generator loss: 0.6920\n",
      "[LOG TRAIN 20200404-19:22:16] epoch: 0301/5000, reconstruction loss: 0.0308\n",
      "[LOG TRAIN 20200404-19:22:16] epoch: 0301/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:22:16] epoch: 0301/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:22:20] epoch: 0302/5000, reconstruction loss: 0.0307\n",
      "[LOG TRAIN 20200404-19:22:20] epoch: 0302/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:22:20] epoch: 0302/5000, generator loss: 0.6921\n",
      "[LOG TRAIN 20200404-19:22:24] epoch: 0303/5000, reconstruction loss: 0.0307\n",
      "[LOG TRAIN 20200404-19:22:24] epoch: 0303/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:22:24] epoch: 0303/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:22:28] epoch: 0304/5000, reconstruction loss: 0.0307\n",
      "[LOG TRAIN 20200404-19:22:28] epoch: 0304/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:22:28] epoch: 0304/5000, generator loss: 0.6922\n",
      "[LOG TRAIN 20200404-19:22:33] epoch: 0305/5000, reconstruction loss: 0.0307\n",
      "[LOG TRAIN 20200404-19:22:33] epoch: 0305/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:22:33] epoch: 0305/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:22:37] epoch: 0306/5000, reconstruction loss: 0.0306\n",
      "[LOG TRAIN 20200404-19:22:37] epoch: 0306/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:22:37] epoch: 0306/5000, generator loss: 0.6923\n",
      "[LOG TRAIN 20200404-19:22:41] epoch: 0307/5000, reconstruction loss: 0.0306\n",
      "[LOG TRAIN 20200404-19:22:41] epoch: 0307/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:22:41] epoch: 0307/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-19:22:45] epoch: 0308/5000, reconstruction loss: 0.0306\n",
      "[LOG TRAIN 20200404-19:22:45] epoch: 0308/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:22:45] epoch: 0308/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:22:48] epoch: 0309/5000, reconstruction loss: 0.0305\n",
      "[LOG TRAIN 20200404-19:22:48] epoch: 0309/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:22:48] epoch: 0309/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:22:52] epoch: 0310/5000, reconstruction loss: 0.0306\n",
      "[LOG TRAIN 20200404-19:22:52] epoch: 0310/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:22:52] epoch: 0310/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:22:56] epoch: 0311/5000, reconstruction loss: 0.0305\n",
      "[LOG TRAIN 20200404-19:22:56] epoch: 0311/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:22:56] epoch: 0311/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:23:00] epoch: 0312/5000, reconstruction loss: 0.0305\n",
      "[LOG TRAIN 20200404-19:23:00] epoch: 0312/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:00] epoch: 0312/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:23:03] epoch: 0313/5000, reconstruction loss: 0.0304\n",
      "[LOG TRAIN 20200404-19:23:03] epoch: 0313/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:03] epoch: 0313/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:23:07] epoch: 0314/5000, reconstruction loss: 0.0304\n",
      "[LOG TRAIN 20200404-19:23:07] epoch: 0314/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:07] epoch: 0314/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:23:11] epoch: 0315/5000, reconstruction loss: 0.0304\n",
      "[LOG TRAIN 20200404-19:23:11] epoch: 0315/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:11] epoch: 0315/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:23:15] epoch: 0316/5000, reconstruction loss: 0.0304\n",
      "[LOG TRAIN 20200404-19:23:15] epoch: 0316/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:15] epoch: 0316/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:23:19] epoch: 0317/5000, reconstruction loss: 0.0304\n",
      "[LOG TRAIN 20200404-19:23:19] epoch: 0317/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:19] epoch: 0317/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:23:23] epoch: 0318/5000, reconstruction loss: 0.0303\n",
      "[LOG TRAIN 20200404-19:23:23] epoch: 0318/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:23] epoch: 0318/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:23:27] epoch: 0319/5000, reconstruction loss: 0.0303\n",
      "[LOG TRAIN 20200404-19:23:27] epoch: 0319/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:27] epoch: 0319/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:23:31] epoch: 0320/5000, reconstruction loss: 0.0303\n",
      "[LOG TRAIN 20200404-19:23:31] epoch: 0320/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:31] epoch: 0320/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:23:35] epoch: 0321/5000, reconstruction loss: 0.0302\n",
      "[LOG TRAIN 20200404-19:23:35] epoch: 0321/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:35] epoch: 0321/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:23:38] epoch: 0322/5000, reconstruction loss: 0.0302\n",
      "[LOG TRAIN 20200404-19:23:38] epoch: 0322/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:38] epoch: 0322/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:23:42] epoch: 0323/5000, reconstruction loss: 0.0302\n",
      "[LOG TRAIN 20200404-19:23:42] epoch: 0323/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:42] epoch: 0323/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:23:46] epoch: 0324/5000, reconstruction loss: 0.0302\n",
      "[LOG TRAIN 20200404-19:23:46] epoch: 0324/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:46] epoch: 0324/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:23:50] epoch: 0325/5000, reconstruction loss: 0.0301\n",
      "[LOG TRAIN 20200404-19:23:50] epoch: 0325/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:50] epoch: 0325/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:23:54] epoch: 0326/5000, reconstruction loss: 0.0301\n",
      "[LOG TRAIN 20200404-19:23:54] epoch: 0326/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:23:54] epoch: 0326/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:23:59] epoch: 0327/5000, reconstruction loss: 0.0301\n",
      "[LOG TRAIN 20200404-19:23:59] epoch: 0327/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:23:59] epoch: 0327/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:03] epoch: 0328/5000, reconstruction loss: 0.0301\n",
      "[LOG TRAIN 20200404-19:24:03] epoch: 0328/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:03] epoch: 0328/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:08] epoch: 0329/5000, reconstruction loss: 0.0301\n",
      "[LOG TRAIN 20200404-19:24:08] epoch: 0329/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:08] epoch: 0329/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:12] epoch: 0330/5000, reconstruction loss: 0.0300\n",
      "[LOG TRAIN 20200404-19:24:12] epoch: 0330/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:12] epoch: 0330/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:17] epoch: 0331/5000, reconstruction loss: 0.0300\n",
      "[LOG TRAIN 20200404-19:24:17] epoch: 0331/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:17] epoch: 0331/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:21] epoch: 0332/5000, reconstruction loss: 0.0300\n",
      "[LOG TRAIN 20200404-19:24:21] epoch: 0332/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:21] epoch: 0332/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:26] epoch: 0333/5000, reconstruction loss: 0.0300\n",
      "[LOG TRAIN 20200404-19:24:26] epoch: 0333/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:26] epoch: 0333/5000, generator loss: 0.6932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:24:30] epoch: 0334/5000, reconstruction loss: 0.0300\n",
      "[LOG TRAIN 20200404-19:24:30] epoch: 0334/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:30] epoch: 0334/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:35] epoch: 0335/5000, reconstruction loss: 0.0299\n",
      "[LOG TRAIN 20200404-19:24:35] epoch: 0335/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:35] epoch: 0335/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:39] epoch: 0336/5000, reconstruction loss: 0.0299\n",
      "[LOG TRAIN 20200404-19:24:39] epoch: 0336/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:39] epoch: 0336/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:44] epoch: 0337/5000, reconstruction loss: 0.0299\n",
      "[LOG TRAIN 20200404-19:24:44] epoch: 0337/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:44] epoch: 0337/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:48] epoch: 0338/5000, reconstruction loss: 0.0298\n",
      "[LOG TRAIN 20200404-19:24:48] epoch: 0338/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:48] epoch: 0338/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:53] epoch: 0339/5000, reconstruction loss: 0.0297\n",
      "[LOG TRAIN 20200404-19:24:53] epoch: 0339/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:53] epoch: 0339/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:24:57] epoch: 0340/5000, reconstruction loss: 0.0297\n",
      "[LOG TRAIN 20200404-19:24:57] epoch: 0340/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:24:57] epoch: 0340/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:25:02] epoch: 0341/5000, reconstruction loss: 0.0298\n",
      "[LOG TRAIN 20200404-19:25:02] epoch: 0341/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:02] epoch: 0341/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:25:06] epoch: 0342/5000, reconstruction loss: 0.0297\n",
      "[LOG TRAIN 20200404-19:25:06] epoch: 0342/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:06] epoch: 0342/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:11] epoch: 0343/5000, reconstruction loss: 0.0296\n",
      "[LOG TRAIN 20200404-19:25:11] epoch: 0343/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:11] epoch: 0343/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:15] epoch: 0344/5000, reconstruction loss: 0.0295\n",
      "[LOG TRAIN 20200404-19:25:15] epoch: 0344/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:15] epoch: 0344/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:20] epoch: 0345/5000, reconstruction loss: 0.0295\n",
      "[LOG TRAIN 20200404-19:25:20] epoch: 0345/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:20] epoch: 0345/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:25] epoch: 0346/5000, reconstruction loss: 0.0295\n",
      "[LOG TRAIN 20200404-19:25:25] epoch: 0346/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:25] epoch: 0346/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:29] epoch: 0347/5000, reconstruction loss: 0.0295\n",
      "[LOG TRAIN 20200404-19:25:29] epoch: 0347/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:29] epoch: 0347/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:34] epoch: 0348/5000, reconstruction loss: 0.0297\n",
      "[LOG TRAIN 20200404-19:25:34] epoch: 0348/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:34] epoch: 0348/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:38] epoch: 0349/5000, reconstruction loss: 0.0295\n",
      "[LOG TRAIN 20200404-19:25:38] epoch: 0349/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:38] epoch: 0349/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:42] epoch: 0350/5000, reconstruction loss: 0.0293\n",
      "[LOG TRAIN 20200404-19:25:42] epoch: 0350/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:42] epoch: 0350/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:47] epoch: 0351/5000, reconstruction loss: 0.0292\n",
      "[LOG TRAIN 20200404-19:25:47] epoch: 0351/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:47] epoch: 0351/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:51] epoch: 0352/5000, reconstruction loss: 0.0292\n",
      "[LOG TRAIN 20200404-19:25:51] epoch: 0352/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:25:51] epoch: 0352/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:25:56] epoch: 0353/5000, reconstruction loss: 0.0291\n",
      "[LOG TRAIN 20200404-19:25:56] epoch: 0353/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:25:56] epoch: 0353/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:00] epoch: 0354/5000, reconstruction loss: 0.0291\n",
      "[LOG TRAIN 20200404-19:26:00] epoch: 0354/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:00] epoch: 0354/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:05] epoch: 0355/5000, reconstruction loss: 0.0291\n",
      "[LOG TRAIN 20200404-19:26:05] epoch: 0355/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:05] epoch: 0355/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:09] epoch: 0356/5000, reconstruction loss: 0.0290\n",
      "[LOG TRAIN 20200404-19:26:09] epoch: 0356/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:09] epoch: 0356/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:14] epoch: 0357/5000, reconstruction loss: 0.0290\n",
      "[LOG TRAIN 20200404-19:26:14] epoch: 0357/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:14] epoch: 0357/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:18] epoch: 0358/5000, reconstruction loss: 0.0292\n",
      "[LOG TRAIN 20200404-19:26:18] epoch: 0358/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:18] epoch: 0358/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:23] epoch: 0359/5000, reconstruction loss: 0.0292\n",
      "[LOG TRAIN 20200404-19:26:23] epoch: 0359/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:23] epoch: 0359/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:27] epoch: 0360/5000, reconstruction loss: 0.0289\n",
      "[LOG TRAIN 20200404-19:26:27] epoch: 0360/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:27] epoch: 0360/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:32] epoch: 0361/5000, reconstruction loss: 0.0288\n",
      "[LOG TRAIN 20200404-19:26:32] epoch: 0361/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:32] epoch: 0361/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:36] epoch: 0362/5000, reconstruction loss: 0.0287\n",
      "[LOG TRAIN 20200404-19:26:36] epoch: 0362/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:36] epoch: 0362/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:41] epoch: 0363/5000, reconstruction loss: 0.0287\n",
      "[LOG TRAIN 20200404-19:26:41] epoch: 0363/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:41] epoch: 0363/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:45] epoch: 0364/5000, reconstruction loss: 0.0286\n",
      "[LOG TRAIN 20200404-19:26:45] epoch: 0364/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:45] epoch: 0364/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:50] epoch: 0365/5000, reconstruction loss: 0.0286\n",
      "[LOG TRAIN 20200404-19:26:50] epoch: 0365/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:50] epoch: 0365/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:54] epoch: 0366/5000, reconstruction loss: 0.0288\n",
      "[LOG TRAIN 20200404-19:26:54] epoch: 0366/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:54] epoch: 0366/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:26:59] epoch: 0367/5000, reconstruction loss: 0.0287\n",
      "[LOG TRAIN 20200404-19:26:59] epoch: 0367/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:26:59] epoch: 0367/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:27:03] epoch: 0368/5000, reconstruction loss: 0.0285\n",
      "[LOG TRAIN 20200404-19:27:03] epoch: 0368/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:03] epoch: 0368/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:27:08] epoch: 0369/5000, reconstruction loss: 0.0285\n",
      "[LOG TRAIN 20200404-19:27:08] epoch: 0369/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:08] epoch: 0369/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:27:13] epoch: 0370/5000, reconstruction loss: 0.0286\n",
      "[LOG TRAIN 20200404-19:27:13] epoch: 0370/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:13] epoch: 0370/5000, generator loss: 0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:27:17] epoch: 0371/5000, reconstruction loss: 0.0284\n",
      "[LOG TRAIN 20200404-19:27:17] epoch: 0371/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:17] epoch: 0371/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:27:21] epoch: 0372/5000, reconstruction loss: 0.0284\n",
      "[LOG TRAIN 20200404-19:27:21] epoch: 0372/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:21] epoch: 0372/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:27:26] epoch: 0373/5000, reconstruction loss: 0.0285\n",
      "[LOG TRAIN 20200404-19:27:26] epoch: 0373/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:26] epoch: 0373/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:27:31] epoch: 0374/5000, reconstruction loss: 0.0284\n",
      "[LOG TRAIN 20200404-19:27:31] epoch: 0374/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:31] epoch: 0374/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:27:35] epoch: 0375/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:27:35] epoch: 0375/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:35] epoch: 0375/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:27:40] epoch: 0376/5000, reconstruction loss: 0.0284\n",
      "[LOG TRAIN 20200404-19:27:40] epoch: 0376/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:40] epoch: 0376/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:27:44] epoch: 0377/5000, reconstruction loss: 0.0284\n",
      "[LOG TRAIN 20200404-19:27:44] epoch: 0377/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:44] epoch: 0377/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:27:49] epoch: 0378/5000, reconstruction loss: 0.0284\n",
      "[LOG TRAIN 20200404-19:27:49] epoch: 0378/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:27:49] epoch: 0378/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:27:53] epoch: 0379/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:27:53] epoch: 0379/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:27:53] epoch: 0379/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:27:58] epoch: 0380/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:27:58] epoch: 0380/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:27:58] epoch: 0380/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:28:02] epoch: 0381/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:28:02] epoch: 0381/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:02] epoch: 0381/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:28:08] epoch: 0382/5000, reconstruction loss: 0.0284\n",
      "[LOG TRAIN 20200404-19:28:08] epoch: 0382/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:08] epoch: 0382/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:28:14] epoch: 0383/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:28:14] epoch: 0383/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:14] epoch: 0383/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:28:20] epoch: 0384/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:28:20] epoch: 0384/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:20] epoch: 0384/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:28:25] epoch: 0385/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:28:25] epoch: 0385/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:25] epoch: 0385/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:28:30] epoch: 0386/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:28:30] epoch: 0386/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:30] epoch: 0386/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:28:35] epoch: 0387/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:28:35] epoch: 0387/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:35] epoch: 0387/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:28:41] epoch: 0388/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:28:41] epoch: 0388/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:41] epoch: 0388/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:28:46] epoch: 0389/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:28:46] epoch: 0389/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:46] epoch: 0389/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:28:51] epoch: 0390/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:28:51] epoch: 0390/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:51] epoch: 0390/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:28:57] epoch: 0391/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:28:57] epoch: 0391/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:28:57] epoch: 0391/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:29:02] epoch: 0392/5000, reconstruction loss: 0.0285\n",
      "[LOG TRAIN 20200404-19:29:02] epoch: 0392/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:02] epoch: 0392/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:29:07] epoch: 0393/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:29:07] epoch: 0393/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:07] epoch: 0393/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:29:12] epoch: 0394/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:29:12] epoch: 0394/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:12] epoch: 0394/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:29:16] epoch: 0395/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:29:16] epoch: 0395/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:16] epoch: 0395/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:29:21] epoch: 0396/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:29:21] epoch: 0396/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:21] epoch: 0396/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:29:25] epoch: 0397/5000, reconstruction loss: 0.0286\n",
      "[LOG TRAIN 20200404-19:29:25] epoch: 0397/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:25] epoch: 0397/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:29:30] epoch: 0398/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:29:30] epoch: 0398/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:30] epoch: 0398/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:29:34] epoch: 0399/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:29:34] epoch: 0399/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:34] epoch: 0399/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:29:38] epoch: 0400/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:29:38] epoch: 0400/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:38] epoch: 0400/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:29:43] epoch: 0401/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:29:43] epoch: 0401/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:43] epoch: 0401/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:29:48] epoch: 0402/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:29:48] epoch: 0402/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:48] epoch: 0402/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:29:53] epoch: 0403/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:29:53] epoch: 0403/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:53] epoch: 0403/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:29:59] epoch: 0404/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:29:59] epoch: 0404/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:29:59] epoch: 0404/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:30:04] epoch: 0405/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:30:04] epoch: 0405/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:04] epoch: 0405/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:30:10] epoch: 0406/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:30:10] epoch: 0406/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:10] epoch: 0406/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:30:15] epoch: 0407/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:30:15] epoch: 0407/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:15] epoch: 0407/5000, generator loss: 0.6926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:30:20] epoch: 0408/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:30:20] epoch: 0408/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:20] epoch: 0408/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:30:25] epoch: 0409/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:30:25] epoch: 0409/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:25] epoch: 0409/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:30:31] epoch: 0410/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:30:31] epoch: 0410/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:31] epoch: 0410/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:30:36] epoch: 0411/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:30:36] epoch: 0411/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:36] epoch: 0411/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:30:41] epoch: 0412/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:30:41] epoch: 0412/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:41] epoch: 0412/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:30:47] epoch: 0413/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:30:47] epoch: 0413/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:47] epoch: 0413/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:30:52] epoch: 0414/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:30:52] epoch: 0414/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:52] epoch: 0414/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:30:57] epoch: 0415/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:30:57] epoch: 0415/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:30:57] epoch: 0415/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:31:03] epoch: 0416/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:31:03] epoch: 0416/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:03] epoch: 0416/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:31:08] epoch: 0417/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:31:08] epoch: 0417/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:08] epoch: 0417/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:31:13] epoch: 0418/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:31:13] epoch: 0418/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:13] epoch: 0418/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:31:18] epoch: 0419/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:31:18] epoch: 0419/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:18] epoch: 0419/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:31:23] epoch: 0420/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:31:23] epoch: 0420/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:23] epoch: 0420/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:31:28] epoch: 0421/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:31:28] epoch: 0421/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:28] epoch: 0421/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:31:33] epoch: 0422/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:31:33] epoch: 0422/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:33] epoch: 0422/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:31:37] epoch: 0423/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:31:37] epoch: 0423/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:37] epoch: 0423/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:31:42] epoch: 0424/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:31:42] epoch: 0424/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:42] epoch: 0424/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-19:31:46] epoch: 0425/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:31:46] epoch: 0425/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:46] epoch: 0425/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:31:51] epoch: 0426/5000, reconstruction loss: 0.0282\n",
      "[LOG TRAIN 20200404-19:31:51] epoch: 0426/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:51] epoch: 0426/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:31:55] epoch: 0427/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:31:55] epoch: 0427/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:55] epoch: 0427/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:31:59] epoch: 0428/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:31:59] epoch: 0428/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:31:59] epoch: 0428/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:32:04] epoch: 0429/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:32:04] epoch: 0429/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:04] epoch: 0429/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:32:08] epoch: 0430/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:32:08] epoch: 0430/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:08] epoch: 0430/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:32:13] epoch: 0431/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:32:13] epoch: 0431/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:13] epoch: 0431/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:32:17] epoch: 0432/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:32:17] epoch: 0432/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:17] epoch: 0432/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:32:22] epoch: 0433/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:32:22] epoch: 0433/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:22] epoch: 0433/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:32:26] epoch: 0434/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:32:26] epoch: 0434/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:26] epoch: 0434/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:32:30] epoch: 0435/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:32:30] epoch: 0435/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:30] epoch: 0435/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:32:35] epoch: 0436/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:32:35] epoch: 0436/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:35] epoch: 0436/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:32:40] epoch: 0437/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:32:40] epoch: 0437/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:40] epoch: 0437/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:32:44] epoch: 0438/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:32:44] epoch: 0438/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:44] epoch: 0438/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:32:48] epoch: 0439/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:32:48] epoch: 0439/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:48] epoch: 0439/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:32:53] epoch: 0440/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:32:53] epoch: 0440/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:53] epoch: 0440/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:32:57] epoch: 0441/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:32:57] epoch: 0441/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:32:57] epoch: 0441/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:33:02] epoch: 0442/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:33:02] epoch: 0442/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:02] epoch: 0442/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:33:07] epoch: 0443/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:33:07] epoch: 0443/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:07] epoch: 0443/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:33:12] epoch: 0444/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:33:12] epoch: 0444/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:12] epoch: 0444/5000, generator loss: 0.6928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:33:17] epoch: 0445/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:33:17] epoch: 0445/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:17] epoch: 0445/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:33:23] epoch: 0446/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:33:23] epoch: 0446/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:23] epoch: 0446/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:33:28] epoch: 0447/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:33:28] epoch: 0447/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:28] epoch: 0447/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:33:33] epoch: 0448/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:33:33] epoch: 0448/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:33] epoch: 0448/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:33:39] epoch: 0449/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:33:39] epoch: 0449/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:39] epoch: 0449/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:33:44] epoch: 0450/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:33:44] epoch: 0450/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:44] epoch: 0450/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:33:49] epoch: 0451/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:33:49] epoch: 0451/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:49] epoch: 0451/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:33:54] epoch: 0452/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:33:54] epoch: 0452/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:54] epoch: 0452/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:33:59] epoch: 0453/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:33:59] epoch: 0453/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:33:59] epoch: 0453/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:34:03] epoch: 0454/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:34:03] epoch: 0454/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:03] epoch: 0454/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:34:08] epoch: 0455/5000, reconstruction loss: 0.0280\n",
      "[LOG TRAIN 20200404-19:34:08] epoch: 0455/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:08] epoch: 0455/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:34:13] epoch: 0456/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:34:13] epoch: 0456/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:13] epoch: 0456/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:34:17] epoch: 0457/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:34:17] epoch: 0457/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:17] epoch: 0457/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:34:22] epoch: 0458/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:34:22] epoch: 0458/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:22] epoch: 0458/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:34:26] epoch: 0459/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:34:26] epoch: 0459/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:26] epoch: 0459/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:34:32] epoch: 0460/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:34:32] epoch: 0460/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:32] epoch: 0460/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:34:36] epoch: 0461/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:34:36] epoch: 0461/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:36] epoch: 0461/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:34:41] epoch: 0462/5000, reconstruction loss: 0.0277\n",
      "[LOG TRAIN 20200404-19:34:41] epoch: 0462/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:41] epoch: 0462/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:34:45] epoch: 0463/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:34:45] epoch: 0463/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:45] epoch: 0463/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:34:51] epoch: 0464/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:34:51] epoch: 0464/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:51] epoch: 0464/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:34:56] epoch: 0465/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:34:56] epoch: 0465/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:34:56] epoch: 0465/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:35:01] epoch: 0466/5000, reconstruction loss: 0.0277\n",
      "[LOG TRAIN 20200404-19:35:01] epoch: 0466/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:01] epoch: 0466/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:35:06] epoch: 0467/5000, reconstruction loss: 0.0277\n",
      "[LOG TRAIN 20200404-19:35:06] epoch: 0467/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:06] epoch: 0467/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:35:12] epoch: 0468/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:35:12] epoch: 0468/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:12] epoch: 0468/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:35:17] epoch: 0469/5000, reconstruction loss: 0.0279\n",
      "[LOG TRAIN 20200404-19:35:17] epoch: 0469/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:17] epoch: 0469/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:35:22] epoch: 0470/5000, reconstruction loss: 0.0277\n",
      "[LOG TRAIN 20200404-19:35:22] epoch: 0470/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:22] epoch: 0470/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:35:27] epoch: 0471/5000, reconstruction loss: 0.0276\n",
      "[LOG TRAIN 20200404-19:35:27] epoch: 0471/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:27] epoch: 0471/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:35:32] epoch: 0472/5000, reconstruction loss: 0.0276\n",
      "[LOG TRAIN 20200404-19:35:32] epoch: 0472/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:32] epoch: 0472/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:35:38] epoch: 0473/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:35:38] epoch: 0473/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:38] epoch: 0473/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:35:43] epoch: 0474/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:35:43] epoch: 0474/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:43] epoch: 0474/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:35:48] epoch: 0475/5000, reconstruction loss: 0.0276\n",
      "[LOG TRAIN 20200404-19:35:48] epoch: 0475/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:48] epoch: 0475/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:35:53] epoch: 0476/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:35:53] epoch: 0476/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:53] epoch: 0476/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:35:59] epoch: 0477/5000, reconstruction loss: 0.0276\n",
      "[LOG TRAIN 20200404-19:35:59] epoch: 0477/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:35:59] epoch: 0477/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:36:05] epoch: 0478/5000, reconstruction loss: 0.0276\n",
      "[LOG TRAIN 20200404-19:36:05] epoch: 0478/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:36:05] epoch: 0478/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:36:10] epoch: 0479/5000, reconstruction loss: 0.0275\n",
      "[LOG TRAIN 20200404-19:36:10] epoch: 0479/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:36:10] epoch: 0479/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:36:15] epoch: 0480/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:36:15] epoch: 0480/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:36:15] epoch: 0480/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:36:20] epoch: 0481/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:36:20] epoch: 0481/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:36:20] epoch: 0481/5000, generator loss: 0.6926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:36:25] epoch: 0482/5000, reconstruction loss: 0.0275\n",
      "[LOG TRAIN 20200404-19:36:25] epoch: 0482/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:36:25] epoch: 0482/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:36:31] epoch: 0483/5000, reconstruction loss: 0.0276\n",
      "[LOG TRAIN 20200404-19:36:31] epoch: 0483/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:36:31] epoch: 0483/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:36:36] epoch: 0484/5000, reconstruction loss: 0.0275\n",
      "[LOG TRAIN 20200404-19:36:36] epoch: 0484/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:36:36] epoch: 0484/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:36:41] epoch: 0485/5000, reconstruction loss: 0.0275\n",
      "[LOG TRAIN 20200404-19:36:41] epoch: 0485/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:36:41] epoch: 0485/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:36:47] epoch: 0486/5000, reconstruction loss: 0.0274\n",
      "[LOG TRAIN 20200404-19:36:47] epoch: 0486/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:36:47] epoch: 0486/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-19:36:52] epoch: 0487/5000, reconstruction loss: 0.0274\n",
      "[LOG TRAIN 20200404-19:36:52] epoch: 0487/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:36:52] epoch: 0487/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:36:57] epoch: 0488/5000, reconstruction loss: 0.0274\n",
      "[LOG TRAIN 20200404-19:36:57] epoch: 0488/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:36:57] epoch: 0488/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:37:02] epoch: 0489/5000, reconstruction loss: 0.0274\n",
      "[LOG TRAIN 20200404-19:37:02] epoch: 0489/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:02] epoch: 0489/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:37:08] epoch: 0490/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-19:37:08] epoch: 0490/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:08] epoch: 0490/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:37:13] epoch: 0491/5000, reconstruction loss: 0.0275\n",
      "[LOG TRAIN 20200404-19:37:13] epoch: 0491/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:13] epoch: 0491/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-19:37:18] epoch: 0492/5000, reconstruction loss: 0.0275\n",
      "[LOG TRAIN 20200404-19:37:18] epoch: 0492/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:18] epoch: 0492/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:37:23] epoch: 0493/5000, reconstruction loss: 0.0274\n",
      "[LOG TRAIN 20200404-19:37:23] epoch: 0493/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:23] epoch: 0493/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:37:28] epoch: 0494/5000, reconstruction loss: 0.0273\n",
      "[LOG TRAIN 20200404-19:37:28] epoch: 0494/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:28] epoch: 0494/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:37:34] epoch: 0495/5000, reconstruction loss: 0.0273\n",
      "[LOG TRAIN 20200404-19:37:34] epoch: 0495/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:34] epoch: 0495/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-19:37:39] epoch: 0496/5000, reconstruction loss: 0.0272\n",
      "[LOG TRAIN 20200404-19:37:39] epoch: 0496/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:39] epoch: 0496/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:37:44] epoch: 0497/5000, reconstruction loss: 0.0273\n",
      "[LOG TRAIN 20200404-19:37:44] epoch: 0497/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:44] epoch: 0497/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:37:50] epoch: 0498/5000, reconstruction loss: 0.0273\n",
      "[LOG TRAIN 20200404-19:37:50] epoch: 0498/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:50] epoch: 0498/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:37:55] epoch: 0499/5000, reconstruction loss: 0.0273\n",
      "[LOG TRAIN 20200404-19:37:55] epoch: 0499/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:37:55] epoch: 0499/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-19:38:00] epoch: 0500/5000, reconstruction loss: 0.0272\n",
      "[LOG TRAIN 20200404-19:38:00] epoch: 0500/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:00] epoch: 0500/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:38:05] epoch: 0501/5000, reconstruction loss: 0.0272\n",
      "[LOG TRAIN 20200404-19:38:05] epoch: 0501/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:05] epoch: 0501/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:38:11] epoch: 0502/5000, reconstruction loss: 0.0271\n",
      "[LOG TRAIN 20200404-19:38:11] epoch: 0502/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:11] epoch: 0502/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:38:16] epoch: 0503/5000, reconstruction loss: 0.0271\n",
      "[LOG TRAIN 20200404-19:38:16] epoch: 0503/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:16] epoch: 0503/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:38:21] epoch: 0504/5000, reconstruction loss: 0.0272\n",
      "[LOG TRAIN 20200404-19:38:21] epoch: 0504/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:21] epoch: 0504/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:38:26] epoch: 0505/5000, reconstruction loss: 0.0271\n",
      "[LOG TRAIN 20200404-19:38:26] epoch: 0505/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:26] epoch: 0505/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:38:32] epoch: 0506/5000, reconstruction loss: 0.0270\n",
      "[LOG TRAIN 20200404-19:38:32] epoch: 0506/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:32] epoch: 0506/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:38:37] epoch: 0507/5000, reconstruction loss: 0.0270\n",
      "[LOG TRAIN 20200404-19:38:37] epoch: 0507/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:37] epoch: 0507/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:38:42] epoch: 0508/5000, reconstruction loss: 0.0270\n",
      "[LOG TRAIN 20200404-19:38:42] epoch: 0508/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:42] epoch: 0508/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:38:48] epoch: 0509/5000, reconstruction loss: 0.0271\n",
      "[LOG TRAIN 20200404-19:38:48] epoch: 0509/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:48] epoch: 0509/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:38:53] epoch: 0510/5000, reconstruction loss: 0.0272\n",
      "[LOG TRAIN 20200404-19:38:53] epoch: 0510/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:53] epoch: 0510/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:38:58] epoch: 0511/5000, reconstruction loss: 0.0269\n",
      "[LOG TRAIN 20200404-19:38:58] epoch: 0511/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:38:58] epoch: 0511/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:39:04] epoch: 0512/5000, reconstruction loss: 0.0269\n",
      "[LOG TRAIN 20200404-19:39:04] epoch: 0512/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:04] epoch: 0512/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:39:09] epoch: 0513/5000, reconstruction loss: 0.0269\n",
      "[LOG TRAIN 20200404-19:39:09] epoch: 0513/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:09] epoch: 0513/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:39:14] epoch: 0514/5000, reconstruction loss: 0.0269\n",
      "[LOG TRAIN 20200404-19:39:14] epoch: 0514/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:14] epoch: 0514/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:39:20] epoch: 0515/5000, reconstruction loss: 0.0272\n",
      "[LOG TRAIN 20200404-19:39:20] epoch: 0515/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:20] epoch: 0515/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:39:25] epoch: 0516/5000, reconstruction loss: 0.0268\n",
      "[LOG TRAIN 20200404-19:39:25] epoch: 0516/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:25] epoch: 0516/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:39:30] epoch: 0517/5000, reconstruction loss: 0.0267\n",
      "[LOG TRAIN 20200404-19:39:30] epoch: 0517/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:30] epoch: 0517/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:39:35] epoch: 0518/5000, reconstruction loss: 0.0267\n",
      "[LOG TRAIN 20200404-19:39:35] epoch: 0518/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:35] epoch: 0518/5000, generator loss: 0.6930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:39:41] epoch: 0519/5000, reconstruction loss: 0.0266\n",
      "[LOG TRAIN 20200404-19:39:41] epoch: 0519/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:41] epoch: 0519/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:39:46] epoch: 0520/5000, reconstruction loss: 0.0266\n",
      "[LOG TRAIN 20200404-19:39:46] epoch: 0520/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:46] epoch: 0520/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:39:51] epoch: 0521/5000, reconstruction loss: 0.0266\n",
      "[LOG TRAIN 20200404-19:39:51] epoch: 0521/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:51] epoch: 0521/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:39:56] epoch: 0522/5000, reconstruction loss: 0.0269\n",
      "[LOG TRAIN 20200404-19:39:56] epoch: 0522/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:39:56] epoch: 0522/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-19:40:02] epoch: 0523/5000, reconstruction loss: 0.0271\n",
      "[LOG TRAIN 20200404-19:40:02] epoch: 0523/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:40:02] epoch: 0523/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:40:07] epoch: 0524/5000, reconstruction loss: 0.0267\n",
      "[LOG TRAIN 20200404-19:40:07] epoch: 0524/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:40:07] epoch: 0524/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:40:12] epoch: 0525/5000, reconstruction loss: 0.0265\n",
      "[LOG TRAIN 20200404-19:40:12] epoch: 0525/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:40:12] epoch: 0525/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:40:17] epoch: 0526/5000, reconstruction loss: 0.0264\n",
      "[LOG TRAIN 20200404-19:40:17] epoch: 0526/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:40:17] epoch: 0526/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:40:23] epoch: 0527/5000, reconstruction loss: 0.0263\n",
      "[LOG TRAIN 20200404-19:40:23] epoch: 0527/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:40:23] epoch: 0527/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:40:28] epoch: 0528/5000, reconstruction loss: 0.0263\n",
      "[LOG TRAIN 20200404-19:40:28] epoch: 0528/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:40:28] epoch: 0528/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:40:33] epoch: 0529/5000, reconstruction loss: 0.0263\n",
      "[LOG TRAIN 20200404-19:40:33] epoch: 0529/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:40:33] epoch: 0529/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:40:38] epoch: 0530/5000, reconstruction loss: 0.0262\n",
      "[LOG TRAIN 20200404-19:40:38] epoch: 0530/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:40:38] epoch: 0530/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:40:44] epoch: 0531/5000, reconstruction loss: 0.0262\n",
      "[LOG TRAIN 20200404-19:40:44] epoch: 0531/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:40:44] epoch: 0531/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:40:49] epoch: 0532/5000, reconstruction loss: 0.0261\n",
      "[LOG TRAIN 20200404-19:40:49] epoch: 0532/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:40:49] epoch: 0532/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-19:40:54] epoch: 0533/5000, reconstruction loss: 0.0263\n",
      "[LOG TRAIN 20200404-19:40:54] epoch: 0533/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:40:54] epoch: 0533/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:40:59] epoch: 0534/5000, reconstruction loss: 0.0265\n",
      "[LOG TRAIN 20200404-19:40:59] epoch: 0534/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:40:59] epoch: 0534/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:41:05] epoch: 0535/5000, reconstruction loss: 0.0260\n",
      "[LOG TRAIN 20200404-19:41:05] epoch: 0535/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:41:05] epoch: 0535/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-19:41:10] epoch: 0536/5000, reconstruction loss: 0.0261\n",
      "[LOG TRAIN 20200404-19:41:10] epoch: 0536/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:41:10] epoch: 0536/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:41:15] epoch: 0537/5000, reconstruction loss: 0.0261\n",
      "[LOG TRAIN 20200404-19:41:15] epoch: 0537/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:41:15] epoch: 0537/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:41:20] epoch: 0538/5000, reconstruction loss: 0.0260\n",
      "[LOG TRAIN 20200404-19:41:20] epoch: 0538/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:41:20] epoch: 0538/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:41:26] epoch: 0539/5000, reconstruction loss: 0.0259\n",
      "[LOG TRAIN 20200404-19:41:26] epoch: 0539/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:41:26] epoch: 0539/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-19:41:31] epoch: 0540/5000, reconstruction loss: 0.0260\n",
      "[LOG TRAIN 20200404-19:41:31] epoch: 0540/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:41:31] epoch: 0540/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-19:41:36] epoch: 0541/5000, reconstruction loss: 0.0264\n",
      "[LOG TRAIN 20200404-19:41:36] epoch: 0541/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:41:36] epoch: 0541/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-19:41:42] epoch: 0542/5000, reconstruction loss: 0.0258\n",
      "[LOG TRAIN 20200404-19:41:42] epoch: 0542/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:41:42] epoch: 0542/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-19:41:47] epoch: 0543/5000, reconstruction loss: 0.0259\n",
      "[LOG TRAIN 20200404-19:41:47] epoch: 0543/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:41:47] epoch: 0543/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:41:53] epoch: 0544/5000, reconstruction loss: 0.0257\n",
      "[LOG TRAIN 20200404-19:41:53] epoch: 0544/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:41:53] epoch: 0544/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:42:02] epoch: 0545/5000, reconstruction loss: 0.0257\n",
      "[LOG TRAIN 20200404-19:42:02] epoch: 0545/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:42:02] epoch: 0545/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:42:10] epoch: 0546/5000, reconstruction loss: 0.0258\n",
      "[LOG TRAIN 20200404-19:42:10] epoch: 0546/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:42:10] epoch: 0546/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:42:17] epoch: 0547/5000, reconstruction loss: 0.0261\n",
      "[LOG TRAIN 20200404-19:42:17] epoch: 0547/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:42:17] epoch: 0547/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:42:23] epoch: 0548/5000, reconstruction loss: 0.0256\n",
      "[LOG TRAIN 20200404-19:42:23] epoch: 0548/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:42:23] epoch: 0548/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:42:29] epoch: 0549/5000, reconstruction loss: 0.0257\n",
      "[LOG TRAIN 20200404-19:42:29] epoch: 0549/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:42:29] epoch: 0549/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:42:35] epoch: 0550/5000, reconstruction loss: 0.0257\n",
      "[LOG TRAIN 20200404-19:42:35] epoch: 0550/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:42:35] epoch: 0550/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:42:42] epoch: 0551/5000, reconstruction loss: 0.0255\n",
      "[LOG TRAIN 20200404-19:42:42] epoch: 0551/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:42:42] epoch: 0551/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:42:48] epoch: 0552/5000, reconstruction loss: 0.0255\n",
      "[LOG TRAIN 20200404-19:42:48] epoch: 0552/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:42:48] epoch: 0552/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:42:54] epoch: 0553/5000, reconstruction loss: 0.0257\n",
      "[LOG TRAIN 20200404-19:42:54] epoch: 0553/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:42:54] epoch: 0553/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:00] epoch: 0554/5000, reconstruction loss: 0.0258\n",
      "[LOG TRAIN 20200404-19:43:00] epoch: 0554/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:00] epoch: 0554/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:06] epoch: 0555/5000, reconstruction loss: 0.0255\n",
      "[LOG TRAIN 20200404-19:43:06] epoch: 0555/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:06] epoch: 0555/5000, generator loss: 0.6937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:43:11] epoch: 0556/5000, reconstruction loss: 0.0255\n",
      "[LOG TRAIN 20200404-19:43:11] epoch: 0556/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:11] epoch: 0556/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:17] epoch: 0557/5000, reconstruction loss: 0.0253\n",
      "[LOG TRAIN 20200404-19:43:17] epoch: 0557/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:17] epoch: 0557/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:22] epoch: 0558/5000, reconstruction loss: 0.0253\n",
      "[LOG TRAIN 20200404-19:43:22] epoch: 0558/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:22] epoch: 0558/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:27] epoch: 0559/5000, reconstruction loss: 0.0254\n",
      "[LOG TRAIN 20200404-19:43:27] epoch: 0559/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:27] epoch: 0559/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:33] epoch: 0560/5000, reconstruction loss: 0.0260\n",
      "[LOG TRAIN 20200404-19:43:33] epoch: 0560/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:33] epoch: 0560/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:38] epoch: 0561/5000, reconstruction loss: 0.0258\n",
      "[LOG TRAIN 20200404-19:43:38] epoch: 0561/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:38] epoch: 0561/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:43] epoch: 0562/5000, reconstruction loss: 0.0254\n",
      "[LOG TRAIN 20200404-19:43:43] epoch: 0562/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:43] epoch: 0562/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:49] epoch: 0563/5000, reconstruction loss: 0.0252\n",
      "[LOG TRAIN 20200404-19:43:49] epoch: 0563/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:49] epoch: 0563/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:54] epoch: 0564/5000, reconstruction loss: 0.0252\n",
      "[LOG TRAIN 20200404-19:43:54] epoch: 0564/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:54] epoch: 0564/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:43:59] epoch: 0565/5000, reconstruction loss: 0.0251\n",
      "[LOG TRAIN 20200404-19:43:59] epoch: 0565/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:43:59] epoch: 0565/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:44:04] epoch: 0566/5000, reconstruction loss: 0.0250\n",
      "[LOG TRAIN 20200404-19:44:04] epoch: 0566/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:44:04] epoch: 0566/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:44:10] epoch: 0567/5000, reconstruction loss: 0.0251\n",
      "[LOG TRAIN 20200404-19:44:10] epoch: 0567/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:44:10] epoch: 0567/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:44:15] epoch: 0568/5000, reconstruction loss: 0.0251\n",
      "[LOG TRAIN 20200404-19:44:15] epoch: 0568/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:44:15] epoch: 0568/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:44:20] epoch: 0569/5000, reconstruction loss: 0.0253\n",
      "[LOG TRAIN 20200404-19:44:20] epoch: 0569/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:44:20] epoch: 0569/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:44:25] epoch: 0570/5000, reconstruction loss: 0.0261\n",
      "[LOG TRAIN 20200404-19:44:25] epoch: 0570/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:44:25] epoch: 0570/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:44:31] epoch: 0571/5000, reconstruction loss: 0.0252\n",
      "[LOG TRAIN 20200404-19:44:31] epoch: 0571/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:44:31] epoch: 0571/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:44:36] epoch: 0572/5000, reconstruction loss: 0.0250\n",
      "[LOG TRAIN 20200404-19:44:36] epoch: 0572/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:44:36] epoch: 0572/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:44:42] epoch: 0573/5000, reconstruction loss: 0.0249\n",
      "[LOG TRAIN 20200404-19:44:42] epoch: 0573/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:44:42] epoch: 0573/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:44:47] epoch: 0574/5000, reconstruction loss: 0.0249\n",
      "[LOG TRAIN 20200404-19:44:47] epoch: 0574/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:44:47] epoch: 0574/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:44:52] epoch: 0575/5000, reconstruction loss: 0.0248\n",
      "[LOG TRAIN 20200404-19:44:52] epoch: 0575/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:44:52] epoch: 0575/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:44:58] epoch: 0576/5000, reconstruction loss: 0.0248\n",
      "[LOG TRAIN 20200404-19:44:58] epoch: 0576/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:44:58] epoch: 0576/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:45:05] epoch: 0577/5000, reconstruction loss: 0.0248\n",
      "[LOG TRAIN 20200404-19:45:05] epoch: 0577/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:45:05] epoch: 0577/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:45:12] epoch: 0578/5000, reconstruction loss: 0.0248\n",
      "[LOG TRAIN 20200404-19:45:12] epoch: 0578/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:45:12] epoch: 0578/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:45:19] epoch: 0579/5000, reconstruction loss: 0.0248\n",
      "[LOG TRAIN 20200404-19:45:19] epoch: 0579/5000, discriminator loss: 1.3860\n",
      "[LOG TRAIN 20200404-19:45:19] epoch: 0579/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:45:26] epoch: 0580/5000, reconstruction loss: 0.0304\n",
      "[LOG TRAIN 20200404-19:45:26] epoch: 0580/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:45:26] epoch: 0580/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:45:32] epoch: 0581/5000, reconstruction loss: 0.0281\n",
      "[LOG TRAIN 20200404-19:45:32] epoch: 0581/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-19:45:32] epoch: 0581/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-19:45:38] epoch: 0582/5000, reconstruction loss: 0.0339\n",
      "[LOG TRAIN 20200404-19:45:38] epoch: 0582/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-19:45:38] epoch: 0582/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-19:45:44] epoch: 0583/5000, reconstruction loss: 0.0343\n",
      "[LOG TRAIN 20200404-19:45:44] epoch: 0583/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-19:45:44] epoch: 0583/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:45:51] epoch: 0584/5000, reconstruction loss: 0.0283\n",
      "[LOG TRAIN 20200404-19:45:51] epoch: 0584/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-19:45:51] epoch: 0584/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-19:45:56] epoch: 0585/5000, reconstruction loss: 0.0263\n",
      "[LOG TRAIN 20200404-19:45:56] epoch: 0585/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-19:45:56] epoch: 0585/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-19:46:03] epoch: 0586/5000, reconstruction loss: 0.0253\n",
      "[LOG TRAIN 20200404-19:46:03] epoch: 0586/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-19:46:03] epoch: 0586/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:46:09] epoch: 0587/5000, reconstruction loss: 0.0250\n",
      "[LOG TRAIN 20200404-19:46:09] epoch: 0587/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-19:46:09] epoch: 0587/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-19:46:15] epoch: 0588/5000, reconstruction loss: 0.0248\n",
      "[LOG TRAIN 20200404-19:46:15] epoch: 0588/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-19:46:15] epoch: 0588/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-19:46:20] epoch: 0589/5000, reconstruction loss: 0.0247\n",
      "[LOG TRAIN 20200404-19:46:20] epoch: 0589/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-19:46:20] epoch: 0589/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-19:46:26] epoch: 0590/5000, reconstruction loss: 0.0247\n",
      "[LOG TRAIN 20200404-19:46:26] epoch: 0590/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-19:46:26] epoch: 0590/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-19:46:31] epoch: 0591/5000, reconstruction loss: 0.0247\n",
      "[LOG TRAIN 20200404-19:46:31] epoch: 0591/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-19:46:31] epoch: 0591/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-19:46:36] epoch: 0592/5000, reconstruction loss: 0.0246\n",
      "[LOG TRAIN 20200404-19:46:36] epoch: 0592/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:46:36] epoch: 0592/5000, generator loss: 0.6938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:46:42] epoch: 0593/5000, reconstruction loss: 0.0246\n",
      "[LOG TRAIN 20200404-19:46:42] epoch: 0593/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:46:42] epoch: 0593/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-19:46:47] epoch: 0594/5000, reconstruction loss: 0.0246\n",
      "[LOG TRAIN 20200404-19:46:47] epoch: 0594/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:46:47] epoch: 0594/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-19:46:52] epoch: 0595/5000, reconstruction loss: 0.0245\n",
      "[LOG TRAIN 20200404-19:46:52] epoch: 0595/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:46:52] epoch: 0595/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-19:46:57] epoch: 0596/5000, reconstruction loss: 0.0245\n",
      "[LOG TRAIN 20200404-19:46:57] epoch: 0596/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:46:57] epoch: 0596/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-19:47:03] epoch: 0597/5000, reconstruction loss: 0.0244\n",
      "[LOG TRAIN 20200404-19:47:03] epoch: 0597/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:47:03] epoch: 0597/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-19:47:08] epoch: 0598/5000, reconstruction loss: 0.0244\n",
      "[LOG TRAIN 20200404-19:47:08] epoch: 0598/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:47:08] epoch: 0598/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-19:47:13] epoch: 0599/5000, reconstruction loss: 0.0244\n",
      "[LOG TRAIN 20200404-19:47:13] epoch: 0599/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:47:13] epoch: 0599/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-19:47:18] epoch: 0600/5000, reconstruction loss: 0.0244\n",
      "[LOG TRAIN 20200404-19:47:18] epoch: 0600/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:47:18] epoch: 0600/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-19:47:24] epoch: 0601/5000, reconstruction loss: 0.0243\n",
      "[LOG TRAIN 20200404-19:47:24] epoch: 0601/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:47:24] epoch: 0601/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-19:47:29] epoch: 0602/5000, reconstruction loss: 0.0243\n",
      "[LOG TRAIN 20200404-19:47:29] epoch: 0602/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-19:47:29] epoch: 0602/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:47:34] epoch: 0603/5000, reconstruction loss: 0.0242\n",
      "[LOG TRAIN 20200404-19:47:34] epoch: 0603/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:47:34] epoch: 0603/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:47:39] epoch: 0604/5000, reconstruction loss: 0.0242\n",
      "[LOG TRAIN 20200404-19:47:39] epoch: 0604/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:47:39] epoch: 0604/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:47:45] epoch: 0605/5000, reconstruction loss: 0.0242\n",
      "[LOG TRAIN 20200404-19:47:45] epoch: 0605/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:47:45] epoch: 0605/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-19:47:50] epoch: 0606/5000, reconstruction loss: 0.0242\n",
      "[LOG TRAIN 20200404-19:47:50] epoch: 0606/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:47:50] epoch: 0606/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-19:47:55] epoch: 0607/5000, reconstruction loss: 0.0242\n",
      "[LOG TRAIN 20200404-19:47:55] epoch: 0607/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:47:55] epoch: 0607/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-19:48:01] epoch: 0608/5000, reconstruction loss: 0.0241\n",
      "[LOG TRAIN 20200404-19:48:01] epoch: 0608/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:48:01] epoch: 0608/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-19:48:06] epoch: 0609/5000, reconstruction loss: 0.0241\n",
      "[LOG TRAIN 20200404-19:48:06] epoch: 0609/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:48:06] epoch: 0609/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:48:11] epoch: 0610/5000, reconstruction loss: 0.0241\n",
      "[LOG TRAIN 20200404-19:48:11] epoch: 0610/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:48:11] epoch: 0610/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:48:17] epoch: 0611/5000, reconstruction loss: 0.0241\n",
      "[LOG TRAIN 20200404-19:48:17] epoch: 0611/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:48:17] epoch: 0611/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:48:22] epoch: 0612/5000, reconstruction loss: 0.0241\n",
      "[LOG TRAIN 20200404-19:48:22] epoch: 0612/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:48:22] epoch: 0612/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:48:27] epoch: 0613/5000, reconstruction loss: 0.0241\n",
      "[LOG TRAIN 20200404-19:48:27] epoch: 0613/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:48:27] epoch: 0613/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-19:48:32] epoch: 0614/5000, reconstruction loss: 0.0240\n",
      "[LOG TRAIN 20200404-19:48:32] epoch: 0614/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:48:32] epoch: 0614/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-19:48:38] epoch: 0615/5000, reconstruction loss: 0.0240\n",
      "[LOG TRAIN 20200404-19:48:38] epoch: 0615/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:48:38] epoch: 0615/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-19:48:43] epoch: 0616/5000, reconstruction loss: 0.0240\n",
      "[LOG TRAIN 20200404-19:48:43] epoch: 0616/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:48:43] epoch: 0616/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:48:48] epoch: 0617/5000, reconstruction loss: 0.0240\n",
      "[LOG TRAIN 20200404-19:48:48] epoch: 0617/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:48:48] epoch: 0617/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:48:54] epoch: 0618/5000, reconstruction loss: 0.0239\n",
      "[LOG TRAIN 20200404-19:48:54] epoch: 0618/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:48:54] epoch: 0618/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:48:59] epoch: 0619/5000, reconstruction loss: 0.0239\n",
      "[LOG TRAIN 20200404-19:48:59] epoch: 0619/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:48:59] epoch: 0619/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:49:04] epoch: 0620/5000, reconstruction loss: 0.0239\n",
      "[LOG TRAIN 20200404-19:49:04] epoch: 0620/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:04] epoch: 0620/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:49:09] epoch: 0621/5000, reconstruction loss: 0.0239\n",
      "[LOG TRAIN 20200404-19:49:09] epoch: 0621/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:09] epoch: 0621/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:49:15] epoch: 0622/5000, reconstruction loss: 0.0238\n",
      "[LOG TRAIN 20200404-19:49:15] epoch: 0622/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:15] epoch: 0622/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-19:49:20] epoch: 0623/5000, reconstruction loss: 0.0238\n",
      "[LOG TRAIN 20200404-19:49:20] epoch: 0623/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:20] epoch: 0623/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-19:49:25] epoch: 0624/5000, reconstruction loss: 0.0238\n",
      "[LOG TRAIN 20200404-19:49:25] epoch: 0624/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:25] epoch: 0624/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-19:49:30] epoch: 0625/5000, reconstruction loss: 0.0238\n",
      "[LOG TRAIN 20200404-19:49:30] epoch: 0625/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:30] epoch: 0625/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-19:49:36] epoch: 0626/5000, reconstruction loss: 0.0237\n",
      "[LOG TRAIN 20200404-19:49:36] epoch: 0626/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:36] epoch: 0626/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-19:49:41] epoch: 0627/5000, reconstruction loss: 0.0237\n",
      "[LOG TRAIN 20200404-19:49:41] epoch: 0627/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:41] epoch: 0627/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-19:49:46] epoch: 0628/5000, reconstruction loss: 0.0237\n",
      "[LOG TRAIN 20200404-19:49:46] epoch: 0628/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:46] epoch: 0628/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-19:49:51] epoch: 0629/5000, reconstruction loss: 0.0236\n",
      "[LOG TRAIN 20200404-19:49:51] epoch: 0629/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:51] epoch: 0629/5000, generator loss: 0.6945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:49:57] epoch: 0630/5000, reconstruction loss: 0.0236\n",
      "[LOG TRAIN 20200404-19:49:57] epoch: 0630/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:49:57] epoch: 0630/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:50:02] epoch: 0631/5000, reconstruction loss: 0.0236\n",
      "[LOG TRAIN 20200404-19:50:02] epoch: 0631/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:02] epoch: 0631/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:50:07] epoch: 0632/5000, reconstruction loss: 0.0236\n",
      "[LOG TRAIN 20200404-19:50:07] epoch: 0632/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:07] epoch: 0632/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:50:12] epoch: 0633/5000, reconstruction loss: 0.0235\n",
      "[LOG TRAIN 20200404-19:50:12] epoch: 0633/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:12] epoch: 0633/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:50:18] epoch: 0634/5000, reconstruction loss: 0.0234\n",
      "[LOG TRAIN 20200404-19:50:18] epoch: 0634/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:18] epoch: 0634/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:50:23] epoch: 0635/5000, reconstruction loss: 0.0235\n",
      "[LOG TRAIN 20200404-19:50:23] epoch: 0635/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:23] epoch: 0635/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:50:28] epoch: 0636/5000, reconstruction loss: 0.0234\n",
      "[LOG TRAIN 20200404-19:50:28] epoch: 0636/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:28] epoch: 0636/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:50:33] epoch: 0637/5000, reconstruction loss: 0.0234\n",
      "[LOG TRAIN 20200404-19:50:33] epoch: 0637/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:33] epoch: 0637/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:50:39] epoch: 0638/5000, reconstruction loss: 0.0233\n",
      "[LOG TRAIN 20200404-19:50:39] epoch: 0638/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:39] epoch: 0638/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:50:44] epoch: 0639/5000, reconstruction loss: 0.0233\n",
      "[LOG TRAIN 20200404-19:50:44] epoch: 0639/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:44] epoch: 0639/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:50:49] epoch: 0640/5000, reconstruction loss: 0.0233\n",
      "[LOG TRAIN 20200404-19:50:49] epoch: 0640/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:49] epoch: 0640/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:50:54] epoch: 0641/5000, reconstruction loss: 0.0232\n",
      "[LOG TRAIN 20200404-19:50:54] epoch: 0641/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:54] epoch: 0641/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:50:59] epoch: 0642/5000, reconstruction loss: 0.0232\n",
      "[LOG TRAIN 20200404-19:50:59] epoch: 0642/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:50:59] epoch: 0642/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:03] epoch: 0643/5000, reconstruction loss: 0.0231\n",
      "[LOG TRAIN 20200404-19:51:03] epoch: 0643/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:03] epoch: 0643/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:08] epoch: 0644/5000, reconstruction loss: 0.0231\n",
      "[LOG TRAIN 20200404-19:51:08] epoch: 0644/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:08] epoch: 0644/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:12] epoch: 0645/5000, reconstruction loss: 0.0230\n",
      "[LOG TRAIN 20200404-19:51:12] epoch: 0645/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:12] epoch: 0645/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:17] epoch: 0646/5000, reconstruction loss: 0.0230\n",
      "[LOG TRAIN 20200404-19:51:17] epoch: 0646/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:17] epoch: 0646/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:21] epoch: 0647/5000, reconstruction loss: 0.0230\n",
      "[LOG TRAIN 20200404-19:51:21] epoch: 0647/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:21] epoch: 0647/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:26] epoch: 0648/5000, reconstruction loss: 0.0229\n",
      "[LOG TRAIN 20200404-19:51:26] epoch: 0648/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:26] epoch: 0648/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:30] epoch: 0649/5000, reconstruction loss: 0.0229\n",
      "[LOG TRAIN 20200404-19:51:30] epoch: 0649/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:30] epoch: 0649/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:34] epoch: 0650/5000, reconstruction loss: 0.0229\n",
      "[LOG TRAIN 20200404-19:51:34] epoch: 0650/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:34] epoch: 0650/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:39] epoch: 0651/5000, reconstruction loss: 0.0228\n",
      "[LOG TRAIN 20200404-19:51:39] epoch: 0651/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:39] epoch: 0651/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:43] epoch: 0652/5000, reconstruction loss: 0.0228\n",
      "[LOG TRAIN 20200404-19:51:43] epoch: 0652/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:43] epoch: 0652/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:47] epoch: 0653/5000, reconstruction loss: 0.0228\n",
      "[LOG TRAIN 20200404-19:51:47] epoch: 0653/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:47] epoch: 0653/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:52] epoch: 0654/5000, reconstruction loss: 0.0229\n",
      "[LOG TRAIN 20200404-19:51:52] epoch: 0654/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:52] epoch: 0654/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:51:56] epoch: 0655/5000, reconstruction loss: 0.0228\n",
      "[LOG TRAIN 20200404-19:51:56] epoch: 0655/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:51:56] epoch: 0655/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:52:01] epoch: 0656/5000, reconstruction loss: 0.0228\n",
      "[LOG TRAIN 20200404-19:52:01] epoch: 0656/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:01] epoch: 0656/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:52:05] epoch: 0657/5000, reconstruction loss: 0.0227\n",
      "[LOG TRAIN 20200404-19:52:05] epoch: 0657/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:05] epoch: 0657/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:52:10] epoch: 0658/5000, reconstruction loss: 0.0226\n",
      "[LOG TRAIN 20200404-19:52:10] epoch: 0658/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:10] epoch: 0658/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:52:14] epoch: 0659/5000, reconstruction loss: 0.0228\n",
      "[LOG TRAIN 20200404-19:52:14] epoch: 0659/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:14] epoch: 0659/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:52:19] epoch: 0660/5000, reconstruction loss: 0.0227\n",
      "[LOG TRAIN 20200404-19:52:19] epoch: 0660/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:19] epoch: 0660/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:52:24] epoch: 0661/5000, reconstruction loss: 0.0226\n",
      "[LOG TRAIN 20200404-19:52:24] epoch: 0661/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:24] epoch: 0661/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:52:28] epoch: 0662/5000, reconstruction loss: 0.0226\n",
      "[LOG TRAIN 20200404-19:52:28] epoch: 0662/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:28] epoch: 0662/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:52:33] epoch: 0663/5000, reconstruction loss: 0.0229\n",
      "[LOG TRAIN 20200404-19:52:33] epoch: 0663/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:33] epoch: 0663/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:52:38] epoch: 0664/5000, reconstruction loss: 0.0225\n",
      "[LOG TRAIN 20200404-19:52:38] epoch: 0664/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:38] epoch: 0664/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-19:52:42] epoch: 0665/5000, reconstruction loss: 0.0226\n",
      "[LOG TRAIN 20200404-19:52:42] epoch: 0665/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:42] epoch: 0665/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:52:48] epoch: 0666/5000, reconstruction loss: 0.0226\n",
      "[LOG TRAIN 20200404-19:52:48] epoch: 0666/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:48] epoch: 0666/5000, generator loss: 0.6943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:52:54] epoch: 0667/5000, reconstruction loss: 0.0225\n",
      "[LOG TRAIN 20200404-19:52:54] epoch: 0667/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:54] epoch: 0667/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:52:59] epoch: 0668/5000, reconstruction loss: 0.0225\n",
      "[LOG TRAIN 20200404-19:52:59] epoch: 0668/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:52:59] epoch: 0668/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:53:05] epoch: 0669/5000, reconstruction loss: 0.0227\n",
      "[LOG TRAIN 20200404-19:53:05] epoch: 0669/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:05] epoch: 0669/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:53:10] epoch: 0670/5000, reconstruction loss: 0.0224\n",
      "[LOG TRAIN 20200404-19:53:10] epoch: 0670/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:10] epoch: 0670/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:53:15] epoch: 0671/5000, reconstruction loss: 0.0224\n",
      "[LOG TRAIN 20200404-19:53:15] epoch: 0671/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:15] epoch: 0671/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:53:21] epoch: 0672/5000, reconstruction loss: 0.0226\n",
      "[LOG TRAIN 20200404-19:53:21] epoch: 0672/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:21] epoch: 0672/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:53:26] epoch: 0673/5000, reconstruction loss: 0.0223\n",
      "[LOG TRAIN 20200404-19:53:26] epoch: 0673/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:26] epoch: 0673/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-19:53:31] epoch: 0674/5000, reconstruction loss: 0.0223\n",
      "[LOG TRAIN 20200404-19:53:31] epoch: 0674/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:31] epoch: 0674/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-19:53:36] epoch: 0675/5000, reconstruction loss: 0.0226\n",
      "[LOG TRAIN 20200404-19:53:36] epoch: 0675/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:36] epoch: 0675/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-19:53:41] epoch: 0676/5000, reconstruction loss: 0.0223\n",
      "[LOG TRAIN 20200404-19:53:41] epoch: 0676/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:41] epoch: 0676/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-19:53:46] epoch: 0677/5000, reconstruction loss: 0.0224\n",
      "[LOG TRAIN 20200404-19:53:46] epoch: 0677/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:46] epoch: 0677/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-19:53:50] epoch: 0678/5000, reconstruction loss: 0.0224\n",
      "[LOG TRAIN 20200404-19:53:50] epoch: 0678/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:50] epoch: 0678/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-19:53:55] epoch: 0679/5000, reconstruction loss: 0.0222\n",
      "[LOG TRAIN 20200404-19:53:55] epoch: 0679/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:53:55] epoch: 0679/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-19:54:01] epoch: 0680/5000, reconstruction loss: 0.0221\n",
      "[LOG TRAIN 20200404-19:54:01] epoch: 0680/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:01] epoch: 0680/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-19:54:05] epoch: 0681/5000, reconstruction loss: 0.0224\n",
      "[LOG TRAIN 20200404-19:54:05] epoch: 0681/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:05] epoch: 0681/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-19:54:09] epoch: 0682/5000, reconstruction loss: 0.0226\n",
      "[LOG TRAIN 20200404-19:54:09] epoch: 0682/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:09] epoch: 0682/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-19:54:14] epoch: 0683/5000, reconstruction loss: 0.0222\n",
      "[LOG TRAIN 20200404-19:54:14] epoch: 0683/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:14] epoch: 0683/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-19:54:19] epoch: 0684/5000, reconstruction loss: 0.0223\n",
      "[LOG TRAIN 20200404-19:54:19] epoch: 0684/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:19] epoch: 0684/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-19:54:23] epoch: 0685/5000, reconstruction loss: 0.0221\n",
      "[LOG TRAIN 20200404-19:54:23] epoch: 0685/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:23] epoch: 0685/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-19:54:28] epoch: 0686/5000, reconstruction loss: 0.0223\n",
      "[LOG TRAIN 20200404-19:54:28] epoch: 0686/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:28] epoch: 0686/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-19:54:32] epoch: 0687/5000, reconstruction loss: 0.0221\n",
      "[LOG TRAIN 20200404-19:54:32] epoch: 0687/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:32] epoch: 0687/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-19:54:37] epoch: 0688/5000, reconstruction loss: 0.0220\n",
      "[LOG TRAIN 20200404-19:54:37] epoch: 0688/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:37] epoch: 0688/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-19:54:41] epoch: 0689/5000, reconstruction loss: 0.0222\n",
      "[LOG TRAIN 20200404-19:54:41] epoch: 0689/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:41] epoch: 0689/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-19:54:46] epoch: 0690/5000, reconstruction loss: 0.0221\n",
      "[LOG TRAIN 20200404-19:54:46] epoch: 0690/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:46] epoch: 0690/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-19:54:50] epoch: 0691/5000, reconstruction loss: 0.0220\n",
      "[LOG TRAIN 20200404-19:54:50] epoch: 0691/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:50] epoch: 0691/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-19:54:54] epoch: 0692/5000, reconstruction loss: 0.0222\n",
      "[LOG TRAIN 20200404-19:54:54] epoch: 0692/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:54] epoch: 0692/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-19:54:59] epoch: 0693/5000, reconstruction loss: 0.0222\n",
      "[LOG TRAIN 20200404-19:54:59] epoch: 0693/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:54:59] epoch: 0693/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-19:55:04] epoch: 0694/5000, reconstruction loss: 0.0219\n",
      "[LOG TRAIN 20200404-19:55:04] epoch: 0694/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:04] epoch: 0694/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-19:55:08] epoch: 0695/5000, reconstruction loss: 0.0220\n",
      "[LOG TRAIN 20200404-19:55:08] epoch: 0695/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:08] epoch: 0695/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:55:13] epoch: 0696/5000, reconstruction loss: 0.0222\n",
      "[LOG TRAIN 20200404-19:55:13] epoch: 0696/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:13] epoch: 0696/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:55:18] epoch: 0697/5000, reconstruction loss: 0.0219\n",
      "[LOG TRAIN 20200404-19:55:18] epoch: 0697/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:18] epoch: 0697/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:55:23] epoch: 0698/5000, reconstruction loss: 0.0219\n",
      "[LOG TRAIN 20200404-19:55:23] epoch: 0698/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:23] epoch: 0698/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:55:28] epoch: 0699/5000, reconstruction loss: 0.0221\n",
      "[LOG TRAIN 20200404-19:55:28] epoch: 0699/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:28] epoch: 0699/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:55:33] epoch: 0700/5000, reconstruction loss: 0.0220\n",
      "[LOG TRAIN 20200404-19:55:33] epoch: 0700/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:33] epoch: 0700/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:55:39] epoch: 0701/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-19:55:39] epoch: 0701/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:39] epoch: 0701/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:55:44] epoch: 0702/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-19:55:44] epoch: 0702/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:44] epoch: 0702/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:55:49] epoch: 0703/5000, reconstruction loss: 0.0220\n",
      "[LOG TRAIN 20200404-19:55:49] epoch: 0703/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:49] epoch: 0703/5000, generator loss: 0.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:55:54] epoch: 0704/5000, reconstruction loss: 0.0221\n",
      "[LOG TRAIN 20200404-19:55:54] epoch: 0704/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:55:54] epoch: 0704/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:56:00] epoch: 0705/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-19:56:00] epoch: 0705/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:00] epoch: 0705/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:56:05] epoch: 0706/5000, reconstruction loss: 0.0220\n",
      "[LOG TRAIN 20200404-19:56:05] epoch: 0706/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:05] epoch: 0706/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:56:10] epoch: 0707/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-19:56:10] epoch: 0707/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:10] epoch: 0707/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:56:15] epoch: 0708/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-19:56:15] epoch: 0708/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:15] epoch: 0708/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:56:21] epoch: 0709/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-19:56:21] epoch: 0709/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:21] epoch: 0709/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:56:26] epoch: 0710/5000, reconstruction loss: 0.0217\n",
      "[LOG TRAIN 20200404-19:56:26] epoch: 0710/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:26] epoch: 0710/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:56:31] epoch: 0711/5000, reconstruction loss: 0.0219\n",
      "[LOG TRAIN 20200404-19:56:31] epoch: 0711/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:31] epoch: 0711/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:56:36] epoch: 0712/5000, reconstruction loss: 0.0217\n",
      "[LOG TRAIN 20200404-19:56:36] epoch: 0712/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:36] epoch: 0712/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:56:42] epoch: 0713/5000, reconstruction loss: 0.0216\n",
      "[LOG TRAIN 20200404-19:56:42] epoch: 0713/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:42] epoch: 0713/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:56:47] epoch: 0714/5000, reconstruction loss: 0.0217\n",
      "[LOG TRAIN 20200404-19:56:47] epoch: 0714/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:47] epoch: 0714/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-19:56:52] epoch: 0715/5000, reconstruction loss: 0.0219\n",
      "[LOG TRAIN 20200404-19:56:52] epoch: 0715/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:52] epoch: 0715/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:56:58] epoch: 0716/5000, reconstruction loss: 0.0216\n",
      "[LOG TRAIN 20200404-19:56:58] epoch: 0716/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:56:58] epoch: 0716/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:57:03] epoch: 0717/5000, reconstruction loss: 0.0217\n",
      "[LOG TRAIN 20200404-19:57:03] epoch: 0717/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:57:03] epoch: 0717/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-19:57:09] epoch: 0718/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-19:57:09] epoch: 0718/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:57:09] epoch: 0718/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:57:14] epoch: 0719/5000, reconstruction loss: 0.0215\n",
      "[LOG TRAIN 20200404-19:57:14] epoch: 0719/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:57:14] epoch: 0719/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:57:19] epoch: 0720/5000, reconstruction loss: 0.0216\n",
      "[LOG TRAIN 20200404-19:57:19] epoch: 0720/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:57:19] epoch: 0720/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:57:24] epoch: 0721/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-19:57:24] epoch: 0721/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-19:57:24] epoch: 0721/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:57:30] epoch: 0722/5000, reconstruction loss: 0.0215\n",
      "[LOG TRAIN 20200404-19:57:30] epoch: 0722/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:57:30] epoch: 0722/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:57:35] epoch: 0723/5000, reconstruction loss: 0.0215\n",
      "[LOG TRAIN 20200404-19:57:35] epoch: 0723/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:57:35] epoch: 0723/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:57:40] epoch: 0724/5000, reconstruction loss: 0.0217\n",
      "[LOG TRAIN 20200404-19:57:40] epoch: 0724/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:57:40] epoch: 0724/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:57:45] epoch: 0725/5000, reconstruction loss: 0.0215\n",
      "[LOG TRAIN 20200404-19:57:45] epoch: 0725/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:57:45] epoch: 0725/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:57:51] epoch: 0726/5000, reconstruction loss: 0.0215\n",
      "[LOG TRAIN 20200404-19:57:51] epoch: 0726/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:57:51] epoch: 0726/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:57:56] epoch: 0727/5000, reconstruction loss: 0.0217\n",
      "[LOG TRAIN 20200404-19:57:56] epoch: 0727/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:57:56] epoch: 0727/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:58:01] epoch: 0728/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200404-19:58:01] epoch: 0728/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:01] epoch: 0728/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:58:06] epoch: 0729/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200404-19:58:06] epoch: 0729/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:06] epoch: 0729/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-19:58:12] epoch: 0730/5000, reconstruction loss: 0.0216\n",
      "[LOG TRAIN 20200404-19:58:12] epoch: 0730/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:12] epoch: 0730/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:58:17] epoch: 0731/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200404-19:58:17] epoch: 0731/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:17] epoch: 0731/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:58:22] epoch: 0732/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200404-19:58:22] epoch: 0732/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:22] epoch: 0732/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:58:27] epoch: 0733/5000, reconstruction loss: 0.0215\n",
      "[LOG TRAIN 20200404-19:58:27] epoch: 0733/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:27] epoch: 0733/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:58:33] epoch: 0734/5000, reconstruction loss: 0.0213\n",
      "[LOG TRAIN 20200404-19:58:33] epoch: 0734/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:33] epoch: 0734/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:58:38] epoch: 0735/5000, reconstruction loss: 0.0213\n",
      "[LOG TRAIN 20200404-19:58:38] epoch: 0735/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:38] epoch: 0735/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:58:43] epoch: 0736/5000, reconstruction loss: 0.0215\n",
      "[LOG TRAIN 20200404-19:58:43] epoch: 0736/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:43] epoch: 0736/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:58:49] epoch: 0737/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200404-19:58:49] epoch: 0737/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:49] epoch: 0737/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:58:54] epoch: 0738/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-19:58:54] epoch: 0738/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:54] epoch: 0738/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:58:59] epoch: 0739/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-19:58:59] epoch: 0739/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:58:59] epoch: 0739/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:59:04] epoch: 0740/5000, reconstruction loss: 0.0215\n",
      "[LOG TRAIN 20200404-19:59:04] epoch: 0740/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:04] epoch: 0740/5000, generator loss: 0.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-19:59:10] epoch: 0741/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200404-19:59:10] epoch: 0741/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:10] epoch: 0741/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:59:15] epoch: 0742/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-19:59:15] epoch: 0742/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:15] epoch: 0742/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:59:20] epoch: 0743/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200404-19:59:20] epoch: 0743/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:20] epoch: 0743/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:59:25] epoch: 0744/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-19:59:25] epoch: 0744/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:25] epoch: 0744/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:59:31] epoch: 0745/5000, reconstruction loss: 0.0213\n",
      "[LOG TRAIN 20200404-19:59:31] epoch: 0745/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:31] epoch: 0745/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:59:36] epoch: 0746/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-19:59:36] epoch: 0746/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:36] epoch: 0746/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:59:41] epoch: 0747/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-19:59:41] epoch: 0747/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:41] epoch: 0747/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:59:46] epoch: 0748/5000, reconstruction loss: 0.0213\n",
      "[LOG TRAIN 20200404-19:59:46] epoch: 0748/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:46] epoch: 0748/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-19:59:51] epoch: 0749/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-19:59:51] epoch: 0749/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:51] epoch: 0749/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-19:59:57] epoch: 0750/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-19:59:57] epoch: 0750/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-19:59:57] epoch: 0750/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:02] epoch: 0751/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-20:00:02] epoch: 0751/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:02] epoch: 0751/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:08] epoch: 0752/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-20:00:08] epoch: 0752/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:08] epoch: 0752/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:13] epoch: 0753/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-20:00:13] epoch: 0753/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:13] epoch: 0753/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:18] epoch: 0754/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-20:00:18] epoch: 0754/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:18] epoch: 0754/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:24] epoch: 0755/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-20:00:24] epoch: 0755/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:24] epoch: 0755/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:29] epoch: 0756/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-20:00:29] epoch: 0756/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:29] epoch: 0756/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:34] epoch: 0757/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:00:34] epoch: 0757/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:34] epoch: 0757/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:40] epoch: 0758/5000, reconstruction loss: 0.0210\n",
      "[LOG TRAIN 20200404-20:00:40] epoch: 0758/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:40] epoch: 0758/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:45] epoch: 0759/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-20:00:45] epoch: 0759/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:45] epoch: 0759/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:50] epoch: 0760/5000, reconstruction loss: 0.0210\n",
      "[LOG TRAIN 20200404-20:00:50] epoch: 0760/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:50] epoch: 0760/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:00:55] epoch: 0761/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:00:55] epoch: 0761/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:00:55] epoch: 0761/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:01:00] epoch: 0762/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-20:01:00] epoch: 0762/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:00] epoch: 0762/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:01:06] epoch: 0763/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:01:06] epoch: 0763/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:06] epoch: 0763/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:01:11] epoch: 0764/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:01:11] epoch: 0764/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:11] epoch: 0764/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:01:16] epoch: 0765/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-20:01:16] epoch: 0765/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:16] epoch: 0765/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:01:22] epoch: 0766/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:01:22] epoch: 0766/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:22] epoch: 0766/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:01:27] epoch: 0767/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200404-20:01:27] epoch: 0767/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:27] epoch: 0767/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:01:32] epoch: 0768/5000, reconstruction loss: 0.0210\n",
      "[LOG TRAIN 20200404-20:01:32] epoch: 0768/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:32] epoch: 0768/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:01:37] epoch: 0769/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-20:01:37] epoch: 0769/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:37] epoch: 0769/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:01:43] epoch: 0770/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200404-20:01:43] epoch: 0770/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:43] epoch: 0770/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:01:48] epoch: 0771/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-20:01:48] epoch: 0771/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:48] epoch: 0771/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:01:53] epoch: 0772/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200404-20:01:53] epoch: 0772/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:53] epoch: 0772/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:01:58] epoch: 0773/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:01:58] epoch: 0773/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:01:58] epoch: 0773/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:02:04] epoch: 0774/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:02:04] epoch: 0774/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:04] epoch: 0774/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:02:09] epoch: 0775/5000, reconstruction loss: 0.0207\n",
      "[LOG TRAIN 20200404-20:02:09] epoch: 0775/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:09] epoch: 0775/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:02:14] epoch: 0776/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200404-20:02:14] epoch: 0776/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:14] epoch: 0776/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:02:19] epoch: 0777/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:02:19] epoch: 0777/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:19] epoch: 0777/5000, generator loss: 0.6934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:02:25] epoch: 0778/5000, reconstruction loss: 0.0207\n",
      "[LOG TRAIN 20200404-20:02:25] epoch: 0778/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:25] epoch: 0778/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:02:30] epoch: 0779/5000, reconstruction loss: 0.0207\n",
      "[LOG TRAIN 20200404-20:02:30] epoch: 0779/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:30] epoch: 0779/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:02:35] epoch: 0780/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-20:02:35] epoch: 0780/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:35] epoch: 0780/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:02:41] epoch: 0781/5000, reconstruction loss: 0.0207\n",
      "[LOG TRAIN 20200404-20:02:41] epoch: 0781/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:41] epoch: 0781/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:02:46] epoch: 0782/5000, reconstruction loss: 0.0207\n",
      "[LOG TRAIN 20200404-20:02:46] epoch: 0782/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:46] epoch: 0782/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:02:51] epoch: 0783/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:02:51] epoch: 0783/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:51] epoch: 0783/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:02:57] epoch: 0784/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:02:57] epoch: 0784/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:02:57] epoch: 0784/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:03:02] epoch: 0785/5000, reconstruction loss: 0.0207\n",
      "[LOG TRAIN 20200404-20:03:02] epoch: 0785/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:02] epoch: 0785/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:03:08] epoch: 0786/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:03:08] epoch: 0786/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:08] epoch: 0786/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:03:13] epoch: 0787/5000, reconstruction loss: 0.0207\n",
      "[LOG TRAIN 20200404-20:03:13] epoch: 0787/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:13] epoch: 0787/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:03:18] epoch: 0788/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:03:18] epoch: 0788/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:18] epoch: 0788/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:03:24] epoch: 0789/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:03:24] epoch: 0789/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:24] epoch: 0789/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:03:29] epoch: 0790/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:03:29] epoch: 0790/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:29] epoch: 0790/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:03:34] epoch: 0791/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:03:34] epoch: 0791/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:34] epoch: 0791/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:03:39] epoch: 0792/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:03:39] epoch: 0792/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:39] epoch: 0792/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:03:45] epoch: 0793/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200404-20:03:45] epoch: 0793/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:45] epoch: 0793/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:03:50] epoch: 0794/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:03:50] epoch: 0794/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:50] epoch: 0794/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:03:55] epoch: 0795/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-20:03:55] epoch: 0795/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:03:55] epoch: 0795/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:00] epoch: 0796/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:04:00] epoch: 0796/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:00] epoch: 0796/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:06] epoch: 0797/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200404-20:04:06] epoch: 0797/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:06] epoch: 0797/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:11] epoch: 0798/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-20:04:11] epoch: 0798/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:11] epoch: 0798/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:16] epoch: 0799/5000, reconstruction loss: 0.0207\n",
      "[LOG TRAIN 20200404-20:04:16] epoch: 0799/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:16] epoch: 0799/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:21] epoch: 0800/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:04:21] epoch: 0800/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:21] epoch: 0800/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:27] epoch: 0801/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-20:04:27] epoch: 0801/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:27] epoch: 0801/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:32] epoch: 0802/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:04:32] epoch: 0802/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:32] epoch: 0802/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:37] epoch: 0803/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:04:37] epoch: 0803/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:37] epoch: 0803/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:43] epoch: 0804/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-20:04:43] epoch: 0804/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:43] epoch: 0804/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:48] epoch: 0805/5000, reconstruction loss: 0.0207\n",
      "[LOG TRAIN 20200404-20:04:48] epoch: 0805/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:48] epoch: 0805/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:53] epoch: 0806/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:04:53] epoch: 0806/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:53] epoch: 0806/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:04:58] epoch: 0807/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:04:58] epoch: 0807/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:04:58] epoch: 0807/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:05:03] epoch: 0808/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:05:03] epoch: 0808/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:03] epoch: 0808/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:05:09] epoch: 0809/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200404-20:05:09] epoch: 0809/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:09] epoch: 0809/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:05:14] epoch: 0810/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:05:14] epoch: 0810/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:14] epoch: 0810/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:05:19] epoch: 0811/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200404-20:05:19] epoch: 0811/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:19] epoch: 0811/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:05:24] epoch: 0812/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:05:24] epoch: 0812/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:24] epoch: 0812/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:05:30] epoch: 0813/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-20:05:30] epoch: 0813/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:30] epoch: 0813/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:05:35] epoch: 0814/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-20:05:35] epoch: 0814/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:35] epoch: 0814/5000, generator loss: 0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:05:40] epoch: 0815/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:05:40] epoch: 0815/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:40] epoch: 0815/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:05:46] epoch: 0816/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:05:46] epoch: 0816/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:46] epoch: 0816/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:05:51] epoch: 0817/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-20:05:51] epoch: 0817/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:51] epoch: 0817/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:05:56] epoch: 0818/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:05:56] epoch: 0818/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:05:56] epoch: 0818/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:02] epoch: 0819/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-20:06:02] epoch: 0819/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:02] epoch: 0819/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:07] epoch: 0820/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:06:07] epoch: 0820/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:07] epoch: 0820/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:12] epoch: 0821/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-20:06:12] epoch: 0821/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:12] epoch: 0821/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:18] epoch: 0822/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:06:18] epoch: 0822/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:18] epoch: 0822/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:23] epoch: 0823/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:06:23] epoch: 0823/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:23] epoch: 0823/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:28] epoch: 0824/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:06:28] epoch: 0824/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:28] epoch: 0824/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:33] epoch: 0825/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-20:06:33] epoch: 0825/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:33] epoch: 0825/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:39] epoch: 0826/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:06:39] epoch: 0826/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:39] epoch: 0826/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:44] epoch: 0827/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:06:44] epoch: 0827/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:44] epoch: 0827/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:49] epoch: 0828/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:06:49] epoch: 0828/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:49] epoch: 0828/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:06:54] epoch: 0829/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-20:06:54] epoch: 0829/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:06:54] epoch: 0829/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:07:00] epoch: 0830/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-20:07:00] epoch: 0830/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:00] epoch: 0830/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:07:05] epoch: 0831/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-20:07:05] epoch: 0831/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:05] epoch: 0831/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:07:10] epoch: 0832/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-20:07:10] epoch: 0832/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:10] epoch: 0832/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:07:15] epoch: 0833/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-20:07:15] epoch: 0833/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:15] epoch: 0833/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:07:21] epoch: 0834/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:07:21] epoch: 0834/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:21] epoch: 0834/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:07:26] epoch: 0835/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-20:07:26] epoch: 0835/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:26] epoch: 0835/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:07:31] epoch: 0836/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:07:31] epoch: 0836/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:31] epoch: 0836/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:07:36] epoch: 0837/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-20:07:36] epoch: 0837/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:36] epoch: 0837/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:07:42] epoch: 0838/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-20:07:42] epoch: 0838/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:42] epoch: 0838/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:07:47] epoch: 0839/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:07:47] epoch: 0839/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:47] epoch: 0839/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:07:52] epoch: 0840/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:07:52] epoch: 0840/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:52] epoch: 0840/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:07:57] epoch: 0841/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:07:57] epoch: 0841/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:07:57] epoch: 0841/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:08:02] epoch: 0842/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-20:08:02] epoch: 0842/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:02] epoch: 0842/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:08:08] epoch: 0843/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:08:08] epoch: 0843/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:08] epoch: 0843/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:08:13] epoch: 0844/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-20:08:13] epoch: 0844/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:13] epoch: 0844/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:08:18] epoch: 0845/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:08:18] epoch: 0845/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:18] epoch: 0845/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:08:23] epoch: 0846/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:08:23] epoch: 0846/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:23] epoch: 0846/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:08:29] epoch: 0847/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:08:29] epoch: 0847/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:29] epoch: 0847/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:08:34] epoch: 0848/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:08:34] epoch: 0848/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:34] epoch: 0848/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:08:39] epoch: 0849/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:08:39] epoch: 0849/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:39] epoch: 0849/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:08:44] epoch: 0850/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:08:44] epoch: 0850/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:44] epoch: 0850/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:08:50] epoch: 0851/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:08:50] epoch: 0851/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:50] epoch: 0851/5000, generator loss: 0.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:08:55] epoch: 0852/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:08:55] epoch: 0852/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:08:55] epoch: 0852/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:09:01] epoch: 0853/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:09:01] epoch: 0853/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:01] epoch: 0853/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:09:06] epoch: 0854/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:09:06] epoch: 0854/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:06] epoch: 0854/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:09:11] epoch: 0855/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:09:11] epoch: 0855/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:11] epoch: 0855/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:09:16] epoch: 0856/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:09:16] epoch: 0856/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:16] epoch: 0856/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:09:22] epoch: 0857/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:09:22] epoch: 0857/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:22] epoch: 0857/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:09:27] epoch: 0858/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:09:27] epoch: 0858/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:27] epoch: 0858/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:09:32] epoch: 0859/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:09:32] epoch: 0859/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:32] epoch: 0859/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:09:37] epoch: 0860/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:09:37] epoch: 0860/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:37] epoch: 0860/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:09:42] epoch: 0861/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:09:42] epoch: 0861/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:42] epoch: 0861/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:09:48] epoch: 0862/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:09:48] epoch: 0862/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:48] epoch: 0862/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:09:53] epoch: 0863/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:09:53] epoch: 0863/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:09:53] epoch: 0863/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:09:58] epoch: 0864/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:09:58] epoch: 0864/5000, discriminator loss: 1.3859\n",
      "[LOG TRAIN 20200404-20:09:58] epoch: 0864/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:10:03] epoch: 0865/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:10:03] epoch: 0865/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:03] epoch: 0865/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:10:09] epoch: 0866/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-20:10:09] epoch: 0866/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:09] epoch: 0866/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:10:14] epoch: 0867/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:10:14] epoch: 0867/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:14] epoch: 0867/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:10:19] epoch: 0868/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:10:19] epoch: 0868/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:19] epoch: 0868/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:10:24] epoch: 0869/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:10:24] epoch: 0869/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:24] epoch: 0869/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:10:30] epoch: 0870/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:10:30] epoch: 0870/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:30] epoch: 0870/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:10:35] epoch: 0871/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-20:10:35] epoch: 0871/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:35] epoch: 0871/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:10:40] epoch: 0872/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-20:10:40] epoch: 0872/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:40] epoch: 0872/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:10:45] epoch: 0873/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:10:45] epoch: 0873/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:45] epoch: 0873/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:10:50] epoch: 0874/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:10:50] epoch: 0874/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:50] epoch: 0874/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:10:56] epoch: 0875/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:10:56] epoch: 0875/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:10:56] epoch: 0875/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:01] epoch: 0876/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:11:01] epoch: 0876/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:01] epoch: 0876/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:06] epoch: 0877/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:11:06] epoch: 0877/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:06] epoch: 0877/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:11] epoch: 0878/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-20:11:11] epoch: 0878/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:11] epoch: 0878/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:16] epoch: 0879/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:11:16] epoch: 0879/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:16] epoch: 0879/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:22] epoch: 0880/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:11:22] epoch: 0880/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:22] epoch: 0880/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:27] epoch: 0881/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:11:27] epoch: 0881/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:27] epoch: 0881/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:32] epoch: 0882/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:11:32] epoch: 0882/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:32] epoch: 0882/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:37] epoch: 0883/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:11:37] epoch: 0883/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:37] epoch: 0883/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:43] epoch: 0884/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:11:43] epoch: 0884/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:43] epoch: 0884/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:48] epoch: 0885/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:11:48] epoch: 0885/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:48] epoch: 0885/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:11:53] epoch: 0886/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:11:53] epoch: 0886/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:53] epoch: 0886/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:11:59] epoch: 0887/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:11:59] epoch: 0887/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:11:59] epoch: 0887/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:12:04] epoch: 0888/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:12:04] epoch: 0888/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:04] epoch: 0888/5000, generator loss: 0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:12:09] epoch: 0889/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-20:12:09] epoch: 0889/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:09] epoch: 0889/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:12:15] epoch: 0890/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:12:15] epoch: 0890/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:15] epoch: 0890/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:12:20] epoch: 0891/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:12:20] epoch: 0891/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:20] epoch: 0891/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:12:25] epoch: 0892/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:12:25] epoch: 0892/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:25] epoch: 0892/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:12:30] epoch: 0893/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:12:30] epoch: 0893/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:30] epoch: 0893/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:12:35] epoch: 0894/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:12:35] epoch: 0894/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:35] epoch: 0894/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:12:41] epoch: 0895/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:12:41] epoch: 0895/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:41] epoch: 0895/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:12:46] epoch: 0896/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:12:46] epoch: 0896/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:46] epoch: 0896/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:12:51] epoch: 0897/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:12:51] epoch: 0897/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:51] epoch: 0897/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:12:56] epoch: 0898/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:12:56] epoch: 0898/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:12:56] epoch: 0898/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:13:02] epoch: 0899/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:13:02] epoch: 0899/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:02] epoch: 0899/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:13:07] epoch: 0900/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:13:07] epoch: 0900/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:07] epoch: 0900/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:13:12] epoch: 0901/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:13:12] epoch: 0901/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:12] epoch: 0901/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:13:17] epoch: 0902/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:13:17] epoch: 0902/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:17] epoch: 0902/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:13:22] epoch: 0903/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:13:22] epoch: 0903/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:22] epoch: 0903/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:13:28] epoch: 0904/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:13:28] epoch: 0904/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:28] epoch: 0904/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:13:33] epoch: 0905/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:13:33] epoch: 0905/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:33] epoch: 0905/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:13:38] epoch: 0906/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:13:38] epoch: 0906/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:38] epoch: 0906/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:13:43] epoch: 0907/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:13:43] epoch: 0907/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:43] epoch: 0907/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:13:49] epoch: 0908/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:13:49] epoch: 0908/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:49] epoch: 0908/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:13:54] epoch: 0909/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:13:54] epoch: 0909/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:54] epoch: 0909/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:13:59] epoch: 0910/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:13:59] epoch: 0910/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:13:59] epoch: 0910/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:14:04] epoch: 0911/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:14:04] epoch: 0911/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:04] epoch: 0911/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:14:09] epoch: 0912/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:14:09] epoch: 0912/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:09] epoch: 0912/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:14:15] epoch: 0913/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:14:15] epoch: 0913/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:15] epoch: 0913/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:14:20] epoch: 0914/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:14:20] epoch: 0914/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:20] epoch: 0914/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:14:25] epoch: 0915/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:14:25] epoch: 0915/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:25] epoch: 0915/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:14:30] epoch: 0916/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:14:30] epoch: 0916/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:30] epoch: 0916/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:14:36] epoch: 0917/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:14:36] epoch: 0917/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:36] epoch: 0917/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:14:41] epoch: 0918/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:14:41] epoch: 0918/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:41] epoch: 0918/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:14:46] epoch: 0919/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:14:46] epoch: 0919/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:46] epoch: 0919/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:14:51] epoch: 0920/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:14:51] epoch: 0920/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:51] epoch: 0920/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:14:57] epoch: 0921/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:14:57] epoch: 0921/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:14:57] epoch: 0921/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:15:02] epoch: 0922/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:15:02] epoch: 0922/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:02] epoch: 0922/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:15:08] epoch: 0923/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:15:08] epoch: 0923/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:08] epoch: 0923/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:15:13] epoch: 0924/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:15:13] epoch: 0924/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:13] epoch: 0924/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:15:18] epoch: 0925/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:15:18] epoch: 0925/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:18] epoch: 0925/5000, generator loss: 0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:15:23] epoch: 0926/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:15:23] epoch: 0926/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:23] epoch: 0926/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:15:28] epoch: 0927/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:15:28] epoch: 0927/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:28] epoch: 0927/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:15:34] epoch: 0928/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:15:34] epoch: 0928/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:34] epoch: 0928/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:15:39] epoch: 0929/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:15:39] epoch: 0929/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:39] epoch: 0929/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:15:44] epoch: 0930/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:15:44] epoch: 0930/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:44] epoch: 0930/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:15:49] epoch: 0931/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:15:49] epoch: 0931/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:49] epoch: 0931/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:15:55] epoch: 0932/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:15:55] epoch: 0932/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:15:55] epoch: 0932/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:16:00] epoch: 0933/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:16:00] epoch: 0933/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:16:00] epoch: 0933/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:16:05] epoch: 0934/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-20:16:05] epoch: 0934/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:16:05] epoch: 0934/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:16:10] epoch: 0935/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:16:10] epoch: 0935/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:16:10] epoch: 0935/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:16:16] epoch: 0936/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:16:16] epoch: 0936/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:16:16] epoch: 0936/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:16:21] epoch: 0937/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:16:21] epoch: 0937/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:16:21] epoch: 0937/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:16:26] epoch: 0938/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:16:26] epoch: 0938/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:16:26] epoch: 0938/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:16:31] epoch: 0939/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:16:31] epoch: 0939/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:16:31] epoch: 0939/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:16:37] epoch: 0940/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:16:37] epoch: 0940/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:16:37] epoch: 0940/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:16:42] epoch: 0941/5000, reconstruction loss: 0.0242\n",
      "[LOG TRAIN 20200404-20:16:42] epoch: 0941/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:16:42] epoch: 0941/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:16:47] epoch: 0942/5000, reconstruction loss: 0.0276\n",
      "[LOG TRAIN 20200404-20:16:47] epoch: 0942/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:16:47] epoch: 0942/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:16:52] epoch: 0943/5000, reconstruction loss: 0.0241\n",
      "[LOG TRAIN 20200404-20:16:52] epoch: 0943/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:16:52] epoch: 0943/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:16:58] epoch: 0944/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-20:16:58] epoch: 0944/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:16:58] epoch: 0944/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:17:03] epoch: 0945/5000, reconstruction loss: 0.0210\n",
      "[LOG TRAIN 20200404-20:17:03] epoch: 0945/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:03] epoch: 0945/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:17:08] epoch: 0946/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:17:08] epoch: 0946/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:08] epoch: 0946/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:17:13] epoch: 0947/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-20:17:13] epoch: 0947/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:13] epoch: 0947/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:17:18] epoch: 0948/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:17:18] epoch: 0948/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:18] epoch: 0948/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:17:24] epoch: 0949/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:17:24] epoch: 0949/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:24] epoch: 0949/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:17:29] epoch: 0950/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:17:29] epoch: 0950/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:29] epoch: 0950/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:17:34] epoch: 0951/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:17:34] epoch: 0951/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:34] epoch: 0951/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:17:39] epoch: 0952/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:17:39] epoch: 0952/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:39] epoch: 0952/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:17:45] epoch: 0953/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:17:45] epoch: 0953/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:45] epoch: 0953/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:17:50] epoch: 0954/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:17:50] epoch: 0954/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:50] epoch: 0954/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:17:55] epoch: 0955/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:17:55] epoch: 0955/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:17:55] epoch: 0955/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:18:01] epoch: 0956/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:18:01] epoch: 0956/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:01] epoch: 0956/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:18:06] epoch: 0957/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:18:06] epoch: 0957/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:06] epoch: 0957/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:18:11] epoch: 0958/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:18:11] epoch: 0958/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:11] epoch: 0958/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:18:16] epoch: 0959/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:18:16] epoch: 0959/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:16] epoch: 0959/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:18:22] epoch: 0960/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:18:22] epoch: 0960/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:22] epoch: 0960/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:18:27] epoch: 0961/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:18:27] epoch: 0961/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:27] epoch: 0961/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:18:32] epoch: 0962/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:18:32] epoch: 0962/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:32] epoch: 0962/5000, generator loss: 0.6935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:18:37] epoch: 0963/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:18:37] epoch: 0963/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:37] epoch: 0963/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:18:43] epoch: 0964/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:18:43] epoch: 0964/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:43] epoch: 0964/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:18:48] epoch: 0965/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:18:48] epoch: 0965/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:48] epoch: 0965/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:18:53] epoch: 0966/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:18:53] epoch: 0966/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:53] epoch: 0966/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:18:59] epoch: 0967/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:18:59] epoch: 0967/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:18:59] epoch: 0967/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:19:04] epoch: 0968/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:19:04] epoch: 0968/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:19:04] epoch: 0968/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:19:09] epoch: 0969/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:19:09] epoch: 0969/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:19:09] epoch: 0969/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:19:14] epoch: 0970/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:19:14] epoch: 0970/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:19:14] epoch: 0970/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:19:20] epoch: 0971/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:19:20] epoch: 0971/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:19:20] epoch: 0971/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:19:25] epoch: 0972/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:19:25] epoch: 0972/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:19:25] epoch: 0972/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:19:30] epoch: 0973/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:19:30] epoch: 0973/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:19:30] epoch: 0973/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:19:35] epoch: 0974/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:19:35] epoch: 0974/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:19:35] epoch: 0974/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:19:41] epoch: 0975/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:19:41] epoch: 0975/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:19:41] epoch: 0975/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:19:46] epoch: 0976/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:19:46] epoch: 0976/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:19:46] epoch: 0976/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:19:51] epoch: 0977/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:19:51] epoch: 0977/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:19:51] epoch: 0977/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:19:56] epoch: 0978/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:19:56] epoch: 0978/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:19:56] epoch: 0978/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:20:02] epoch: 0979/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:02] epoch: 0979/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:20:02] epoch: 0979/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:20:07] epoch: 0980/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:07] epoch: 0980/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:20:07] epoch: 0980/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:20:12] epoch: 0981/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:12] epoch: 0981/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:20:12] epoch: 0981/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:20:17] epoch: 0982/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:17] epoch: 0982/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:20:17] epoch: 0982/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:20:23] epoch: 0983/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:23] epoch: 0983/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:20:23] epoch: 0983/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:20:28] epoch: 0984/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:28] epoch: 0984/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:20:28] epoch: 0984/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:20:33] epoch: 0985/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:33] epoch: 0985/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:20:33] epoch: 0985/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:20:38] epoch: 0986/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:38] epoch: 0986/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:20:38] epoch: 0986/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:20:43] epoch: 0987/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:43] epoch: 0987/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:20:43] epoch: 0987/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:20:49] epoch: 0988/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:49] epoch: 0988/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:20:49] epoch: 0988/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:20:54] epoch: 0989/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:20:54] epoch: 0989/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:20:54] epoch: 0989/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:21:00] epoch: 0990/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:00] epoch: 0990/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:00] epoch: 0990/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:21:05] epoch: 0991/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:05] epoch: 0991/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:05] epoch: 0991/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:21:10] epoch: 0992/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:10] epoch: 0992/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:10] epoch: 0992/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:21:15] epoch: 0993/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:15] epoch: 0993/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:15] epoch: 0993/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:21:20] epoch: 0994/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:20] epoch: 0994/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:20] epoch: 0994/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:21:26] epoch: 0995/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:26] epoch: 0995/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:26] epoch: 0995/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:21:31] epoch: 0996/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:31] epoch: 0996/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:31] epoch: 0996/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:21:36] epoch: 0997/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:36] epoch: 0997/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:36] epoch: 0997/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:21:41] epoch: 0998/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:41] epoch: 0998/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:41] epoch: 0998/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:21:46] epoch: 0999/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:21:46] epoch: 0999/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:21:46] epoch: 0999/5000, generator loss: 0.6932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:21:52] epoch: 1000/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:52] epoch: 1000/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:52] epoch: 1000/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:21:57] epoch: 1001/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:21:57] epoch: 1001/5000, discriminator loss: 1.3858\n",
      "[LOG TRAIN 20200404-20:21:57] epoch: 1001/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:22:02] epoch: 1002/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:22:02] epoch: 1002/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:02] epoch: 1002/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:22:07] epoch: 1003/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:22:07] epoch: 1003/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:07] epoch: 1003/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:22:12] epoch: 1004/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:22:12] epoch: 1004/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:12] epoch: 1004/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:22:18] epoch: 1005/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:22:18] epoch: 1005/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:18] epoch: 1005/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:22:23] epoch: 1006/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:22:23] epoch: 1006/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:23] epoch: 1006/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:22:28] epoch: 1007/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:22:28] epoch: 1007/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:28] epoch: 1007/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:22:33] epoch: 1008/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:22:33] epoch: 1008/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:33] epoch: 1008/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:22:39] epoch: 1009/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:22:39] epoch: 1009/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:39] epoch: 1009/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:22:44] epoch: 1010/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:22:44] epoch: 1010/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:44] epoch: 1010/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:22:49] epoch: 1011/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:22:49] epoch: 1011/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:49] epoch: 1011/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:22:54] epoch: 1012/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:22:54] epoch: 1012/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:22:54] epoch: 1012/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:23:00] epoch: 1013/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:23:00] epoch: 1013/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:00] epoch: 1013/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:23:05] epoch: 1014/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:23:05] epoch: 1014/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:05] epoch: 1014/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:23:10] epoch: 1015/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:23:10] epoch: 1015/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:10] epoch: 1015/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:23:16] epoch: 1016/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:23:16] epoch: 1016/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:16] epoch: 1016/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:23:21] epoch: 1017/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:23:21] epoch: 1017/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:21] epoch: 1017/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:23:26] epoch: 1018/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:23:26] epoch: 1018/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:26] epoch: 1018/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:23:31] epoch: 1019/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:23:31] epoch: 1019/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:31] epoch: 1019/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:23:36] epoch: 1020/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:23:36] epoch: 1020/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:36] epoch: 1020/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:23:42] epoch: 1021/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:23:42] epoch: 1021/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:42] epoch: 1021/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:23:47] epoch: 1022/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:23:47] epoch: 1022/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:47] epoch: 1022/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:23:52] epoch: 1023/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:23:52] epoch: 1023/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:52] epoch: 1023/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:23:57] epoch: 1024/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:23:57] epoch: 1024/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:23:57] epoch: 1024/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:24:03] epoch: 1025/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:24:03] epoch: 1025/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:03] epoch: 1025/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:24:08] epoch: 1026/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:24:08] epoch: 1026/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:08] epoch: 1026/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:24:13] epoch: 1027/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:24:13] epoch: 1027/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:13] epoch: 1027/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:24:19] epoch: 1028/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:24:19] epoch: 1028/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:19] epoch: 1028/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:24:24] epoch: 1029/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:24:24] epoch: 1029/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:24] epoch: 1029/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:24:29] epoch: 1030/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:24:29] epoch: 1030/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:29] epoch: 1030/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:24:35] epoch: 1031/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:24:35] epoch: 1031/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:35] epoch: 1031/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:24:40] epoch: 1032/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:24:40] epoch: 1032/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:40] epoch: 1032/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:24:45] epoch: 1033/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:24:45] epoch: 1033/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:45] epoch: 1033/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:24:50] epoch: 1034/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:24:50] epoch: 1034/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:50] epoch: 1034/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:24:55] epoch: 1035/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:24:55] epoch: 1035/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:24:55] epoch: 1035/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:25:01] epoch: 1036/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:25:01] epoch: 1036/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:01] epoch: 1036/5000, generator loss: 0.6934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:25:06] epoch: 1037/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:25:06] epoch: 1037/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:06] epoch: 1037/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:25:11] epoch: 1038/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:25:11] epoch: 1038/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:11] epoch: 1038/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:25:16] epoch: 1039/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:25:16] epoch: 1039/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:16] epoch: 1039/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:25:22] epoch: 1040/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:25:22] epoch: 1040/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:22] epoch: 1040/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:25:27] epoch: 1041/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:25:27] epoch: 1041/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:27] epoch: 1041/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:25:32] epoch: 1042/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:25:32] epoch: 1042/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:32] epoch: 1042/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:25:37] epoch: 1043/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:25:37] epoch: 1043/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:37] epoch: 1043/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:25:43] epoch: 1044/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:25:43] epoch: 1044/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:43] epoch: 1044/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:25:48] epoch: 1045/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:25:48] epoch: 1045/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:48] epoch: 1045/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:25:53] epoch: 1046/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:25:53] epoch: 1046/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:53] epoch: 1046/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:25:58] epoch: 1047/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:25:58] epoch: 1047/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:25:58] epoch: 1047/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:26:03] epoch: 1048/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:26:03] epoch: 1048/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:26:03] epoch: 1048/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:26:09] epoch: 1049/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200404-20:26:09] epoch: 1049/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:26:09] epoch: 1049/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:26:14] epoch: 1050/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:26:14] epoch: 1050/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:26:14] epoch: 1050/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:26:19] epoch: 1051/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200404-20:26:19] epoch: 1051/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:26:19] epoch: 1051/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:26:24] epoch: 1052/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-20:26:24] epoch: 1052/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:26:24] epoch: 1052/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:26:30] epoch: 1053/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-20:26:30] epoch: 1053/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:26:30] epoch: 1053/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:26:35] epoch: 1054/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-20:26:35] epoch: 1054/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:26:35] epoch: 1054/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:26:40] epoch: 1055/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200404-20:26:40] epoch: 1055/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:26:40] epoch: 1055/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:26:45] epoch: 1056/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-20:26:45] epoch: 1056/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:26:45] epoch: 1056/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:26:51] epoch: 1057/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-20:26:51] epoch: 1057/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:26:51] epoch: 1057/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:26:56] epoch: 1058/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:26:56] epoch: 1058/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:26:56] epoch: 1058/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:02] epoch: 1059/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200404-20:27:02] epoch: 1059/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:02] epoch: 1059/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:07] epoch: 1060/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200404-20:27:07] epoch: 1060/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:07] epoch: 1060/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:12] epoch: 1061/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200404-20:27:12] epoch: 1061/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:12] epoch: 1061/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:17] epoch: 1062/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:27:17] epoch: 1062/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:17] epoch: 1062/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:23] epoch: 1063/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200404-20:27:23] epoch: 1063/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:23] epoch: 1063/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:28] epoch: 1064/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:27:28] epoch: 1064/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:28] epoch: 1064/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:33] epoch: 1065/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:27:33] epoch: 1065/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:33] epoch: 1065/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:38] epoch: 1066/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:27:38] epoch: 1066/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:38] epoch: 1066/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:44] epoch: 1067/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:27:44] epoch: 1067/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:44] epoch: 1067/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:49] epoch: 1068/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:27:49] epoch: 1068/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:49] epoch: 1068/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:54] epoch: 1069/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:27:54] epoch: 1069/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:54] epoch: 1069/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:27:59] epoch: 1070/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:27:59] epoch: 1070/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:27:59] epoch: 1070/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:28:05] epoch: 1071/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:28:05] epoch: 1071/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:05] epoch: 1071/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:28:10] epoch: 1072/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:28:10] epoch: 1072/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:10] epoch: 1072/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:28:15] epoch: 1073/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:28:15] epoch: 1073/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:15] epoch: 1073/5000, generator loss: 0.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:28:20] epoch: 1074/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:28:20] epoch: 1074/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:20] epoch: 1074/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:28:26] epoch: 1075/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200404-20:28:26] epoch: 1075/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:26] epoch: 1075/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:28:31] epoch: 1076/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:28:31] epoch: 1076/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:31] epoch: 1076/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:28:36] epoch: 1077/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200404-20:28:36] epoch: 1077/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:36] epoch: 1077/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:28:41] epoch: 1078/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200404-20:28:41] epoch: 1078/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:41] epoch: 1078/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:28:47] epoch: 1079/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200404-20:28:47] epoch: 1079/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:47] epoch: 1079/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:28:52] epoch: 1080/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:28:52] epoch: 1080/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:52] epoch: 1080/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:28:57] epoch: 1081/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200404-20:28:57] epoch: 1081/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:28:57] epoch: 1081/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:29:02] epoch: 1082/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:29:02] epoch: 1082/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:29:02] epoch: 1082/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:29:07] epoch: 1083/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:29:07] epoch: 1083/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:29:07] epoch: 1083/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:29:13] epoch: 1084/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:29:13] epoch: 1084/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:29:13] epoch: 1084/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:29:18] epoch: 1085/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200404-20:29:18] epoch: 1085/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:29:18] epoch: 1085/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:29:23] epoch: 1086/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-20:29:23] epoch: 1086/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:29:23] epoch: 1086/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:29:28] epoch: 1087/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-20:29:28] epoch: 1087/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:29:28] epoch: 1087/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:29:34] epoch: 1088/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200404-20:29:34] epoch: 1088/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:29:34] epoch: 1088/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:29:39] epoch: 1089/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:29:39] epoch: 1089/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:29:39] epoch: 1089/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:29:44] epoch: 1090/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200404-20:29:44] epoch: 1090/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:29:44] epoch: 1090/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:29:50] epoch: 1091/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-20:29:50] epoch: 1091/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:29:50] epoch: 1091/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:29:55] epoch: 1092/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:29:55] epoch: 1092/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:29:55] epoch: 1092/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:30:01] epoch: 1093/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:30:01] epoch: 1093/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:30:01] epoch: 1093/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:30:06] epoch: 1094/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-20:30:06] epoch: 1094/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:30:06] epoch: 1094/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:30:11] epoch: 1095/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-20:30:11] epoch: 1095/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:30:11] epoch: 1095/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:30:16] epoch: 1096/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-20:30:16] epoch: 1096/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:30:16] epoch: 1096/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:30:22] epoch: 1097/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-20:30:22] epoch: 1097/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:30:22] epoch: 1097/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:30:27] epoch: 1098/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-20:30:27] epoch: 1098/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:30:27] epoch: 1098/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:30:32] epoch: 1099/5000, reconstruction loss: 0.0257\n",
      "[LOG TRAIN 20200404-20:30:32] epoch: 1099/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:30:32] epoch: 1099/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:30:38] epoch: 1100/5000, reconstruction loss: 0.0240\n",
      "[LOG TRAIN 20200404-20:30:38] epoch: 1100/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:30:38] epoch: 1100/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:30:43] epoch: 1101/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200404-20:30:43] epoch: 1101/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:30:43] epoch: 1101/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:30:48] epoch: 1102/5000, reconstruction loss: 0.0227\n",
      "[LOG TRAIN 20200404-20:30:48] epoch: 1102/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:30:48] epoch: 1102/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:30:54] epoch: 1103/5000, reconstruction loss: 0.0255\n",
      "[LOG TRAIN 20200404-20:30:54] epoch: 1103/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:30:54] epoch: 1103/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:30:59] epoch: 1104/5000, reconstruction loss: 0.0236\n",
      "[LOG TRAIN 20200404-20:30:59] epoch: 1104/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:30:59] epoch: 1104/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:31:04] epoch: 1105/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-20:31:04] epoch: 1105/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:04] epoch: 1105/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:31:09] epoch: 1106/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-20:31:09] epoch: 1106/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:09] epoch: 1106/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:31:15] epoch: 1107/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-20:31:15] epoch: 1107/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:15] epoch: 1107/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:31:20] epoch: 1108/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:31:20] epoch: 1108/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:20] epoch: 1108/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:31:25] epoch: 1109/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-20:31:25] epoch: 1109/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:25] epoch: 1109/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:31:31] epoch: 1110/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-20:31:31] epoch: 1110/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:31] epoch: 1110/5000, generator loss: 0.6934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:31:36] epoch: 1111/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-20:31:36] epoch: 1111/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:36] epoch: 1111/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:31:41] epoch: 1112/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-20:31:41] epoch: 1112/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:41] epoch: 1112/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:31:47] epoch: 1113/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-20:31:47] epoch: 1113/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:47] epoch: 1113/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:31:52] epoch: 1114/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-20:31:52] epoch: 1114/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:52] epoch: 1114/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:31:57] epoch: 1115/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-20:31:57] epoch: 1115/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:31:57] epoch: 1115/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:32:02] epoch: 1116/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-20:32:02] epoch: 1116/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:02] epoch: 1116/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:32:08] epoch: 1117/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-20:32:08] epoch: 1117/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:08] epoch: 1117/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:32:13] epoch: 1118/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-20:32:13] epoch: 1118/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:13] epoch: 1118/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:32:18] epoch: 1119/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:32:18] epoch: 1119/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:18] epoch: 1119/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:32:24] epoch: 1120/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:32:24] epoch: 1120/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:24] epoch: 1120/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:32:29] epoch: 1121/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:32:29] epoch: 1121/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:29] epoch: 1121/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:32:34] epoch: 1122/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:32:34] epoch: 1122/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:34] epoch: 1122/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:32:40] epoch: 1123/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:32:40] epoch: 1123/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:40] epoch: 1123/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:32:45] epoch: 1124/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:32:45] epoch: 1124/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:45] epoch: 1124/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:32:50] epoch: 1125/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:32:50] epoch: 1125/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:50] epoch: 1125/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:32:55] epoch: 1126/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:32:55] epoch: 1126/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:32:55] epoch: 1126/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:33:01] epoch: 1127/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:33:01] epoch: 1127/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:01] epoch: 1127/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:33:06] epoch: 1128/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:33:06] epoch: 1128/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:06] epoch: 1128/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:33:12] epoch: 1129/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:33:12] epoch: 1129/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:12] epoch: 1129/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:33:17] epoch: 1130/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:33:17] epoch: 1130/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:17] epoch: 1130/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:33:22] epoch: 1131/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:33:22] epoch: 1131/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:22] epoch: 1131/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:33:27] epoch: 1132/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:33:27] epoch: 1132/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:27] epoch: 1132/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:33:33] epoch: 1133/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:33:33] epoch: 1133/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:33] epoch: 1133/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:33:38] epoch: 1134/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:33:38] epoch: 1134/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:38] epoch: 1134/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:33:43] epoch: 1135/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:33:43] epoch: 1135/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:43] epoch: 1135/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:33:49] epoch: 1136/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:33:49] epoch: 1136/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:49] epoch: 1136/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:33:54] epoch: 1137/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:33:54] epoch: 1137/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:33:54] epoch: 1137/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:33:59] epoch: 1138/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:33:59] epoch: 1138/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:33:59] epoch: 1138/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:34:05] epoch: 1139/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:34:05] epoch: 1139/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:34:05] epoch: 1139/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:34:10] epoch: 1140/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:34:10] epoch: 1140/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:34:10] epoch: 1140/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:34:15] epoch: 1141/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-20:34:15] epoch: 1141/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:34:15] epoch: 1141/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:34:20] epoch: 1142/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:34:20] epoch: 1142/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:34:20] epoch: 1142/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:34:26] epoch: 1143/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:34:26] epoch: 1143/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:34:26] epoch: 1143/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:34:31] epoch: 1144/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:34:31] epoch: 1144/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:34:31] epoch: 1144/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:34:36] epoch: 1145/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:34:36] epoch: 1145/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:34:36] epoch: 1145/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:34:42] epoch: 1146/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:34:42] epoch: 1146/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:34:42] epoch: 1146/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:34:47] epoch: 1147/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:34:47] epoch: 1147/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:34:47] epoch: 1147/5000, generator loss: 0.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:34:52] epoch: 1148/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:34:52] epoch: 1148/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:34:52] epoch: 1148/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:34:58] epoch: 1149/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:34:58] epoch: 1149/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:34:58] epoch: 1149/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:35:03] epoch: 1150/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:35:03] epoch: 1150/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:35:03] epoch: 1150/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:35:08] epoch: 1151/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:35:08] epoch: 1151/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:35:08] epoch: 1151/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:35:13] epoch: 1152/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:35:13] epoch: 1152/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:35:13] epoch: 1152/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:35:19] epoch: 1153/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:35:19] epoch: 1153/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:35:19] epoch: 1153/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:35:24] epoch: 1154/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:35:24] epoch: 1154/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:35:24] epoch: 1154/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:35:29] epoch: 1155/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:35:29] epoch: 1155/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:35:29] epoch: 1155/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:35:35] epoch: 1156/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:35:35] epoch: 1156/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:35:35] epoch: 1156/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:35:40] epoch: 1157/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:35:40] epoch: 1157/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:35:40] epoch: 1157/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:35:45] epoch: 1158/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:35:45] epoch: 1158/5000, discriminator loss: 1.3857\n",
      "[LOG TRAIN 20200404-20:35:45] epoch: 1158/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:35:50] epoch: 1159/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:35:50] epoch: 1159/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:35:50] epoch: 1159/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:35:56] epoch: 1160/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:35:56] epoch: 1160/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:35:56] epoch: 1160/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:36:01] epoch: 1161/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:36:01] epoch: 1161/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:01] epoch: 1161/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:36:07] epoch: 1162/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:36:07] epoch: 1162/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:07] epoch: 1162/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:36:12] epoch: 1163/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:36:12] epoch: 1163/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:12] epoch: 1163/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:36:17] epoch: 1164/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:36:17] epoch: 1164/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:17] epoch: 1164/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:36:23] epoch: 1165/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:36:23] epoch: 1165/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:23] epoch: 1165/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:36:28] epoch: 1166/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:36:28] epoch: 1166/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:28] epoch: 1166/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:36:33] epoch: 1167/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:36:33] epoch: 1167/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:33] epoch: 1167/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:36:39] epoch: 1168/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:36:39] epoch: 1168/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:39] epoch: 1168/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:36:44] epoch: 1169/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:36:44] epoch: 1169/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:44] epoch: 1169/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:36:49] epoch: 1170/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:36:49] epoch: 1170/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:49] epoch: 1170/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:36:54] epoch: 1171/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:36:54] epoch: 1171/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:36:54] epoch: 1171/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:37:00] epoch: 1172/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:37:00] epoch: 1172/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:00] epoch: 1172/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:37:05] epoch: 1173/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:37:05] epoch: 1173/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:05] epoch: 1173/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:37:10] epoch: 1174/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:37:10] epoch: 1174/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:10] epoch: 1174/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:37:16] epoch: 1175/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:37:16] epoch: 1175/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:16] epoch: 1175/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:37:21] epoch: 1176/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:37:21] epoch: 1176/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:21] epoch: 1176/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:37:26] epoch: 1177/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:37:26] epoch: 1177/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:26] epoch: 1177/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:37:31] epoch: 1178/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:37:31] epoch: 1178/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:31] epoch: 1178/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:37:37] epoch: 1179/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:37:37] epoch: 1179/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:37] epoch: 1179/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:37:42] epoch: 1180/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:37:42] epoch: 1180/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:42] epoch: 1180/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:37:47] epoch: 1181/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:37:47] epoch: 1181/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:47] epoch: 1181/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:37:53] epoch: 1182/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:37:53] epoch: 1182/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:53] epoch: 1182/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:37:58] epoch: 1183/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:37:58] epoch: 1183/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:37:58] epoch: 1183/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:38:03] epoch: 1184/5000, reconstruction loss: 0.0219\n",
      "[LOG TRAIN 20200404-20:38:03] epoch: 1184/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:38:03] epoch: 1184/5000, generator loss: 0.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:38:08] epoch: 1185/5000, reconstruction loss: 0.0265\n",
      "[LOG TRAIN 20200404-20:38:08] epoch: 1185/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:38:08] epoch: 1185/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:38:14] epoch: 1186/5000, reconstruction loss: 0.0248\n",
      "[LOG TRAIN 20200404-20:38:14] epoch: 1186/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:38:14] epoch: 1186/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:38:19] epoch: 1187/5000, reconstruction loss: 0.0248\n",
      "[LOG TRAIN 20200404-20:38:19] epoch: 1187/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:38:19] epoch: 1187/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:38:24] epoch: 1188/5000, reconstruction loss: 0.0226\n",
      "[LOG TRAIN 20200404-20:38:24] epoch: 1188/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:38:24] epoch: 1188/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:38:30] epoch: 1189/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200404-20:38:30] epoch: 1189/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:38:30] epoch: 1189/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:38:35] epoch: 1190/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:38:35] epoch: 1190/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:38:35] epoch: 1190/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:38:40] epoch: 1191/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-20:38:40] epoch: 1191/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:38:40] epoch: 1191/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:38:46] epoch: 1192/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:38:46] epoch: 1192/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:38:46] epoch: 1192/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:38:51] epoch: 1193/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:38:51] epoch: 1193/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:38:51] epoch: 1193/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:38:56] epoch: 1194/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:38:56] epoch: 1194/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:38:56] epoch: 1194/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:39:02] epoch: 1195/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:39:02] epoch: 1195/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:02] epoch: 1195/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:39:07] epoch: 1196/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:39:07] epoch: 1196/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:07] epoch: 1196/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:39:12] epoch: 1197/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:39:12] epoch: 1197/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:12] epoch: 1197/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:39:18] epoch: 1198/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:39:18] epoch: 1198/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:18] epoch: 1198/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-20:39:23] epoch: 1199/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:39:23] epoch: 1199/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:23] epoch: 1199/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:39:28] epoch: 1200/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:39:28] epoch: 1200/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:28] epoch: 1200/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-20:39:34] epoch: 1201/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:39:34] epoch: 1201/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:34] epoch: 1201/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-20:39:39] epoch: 1202/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:39:39] epoch: 1202/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:39] epoch: 1202/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-20:39:44] epoch: 1203/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:39:44] epoch: 1203/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:44] epoch: 1203/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-20:39:50] epoch: 1204/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:39:50] epoch: 1204/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:50] epoch: 1204/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-20:39:55] epoch: 1205/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:39:55] epoch: 1205/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:39:55] epoch: 1205/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-20:40:00] epoch: 1206/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:00] epoch: 1206/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:40:00] epoch: 1206/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-20:40:06] epoch: 1207/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:06] epoch: 1207/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:06] epoch: 1207/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-20:40:11] epoch: 1208/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:11] epoch: 1208/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:11] epoch: 1208/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-20:40:16] epoch: 1209/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:16] epoch: 1209/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:16] epoch: 1209/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-20:40:21] epoch: 1210/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:21] epoch: 1210/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:21] epoch: 1210/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:40:27] epoch: 1211/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:27] epoch: 1211/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:27] epoch: 1211/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:40:32] epoch: 1212/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:32] epoch: 1212/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:32] epoch: 1212/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-20:40:37] epoch: 1213/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:37] epoch: 1213/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:37] epoch: 1213/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:40:43] epoch: 1214/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:43] epoch: 1214/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:43] epoch: 1214/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:40:48] epoch: 1215/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:48] epoch: 1215/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:48] epoch: 1215/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:40:53] epoch: 1216/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:53] epoch: 1216/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:53] epoch: 1216/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:40:59] epoch: 1217/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:40:59] epoch: 1217/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:40:59] epoch: 1217/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:41:04] epoch: 1218/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:04] epoch: 1218/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:04] epoch: 1218/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:41:09] epoch: 1219/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:09] epoch: 1219/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:09] epoch: 1219/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:41:15] epoch: 1220/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:15] epoch: 1220/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:15] epoch: 1220/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:41:20] epoch: 1221/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:20] epoch: 1221/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:20] epoch: 1221/5000, generator loss: 0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:41:25] epoch: 1222/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:25] epoch: 1222/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:25] epoch: 1222/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:41:31] epoch: 1223/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:31] epoch: 1223/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:31] epoch: 1223/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:41:36] epoch: 1224/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:36] epoch: 1224/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:36] epoch: 1224/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-20:41:41] epoch: 1225/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:41] epoch: 1225/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:41] epoch: 1225/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-20:41:46] epoch: 1226/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:46] epoch: 1226/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:46] epoch: 1226/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-20:41:52] epoch: 1227/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:52] epoch: 1227/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:52] epoch: 1227/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:41:57] epoch: 1228/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:41:57] epoch: 1228/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:41:57] epoch: 1228/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:42:03] epoch: 1229/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:42:03] epoch: 1229/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:42:03] epoch: 1229/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:42:08] epoch: 1230/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:42:08] epoch: 1230/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:42:08] epoch: 1230/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:42:14] epoch: 1231/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:42:14] epoch: 1231/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:42:14] epoch: 1231/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:42:19] epoch: 1232/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:42:19] epoch: 1232/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:42:19] epoch: 1232/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:42:24] epoch: 1233/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:42:24] epoch: 1233/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:42:24] epoch: 1233/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:42:29] epoch: 1234/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:42:29] epoch: 1234/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:42:29] epoch: 1234/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:42:35] epoch: 1235/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:42:35] epoch: 1235/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:42:35] epoch: 1235/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:42:40] epoch: 1236/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:42:40] epoch: 1236/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:42:40] epoch: 1236/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-20:42:45] epoch: 1237/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:42:45] epoch: 1237/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:42:45] epoch: 1237/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:42:50] epoch: 1238/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:42:50] epoch: 1238/5000, discriminator loss: 1.3856\n",
      "[LOG TRAIN 20200404-20:42:50] epoch: 1238/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-20:42:56] epoch: 1239/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:42:56] epoch: 1239/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:42:56] epoch: 1239/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:43:01] epoch: 1240/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:43:01] epoch: 1240/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:01] epoch: 1240/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:43:06] epoch: 1241/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:43:06] epoch: 1241/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:06] epoch: 1241/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:43:12] epoch: 1242/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:43:12] epoch: 1242/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:12] epoch: 1242/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:43:17] epoch: 1243/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:43:17] epoch: 1243/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:17] epoch: 1243/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-20:43:22] epoch: 1244/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:43:22] epoch: 1244/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:22] epoch: 1244/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-20:43:27] epoch: 1245/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:43:27] epoch: 1245/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:27] epoch: 1245/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-20:43:33] epoch: 1246/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:43:33] epoch: 1246/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:33] epoch: 1246/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-20:43:38] epoch: 1247/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:43:38] epoch: 1247/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:38] epoch: 1247/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:43:43] epoch: 1248/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:43:43] epoch: 1248/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:43] epoch: 1248/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:43:49] epoch: 1249/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:43:49] epoch: 1249/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:49] epoch: 1249/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:43:54] epoch: 1250/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:43:54] epoch: 1250/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:54] epoch: 1250/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:43:59] epoch: 1251/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:43:59] epoch: 1251/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:43:59] epoch: 1251/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:44:04] epoch: 1252/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:44:04] epoch: 1252/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:04] epoch: 1252/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:44:10] epoch: 1253/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:44:10] epoch: 1253/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:10] epoch: 1253/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:44:15] epoch: 1254/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:44:15] epoch: 1254/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:15] epoch: 1254/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:44:20] epoch: 1255/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:44:20] epoch: 1255/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:20] epoch: 1255/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:44:26] epoch: 1256/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:44:26] epoch: 1256/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:26] epoch: 1256/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:44:31] epoch: 1257/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:44:31] epoch: 1257/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:31] epoch: 1257/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:44:36] epoch: 1258/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:44:36] epoch: 1258/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:36] epoch: 1258/5000, generator loss: 0.6937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:44:41] epoch: 1259/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:44:41] epoch: 1259/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:41] epoch: 1259/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:44:47] epoch: 1260/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:44:47] epoch: 1260/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:47] epoch: 1260/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:44:52] epoch: 1261/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:44:52] epoch: 1261/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:52] epoch: 1261/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:44:57] epoch: 1262/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:44:57] epoch: 1262/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:44:57] epoch: 1262/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:45:03] epoch: 1263/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:45:03] epoch: 1263/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:03] epoch: 1263/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:45:08] epoch: 1264/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:45:08] epoch: 1264/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:08] epoch: 1264/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:45:14] epoch: 1265/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:45:14] epoch: 1265/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:14] epoch: 1265/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:45:19] epoch: 1266/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:45:19] epoch: 1266/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:19] epoch: 1266/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:45:24] epoch: 1267/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:45:24] epoch: 1267/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:24] epoch: 1267/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:45:29] epoch: 1268/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:45:29] epoch: 1268/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:29] epoch: 1268/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:45:35] epoch: 1269/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:45:35] epoch: 1269/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:35] epoch: 1269/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:45:40] epoch: 1270/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:45:40] epoch: 1270/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:40] epoch: 1270/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:45:45] epoch: 1271/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:45:45] epoch: 1271/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:45] epoch: 1271/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:45:51] epoch: 1272/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:45:51] epoch: 1272/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:51] epoch: 1272/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:45:56] epoch: 1273/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:45:56] epoch: 1273/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:45:56] epoch: 1273/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:46:01] epoch: 1274/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:46:01] epoch: 1274/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:01] epoch: 1274/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:46:06] epoch: 1275/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:46:06] epoch: 1275/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:06] epoch: 1275/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:46:11] epoch: 1276/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:46:11] epoch: 1276/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:11] epoch: 1276/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:46:17] epoch: 1277/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:46:17] epoch: 1277/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:17] epoch: 1277/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:46:22] epoch: 1278/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:46:22] epoch: 1278/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:22] epoch: 1278/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:46:27] epoch: 1279/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:46:27] epoch: 1279/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:27] epoch: 1279/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:46:32] epoch: 1280/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:46:32] epoch: 1280/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:32] epoch: 1280/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:46:38] epoch: 1281/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:46:38] epoch: 1281/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:38] epoch: 1281/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:46:43] epoch: 1282/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:46:43] epoch: 1282/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:43] epoch: 1282/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:46:48] epoch: 1283/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:46:48] epoch: 1283/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:48] epoch: 1283/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:46:54] epoch: 1284/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:46:54] epoch: 1284/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:54] epoch: 1284/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:46:59] epoch: 1285/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:46:59] epoch: 1285/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:46:59] epoch: 1285/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:47:04] epoch: 1286/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-20:47:04] epoch: 1286/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:04] epoch: 1286/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:47:09] epoch: 1287/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:47:09] epoch: 1287/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:09] epoch: 1287/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:47:15] epoch: 1288/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:47:15] epoch: 1288/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:15] epoch: 1288/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:47:20] epoch: 1289/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:47:20] epoch: 1289/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:20] epoch: 1289/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:47:25] epoch: 1290/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:47:25] epoch: 1290/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:25] epoch: 1290/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:47:30] epoch: 1291/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:47:30] epoch: 1291/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:30] epoch: 1291/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:47:36] epoch: 1292/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:47:36] epoch: 1292/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:36] epoch: 1292/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:47:41] epoch: 1293/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:47:41] epoch: 1293/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:41] epoch: 1293/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:47:46] epoch: 1294/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:47:46] epoch: 1294/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:46] epoch: 1294/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:47:51] epoch: 1295/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:47:51] epoch: 1295/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:51] epoch: 1295/5000, generator loss: 0.6934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:47:57] epoch: 1296/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:47:57] epoch: 1296/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:47:57] epoch: 1296/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:02] epoch: 1297/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:48:02] epoch: 1297/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:02] epoch: 1297/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:08] epoch: 1298/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:48:08] epoch: 1298/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:08] epoch: 1298/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:13] epoch: 1299/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-20:48:13] epoch: 1299/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:13] epoch: 1299/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:18] epoch: 1300/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:48:18] epoch: 1300/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:18] epoch: 1300/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:23] epoch: 1301/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:48:23] epoch: 1301/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:23] epoch: 1301/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:29] epoch: 1302/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:48:29] epoch: 1302/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:29] epoch: 1302/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:34] epoch: 1303/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:48:34] epoch: 1303/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:34] epoch: 1303/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:39] epoch: 1304/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:48:39] epoch: 1304/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:39] epoch: 1304/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:44] epoch: 1305/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:48:44] epoch: 1305/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:44] epoch: 1305/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:50] epoch: 1306/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:48:50] epoch: 1306/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:50] epoch: 1306/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:48:55] epoch: 1307/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-20:48:55] epoch: 1307/5000, discriminator loss: 1.3855\n",
      "[LOG TRAIN 20200404-20:48:55] epoch: 1307/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:49:00] epoch: 1308/5000, reconstruction loss: 0.0323\n",
      "[LOG TRAIN 20200404-20:49:00] epoch: 1308/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-20:49:00] epoch: 1308/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:49:05] epoch: 1309/5000, reconstruction loss: 0.0251\n",
      "[LOG TRAIN 20200404-20:49:05] epoch: 1309/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:49:05] epoch: 1309/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:49:10] epoch: 1310/5000, reconstruction loss: 0.0210\n",
      "[LOG TRAIN 20200404-20:49:10] epoch: 1310/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:49:10] epoch: 1310/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:49:16] epoch: 1311/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200404-20:49:16] epoch: 1311/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:49:16] epoch: 1311/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:49:21] epoch: 1312/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:49:21] epoch: 1312/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:49:21] epoch: 1312/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:49:26] epoch: 1313/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:49:26] epoch: 1313/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:49:26] epoch: 1313/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:49:31] epoch: 1314/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-20:49:31] epoch: 1314/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:49:31] epoch: 1314/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:49:37] epoch: 1315/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:49:37] epoch: 1315/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:49:37] epoch: 1315/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:49:42] epoch: 1316/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:49:42] epoch: 1316/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:49:42] epoch: 1316/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:49:47] epoch: 1317/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:49:47] epoch: 1317/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:49:47] epoch: 1317/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:49:52] epoch: 1318/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:49:52] epoch: 1318/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:49:52] epoch: 1318/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:49:58] epoch: 1319/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:49:58] epoch: 1319/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:49:58] epoch: 1319/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:50:03] epoch: 1320/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:50:03] epoch: 1320/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:03] epoch: 1320/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:50:08] epoch: 1321/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:50:08] epoch: 1321/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:08] epoch: 1321/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:50:13] epoch: 1322/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:50:13] epoch: 1322/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:13] epoch: 1322/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:50:18] epoch: 1323/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:50:18] epoch: 1323/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:18] epoch: 1323/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:50:24] epoch: 1324/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:50:24] epoch: 1324/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:24] epoch: 1324/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-20:50:29] epoch: 1325/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:50:29] epoch: 1325/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:29] epoch: 1325/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-20:50:34] epoch: 1326/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:50:34] epoch: 1326/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:34] epoch: 1326/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:50:39] epoch: 1327/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:50:39] epoch: 1327/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:39] epoch: 1327/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:50:45] epoch: 1328/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:50:45] epoch: 1328/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:45] epoch: 1328/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:50:50] epoch: 1329/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:50:50] epoch: 1329/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:50] epoch: 1329/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:50:55] epoch: 1330/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:50:55] epoch: 1330/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:50:55] epoch: 1330/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:51:01] epoch: 1331/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:51:01] epoch: 1331/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:01] epoch: 1331/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:51:06] epoch: 1332/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:51:06] epoch: 1332/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:06] epoch: 1332/5000, generator loss: 0.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:51:11] epoch: 1333/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:51:11] epoch: 1333/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:11] epoch: 1333/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:51:17] epoch: 1334/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:51:17] epoch: 1334/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:17] epoch: 1334/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-20:51:22] epoch: 1335/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:51:22] epoch: 1335/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:22] epoch: 1335/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-20:51:27] epoch: 1336/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:51:27] epoch: 1336/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:27] epoch: 1336/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:51:32] epoch: 1337/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:51:32] epoch: 1337/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:32] epoch: 1337/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:51:38] epoch: 1338/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:51:38] epoch: 1338/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:38] epoch: 1338/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:51:43] epoch: 1339/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:51:43] epoch: 1339/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:43] epoch: 1339/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:51:48] epoch: 1340/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:51:48] epoch: 1340/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:48] epoch: 1340/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:51:53] epoch: 1341/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:51:53] epoch: 1341/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:53] epoch: 1341/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:51:58] epoch: 1342/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:51:58] epoch: 1342/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:51:58] epoch: 1342/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:52:04] epoch: 1343/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:52:04] epoch: 1343/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:04] epoch: 1343/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:52:09] epoch: 1344/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:52:09] epoch: 1344/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:09] epoch: 1344/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:52:14] epoch: 1345/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:52:14] epoch: 1345/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:14] epoch: 1345/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:52:19] epoch: 1346/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:52:19] epoch: 1346/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:19] epoch: 1346/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:52:25] epoch: 1347/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:52:25] epoch: 1347/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:25] epoch: 1347/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:52:30] epoch: 1348/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:52:30] epoch: 1348/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:30] epoch: 1348/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:52:35] epoch: 1349/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:52:35] epoch: 1349/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:35] epoch: 1349/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:52:40] epoch: 1350/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:52:40] epoch: 1350/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:40] epoch: 1350/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:52:46] epoch: 1351/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:52:46] epoch: 1351/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:46] epoch: 1351/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:52:51] epoch: 1352/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:52:51] epoch: 1352/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:51] epoch: 1352/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:52:56] epoch: 1353/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:52:56] epoch: 1353/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:52:56] epoch: 1353/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:53:01] epoch: 1354/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:53:01] epoch: 1354/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:01] epoch: 1354/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:53:07] epoch: 1355/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:53:07] epoch: 1355/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:07] epoch: 1355/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:53:12] epoch: 1356/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:53:12] epoch: 1356/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:12] epoch: 1356/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:53:17] epoch: 1357/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:53:17] epoch: 1357/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:17] epoch: 1357/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:53:22] epoch: 1358/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:53:22] epoch: 1358/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:22] epoch: 1358/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:53:27] epoch: 1359/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:53:27] epoch: 1359/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:27] epoch: 1359/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:53:33] epoch: 1360/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:53:33] epoch: 1360/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:33] epoch: 1360/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:53:38] epoch: 1361/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:53:38] epoch: 1361/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:38] epoch: 1361/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:53:43] epoch: 1362/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:53:43] epoch: 1362/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:43] epoch: 1362/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-20:53:48] epoch: 1363/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:53:48] epoch: 1363/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:48] epoch: 1363/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:53:54] epoch: 1364/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:53:54] epoch: 1364/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:54] epoch: 1364/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:53:59] epoch: 1365/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:53:59] epoch: 1365/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:53:59] epoch: 1365/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:54:05] epoch: 1366/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:54:05] epoch: 1366/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:05] epoch: 1366/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:54:10] epoch: 1367/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:54:10] epoch: 1367/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:10] epoch: 1367/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:54:15] epoch: 1368/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:54:15] epoch: 1368/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:15] epoch: 1368/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-20:54:20] epoch: 1369/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:54:20] epoch: 1369/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:20] epoch: 1369/5000, generator loss: 0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:54:26] epoch: 1370/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:54:26] epoch: 1370/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:26] epoch: 1370/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:54:31] epoch: 1371/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:54:31] epoch: 1371/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:31] epoch: 1371/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-20:54:36] epoch: 1372/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:54:36] epoch: 1372/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:36] epoch: 1372/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:54:41] epoch: 1373/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:54:41] epoch: 1373/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:41] epoch: 1373/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-20:54:47] epoch: 1374/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:54:47] epoch: 1374/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:47] epoch: 1374/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:54:52] epoch: 1375/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:54:52] epoch: 1375/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:52] epoch: 1375/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:54:57] epoch: 1376/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:54:57] epoch: 1376/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:54:57] epoch: 1376/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-20:55:02] epoch: 1377/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:55:02] epoch: 1377/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:02] epoch: 1377/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:55:08] epoch: 1378/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:55:08] epoch: 1378/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:08] epoch: 1378/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-20:55:13] epoch: 1379/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:55:13] epoch: 1379/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:13] epoch: 1379/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:55:18] epoch: 1380/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:55:18] epoch: 1380/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:18] epoch: 1380/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:55:23] epoch: 1381/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:55:23] epoch: 1381/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:23] epoch: 1381/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:55:29] epoch: 1382/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:55:29] epoch: 1382/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:29] epoch: 1382/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:55:34] epoch: 1383/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:55:34] epoch: 1383/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:34] epoch: 1383/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:55:39] epoch: 1384/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:55:39] epoch: 1384/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:39] epoch: 1384/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:55:44] epoch: 1385/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:55:44] epoch: 1385/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:44] epoch: 1385/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:55:50] epoch: 1386/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:55:50] epoch: 1386/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:50] epoch: 1386/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:55:55] epoch: 1387/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:55:55] epoch: 1387/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:55:55] epoch: 1387/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:56:00] epoch: 1388/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:56:00] epoch: 1388/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:00] epoch: 1388/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:56:05] epoch: 1389/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:56:05] epoch: 1389/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:05] epoch: 1389/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:56:11] epoch: 1390/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:56:11] epoch: 1390/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:11] epoch: 1390/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:56:16] epoch: 1391/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:56:16] epoch: 1391/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:16] epoch: 1391/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:56:21] epoch: 1392/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:56:21] epoch: 1392/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:21] epoch: 1392/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:56:26] epoch: 1393/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:56:26] epoch: 1393/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:26] epoch: 1393/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:56:32] epoch: 1394/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:56:32] epoch: 1394/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:32] epoch: 1394/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:56:37] epoch: 1395/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:56:37] epoch: 1395/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:37] epoch: 1395/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:56:42] epoch: 1396/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:56:42] epoch: 1396/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:42] epoch: 1396/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:56:47] epoch: 1397/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:56:47] epoch: 1397/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:47] epoch: 1397/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:56:53] epoch: 1398/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:56:53] epoch: 1398/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:53] epoch: 1398/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:56:58] epoch: 1399/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:56:58] epoch: 1399/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:56:58] epoch: 1399/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:57:03] epoch: 1400/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:57:03] epoch: 1400/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:57:03] epoch: 1400/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:57:09] epoch: 1401/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:57:09] epoch: 1401/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:57:09] epoch: 1401/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:57:14] epoch: 1402/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:57:14] epoch: 1402/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:57:14] epoch: 1402/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:57:19] epoch: 1403/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:57:19] epoch: 1403/5000, discriminator loss: 1.3854\n",
      "[LOG TRAIN 20200404-20:57:19] epoch: 1403/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:57:25] epoch: 1404/5000, reconstruction loss: 0.0275\n",
      "[LOG TRAIN 20200404-20:57:25] epoch: 1404/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-20:57:25] epoch: 1404/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:57:30] epoch: 1405/5000, reconstruction loss: 0.0455\n",
      "[LOG TRAIN 20200404-20:57:30] epoch: 1405/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:57:30] epoch: 1405/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:57:35] epoch: 1406/5000, reconstruction loss: 0.0379\n",
      "[LOG TRAIN 20200404-20:57:35] epoch: 1406/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-20:57:35] epoch: 1406/5000, generator loss: 0.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-20:57:41] epoch: 1407/5000, reconstruction loss: 0.0257\n",
      "[LOG TRAIN 20200404-20:57:41] epoch: 1407/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-20:57:41] epoch: 1407/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:57:46] epoch: 1408/5000, reconstruction loss: 0.0216\n",
      "[LOG TRAIN 20200404-20:57:46] epoch: 1408/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:57:46] epoch: 1408/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:57:51] epoch: 1409/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-20:57:51] epoch: 1409/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-20:57:51] epoch: 1409/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:57:57] epoch: 1410/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-20:57:57] epoch: 1410/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:57:57] epoch: 1410/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:58:02] epoch: 1411/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-20:58:02] epoch: 1411/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:02] epoch: 1411/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:58:07] epoch: 1412/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-20:58:07] epoch: 1412/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:07] epoch: 1412/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-20:58:13] epoch: 1413/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-20:58:13] epoch: 1413/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:13] epoch: 1413/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-20:58:18] epoch: 1414/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-20:58:18] epoch: 1414/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:18] epoch: 1414/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:58:23] epoch: 1415/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:58:23] epoch: 1415/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:23] epoch: 1415/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-20:58:29] epoch: 1416/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-20:58:29] epoch: 1416/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:29] epoch: 1416/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-20:58:34] epoch: 1417/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:58:34] epoch: 1417/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:34] epoch: 1417/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-20:58:39] epoch: 1418/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:58:39] epoch: 1418/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:39] epoch: 1418/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:58:44] epoch: 1419/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:58:44] epoch: 1419/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:44] epoch: 1419/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:58:50] epoch: 1420/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:58:50] epoch: 1420/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:50] epoch: 1420/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:58:55] epoch: 1421/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:58:55] epoch: 1421/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:58:55] epoch: 1421/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-20:59:00] epoch: 1422/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:59:00] epoch: 1422/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:59:00] epoch: 1422/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-20:59:06] epoch: 1423/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-20:59:06] epoch: 1423/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:59:06] epoch: 1423/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-20:59:11] epoch: 1424/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-20:59:11] epoch: 1424/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:59:11] epoch: 1424/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-20:59:16] epoch: 1425/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:59:16] epoch: 1425/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:59:16] epoch: 1425/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-20:59:21] epoch: 1426/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-20:59:21] epoch: 1426/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:59:21] epoch: 1426/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-20:59:27] epoch: 1427/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-20:59:27] epoch: 1427/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-20:59:27] epoch: 1427/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-20:59:32] epoch: 1428/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-20:59:32] epoch: 1428/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-20:59:32] epoch: 1428/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-20:59:37] epoch: 1429/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-20:59:37] epoch: 1429/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-20:59:37] epoch: 1429/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-20:59:43] epoch: 1430/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-20:59:43] epoch: 1430/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-20:59:43] epoch: 1430/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:59:48] epoch: 1431/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-20:59:48] epoch: 1431/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-20:59:48] epoch: 1431/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:59:53] epoch: 1432/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-20:59:53] epoch: 1432/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-20:59:53] epoch: 1432/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-20:59:59] epoch: 1433/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-20:59:59] epoch: 1433/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-20:59:59] epoch: 1433/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:00:04] epoch: 1434/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:04] epoch: 1434/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:04] epoch: 1434/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:00:09] epoch: 1435/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:09] epoch: 1435/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:09] epoch: 1435/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:00:15] epoch: 1436/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:15] epoch: 1436/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:15] epoch: 1436/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:00:20] epoch: 1437/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:20] epoch: 1437/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:20] epoch: 1437/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:00:25] epoch: 1438/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:25] epoch: 1438/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:25] epoch: 1438/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:00:31] epoch: 1439/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:31] epoch: 1439/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:31] epoch: 1439/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:00:36] epoch: 1440/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:36] epoch: 1440/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:36] epoch: 1440/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:00:41] epoch: 1441/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:41] epoch: 1441/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:41] epoch: 1441/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:00:46] epoch: 1442/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:46] epoch: 1442/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:46] epoch: 1442/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:00:52] epoch: 1443/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:52] epoch: 1443/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:52] epoch: 1443/5000, generator loss: 0.6934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:00:57] epoch: 1444/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:00:57] epoch: 1444/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:00:57] epoch: 1444/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:01:02] epoch: 1445/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:01:02] epoch: 1445/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:02] epoch: 1445/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:01:08] epoch: 1446/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:01:08] epoch: 1446/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:08] epoch: 1446/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:01:13] epoch: 1447/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:01:13] epoch: 1447/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:13] epoch: 1447/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:01:18] epoch: 1448/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:01:18] epoch: 1448/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:18] epoch: 1448/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:01:23] epoch: 1449/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:01:23] epoch: 1449/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:23] epoch: 1449/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:01:29] epoch: 1450/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:01:29] epoch: 1450/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:29] epoch: 1450/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:01:34] epoch: 1451/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:01:34] epoch: 1451/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:34] epoch: 1451/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:01:39] epoch: 1452/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:01:39] epoch: 1452/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:39] epoch: 1452/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:01:44] epoch: 1453/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:01:44] epoch: 1453/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:44] epoch: 1453/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:01:50] epoch: 1454/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:01:50] epoch: 1454/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:50] epoch: 1454/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:01:55] epoch: 1455/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:01:55] epoch: 1455/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:01:55] epoch: 1455/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:02:00] epoch: 1456/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:02:00] epoch: 1456/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:00] epoch: 1456/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:02:06] epoch: 1457/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:02:06] epoch: 1457/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:06] epoch: 1457/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:02:11] epoch: 1458/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:02:11] epoch: 1458/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:11] epoch: 1458/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:02:16] epoch: 1459/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:02:16] epoch: 1459/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:16] epoch: 1459/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:02:22] epoch: 1460/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:02:22] epoch: 1460/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:22] epoch: 1460/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:02:27] epoch: 1461/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:02:27] epoch: 1461/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:27] epoch: 1461/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:02:32] epoch: 1462/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:02:32] epoch: 1462/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:32] epoch: 1462/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:02:37] epoch: 1463/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:02:37] epoch: 1463/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:37] epoch: 1463/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:02:43] epoch: 1464/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:02:43] epoch: 1464/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:43] epoch: 1464/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:02:48] epoch: 1465/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:02:48] epoch: 1465/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:48] epoch: 1465/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:02:53] epoch: 1466/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:02:53] epoch: 1466/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:53] epoch: 1466/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:02:59] epoch: 1467/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-21:02:59] epoch: 1467/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:02:59] epoch: 1467/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:03:04] epoch: 1468/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:03:04] epoch: 1468/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:04] epoch: 1468/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:03:10] epoch: 1469/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:03:10] epoch: 1469/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:10] epoch: 1469/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:03:15] epoch: 1470/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-21:03:15] epoch: 1470/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:15] epoch: 1470/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:03:20] epoch: 1471/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:03:20] epoch: 1471/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:20] epoch: 1471/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:03:26] epoch: 1472/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:03:26] epoch: 1472/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:26] epoch: 1472/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:03:31] epoch: 1473/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:03:31] epoch: 1473/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:31] epoch: 1473/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:03:36] epoch: 1474/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:03:36] epoch: 1474/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:36] epoch: 1474/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:03:41] epoch: 1475/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:03:41] epoch: 1475/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:41] epoch: 1475/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:03:47] epoch: 1476/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:03:47] epoch: 1476/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:47] epoch: 1476/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:03:52] epoch: 1477/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-21:03:52] epoch: 1477/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:52] epoch: 1477/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:03:57] epoch: 1478/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:03:57] epoch: 1478/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:03:57] epoch: 1478/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:04:02] epoch: 1479/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:04:02] epoch: 1479/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:02] epoch: 1479/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:04:08] epoch: 1480/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:04:08] epoch: 1480/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:08] epoch: 1480/5000, generator loss: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:04:13] epoch: 1481/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:04:13] epoch: 1481/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:13] epoch: 1481/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:04:18] epoch: 1482/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:04:18] epoch: 1482/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:18] epoch: 1482/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:04:24] epoch: 1483/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:04:24] epoch: 1483/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:24] epoch: 1483/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:04:29] epoch: 1484/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:04:29] epoch: 1484/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:29] epoch: 1484/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:04:34] epoch: 1485/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:04:34] epoch: 1485/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:34] epoch: 1485/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:04:39] epoch: 1486/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:04:39] epoch: 1486/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:39] epoch: 1486/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:04:45] epoch: 1487/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:04:45] epoch: 1487/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:45] epoch: 1487/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:04:50] epoch: 1488/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-21:04:50] epoch: 1488/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:50] epoch: 1488/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:04:55] epoch: 1489/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:04:55] epoch: 1489/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:04:55] epoch: 1489/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:05:01] epoch: 1490/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:05:01] epoch: 1490/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:01] epoch: 1490/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:05:06] epoch: 1491/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:05:06] epoch: 1491/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:06] epoch: 1491/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:05:11] epoch: 1492/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-21:05:11] epoch: 1492/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:11] epoch: 1492/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:05:16] epoch: 1493/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:05:16] epoch: 1493/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:16] epoch: 1493/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:05:22] epoch: 1494/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:05:22] epoch: 1494/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:22] epoch: 1494/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:05:27] epoch: 1495/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:05:27] epoch: 1495/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:27] epoch: 1495/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:05:32] epoch: 1496/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:05:32] epoch: 1496/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:32] epoch: 1496/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:05:38] epoch: 1497/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:05:38] epoch: 1497/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:38] epoch: 1497/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:05:43] epoch: 1498/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:05:43] epoch: 1498/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:43] epoch: 1498/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:05:48] epoch: 1499/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:05:48] epoch: 1499/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:48] epoch: 1499/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:05:53] epoch: 1500/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:05:53] epoch: 1500/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:53] epoch: 1500/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:05:59] epoch: 1501/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:05:59] epoch: 1501/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:05:59] epoch: 1501/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:06:04] epoch: 1502/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:06:04] epoch: 1502/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:04] epoch: 1502/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:06:10] epoch: 1503/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:06:10] epoch: 1503/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:10] epoch: 1503/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:06:15] epoch: 1504/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:06:15] epoch: 1504/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:15] epoch: 1504/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:06:20] epoch: 1505/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-21:06:20] epoch: 1505/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:20] epoch: 1505/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:06:26] epoch: 1506/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:06:26] epoch: 1506/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:26] epoch: 1506/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:06:31] epoch: 1507/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:06:31] epoch: 1507/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:31] epoch: 1507/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:06:36] epoch: 1508/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:06:36] epoch: 1508/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:36] epoch: 1508/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:06:42] epoch: 1509/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:06:42] epoch: 1509/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:42] epoch: 1509/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:06:47] epoch: 1510/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:06:47] epoch: 1510/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:47] epoch: 1510/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:06:52] epoch: 1511/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:06:52] epoch: 1511/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:52] epoch: 1511/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:06:57] epoch: 1512/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:06:57] epoch: 1512/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:06:57] epoch: 1512/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:07:03] epoch: 1513/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:07:03] epoch: 1513/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:03] epoch: 1513/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:07:08] epoch: 1514/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:07:08] epoch: 1514/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:08] epoch: 1514/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:07:13] epoch: 1515/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:07:13] epoch: 1515/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:13] epoch: 1515/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:07:19] epoch: 1516/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:07:19] epoch: 1516/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:19] epoch: 1516/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:07:24] epoch: 1517/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:07:24] epoch: 1517/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:24] epoch: 1517/5000, generator loss: 0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:07:29] epoch: 1518/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:07:29] epoch: 1518/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:29] epoch: 1518/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:07:35] epoch: 1519/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:07:35] epoch: 1519/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:35] epoch: 1519/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:07:40] epoch: 1520/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:07:40] epoch: 1520/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:40] epoch: 1520/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:07:45] epoch: 1521/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-21:07:45] epoch: 1521/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:45] epoch: 1521/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:07:51] epoch: 1522/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-21:07:51] epoch: 1522/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:51] epoch: 1522/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:07:56] epoch: 1523/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:07:56] epoch: 1523/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:07:56] epoch: 1523/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:08:01] epoch: 1524/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:08:01] epoch: 1524/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:08:01] epoch: 1524/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:08:07] epoch: 1525/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:08:07] epoch: 1525/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:08:07] epoch: 1525/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:08:12] epoch: 1526/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:08:12] epoch: 1526/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:08:12] epoch: 1526/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:08:17] epoch: 1527/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:08:17] epoch: 1527/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:08:17] epoch: 1527/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:08:22] epoch: 1528/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:08:22] epoch: 1528/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:08:22] epoch: 1528/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:08:28] epoch: 1529/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:08:28] epoch: 1529/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:08:28] epoch: 1529/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:08:33] epoch: 1530/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:08:33] epoch: 1530/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:08:33] epoch: 1530/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:08:38] epoch: 1531/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:08:38] epoch: 1531/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:08:38] epoch: 1531/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:08:43] epoch: 1532/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:08:43] epoch: 1532/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:08:43] epoch: 1532/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:08:49] epoch: 1533/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-21:08:49] epoch: 1533/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:08:49] epoch: 1533/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:08:54] epoch: 1534/5000, reconstruction loss: 0.0234\n",
      "[LOG TRAIN 20200404-21:08:54] epoch: 1534/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:08:54] epoch: 1534/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:09:00] epoch: 1535/5000, reconstruction loss: 0.0254\n",
      "[LOG TRAIN 20200404-21:09:00] epoch: 1535/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:09:00] epoch: 1535/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:09:05] epoch: 1536/5000, reconstruction loss: 0.0234\n",
      "[LOG TRAIN 20200404-21:09:05] epoch: 1536/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:09:05] epoch: 1536/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:09:10] epoch: 1537/5000, reconstruction loss: 0.0213\n",
      "[LOG TRAIN 20200404-21:09:10] epoch: 1537/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:09:10] epoch: 1537/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:09:16] epoch: 1538/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-21:09:16] epoch: 1538/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:09:16] epoch: 1538/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:09:21] epoch: 1539/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200404-21:09:21] epoch: 1539/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:09:21] epoch: 1539/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:09:26] epoch: 1540/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-21:09:26] epoch: 1540/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:09:26] epoch: 1540/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:09:31] epoch: 1541/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-21:09:31] epoch: 1541/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:09:31] epoch: 1541/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:09:37] epoch: 1542/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:09:37] epoch: 1542/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:09:37] epoch: 1542/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:09:42] epoch: 1543/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:09:42] epoch: 1543/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:09:42] epoch: 1543/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:09:47] epoch: 1544/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:09:47] epoch: 1544/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:09:47] epoch: 1544/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:09:52] epoch: 1545/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:09:52] epoch: 1545/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:09:52] epoch: 1545/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:09:58] epoch: 1546/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:09:58] epoch: 1546/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:09:58] epoch: 1546/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:10:03] epoch: 1547/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:10:03] epoch: 1547/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:10:03] epoch: 1547/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:10:08] epoch: 1548/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:10:08] epoch: 1548/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:10:08] epoch: 1548/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:10:13] epoch: 1549/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:10:13] epoch: 1549/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:10:13] epoch: 1549/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:10:19] epoch: 1550/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:10:19] epoch: 1550/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:10:19] epoch: 1550/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:10:24] epoch: 1551/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:10:24] epoch: 1551/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:10:24] epoch: 1551/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:10:29] epoch: 1552/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:10:29] epoch: 1552/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:10:29] epoch: 1552/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:10:35] epoch: 1553/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:10:35] epoch: 1553/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:10:35] epoch: 1553/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:10:40] epoch: 1554/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:10:40] epoch: 1554/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:10:40] epoch: 1554/5000, generator loss: 0.6943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:10:45] epoch: 1555/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:10:45] epoch: 1555/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:10:45] epoch: 1555/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:10:51] epoch: 1556/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:10:51] epoch: 1556/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:10:51] epoch: 1556/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:10:56] epoch: 1557/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:10:56] epoch: 1557/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:10:56] epoch: 1557/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:11:01] epoch: 1558/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:11:01] epoch: 1558/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:01] epoch: 1558/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:11:07] epoch: 1559/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:11:07] epoch: 1559/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:07] epoch: 1559/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:11:12] epoch: 1560/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:11:12] epoch: 1560/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:12] epoch: 1560/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:11:17] epoch: 1561/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:11:17] epoch: 1561/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:17] epoch: 1561/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:11:23] epoch: 1562/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:11:23] epoch: 1562/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:23] epoch: 1562/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:11:28] epoch: 1563/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:11:28] epoch: 1563/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:28] epoch: 1563/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:11:33] epoch: 1564/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:11:33] epoch: 1564/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:33] epoch: 1564/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:11:38] epoch: 1565/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:11:38] epoch: 1565/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:38] epoch: 1565/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:11:44] epoch: 1566/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:11:44] epoch: 1566/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:44] epoch: 1566/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:11:49] epoch: 1567/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:11:49] epoch: 1567/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:49] epoch: 1567/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:11:54] epoch: 1568/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:11:54] epoch: 1568/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:11:54] epoch: 1568/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:12:00] epoch: 1569/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:12:00] epoch: 1569/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:00] epoch: 1569/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:12:05] epoch: 1570/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:12:05] epoch: 1570/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:05] epoch: 1570/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:12:10] epoch: 1571/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:12:10] epoch: 1571/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:10] epoch: 1571/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:12:16] epoch: 1572/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:12:16] epoch: 1572/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:16] epoch: 1572/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:12:21] epoch: 1573/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:12:21] epoch: 1573/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:21] epoch: 1573/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:12:26] epoch: 1574/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:12:26] epoch: 1574/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:26] epoch: 1574/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:12:31] epoch: 1575/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:12:31] epoch: 1575/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:31] epoch: 1575/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:12:37] epoch: 1576/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:12:37] epoch: 1576/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:37] epoch: 1576/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:12:42] epoch: 1577/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:12:42] epoch: 1577/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:42] epoch: 1577/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:12:47] epoch: 1578/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:12:47] epoch: 1578/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:47] epoch: 1578/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:12:53] epoch: 1579/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:12:53] epoch: 1579/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:53] epoch: 1579/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:12:58] epoch: 1580/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:12:58] epoch: 1580/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:12:58] epoch: 1580/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:13:03] epoch: 1581/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:13:03] epoch: 1581/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:03] epoch: 1581/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:13:09] epoch: 1582/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:13:09] epoch: 1582/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:09] epoch: 1582/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:13:14] epoch: 1583/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:13:14] epoch: 1583/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:14] epoch: 1583/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:13:19] epoch: 1584/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:13:19] epoch: 1584/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:19] epoch: 1584/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:13:24] epoch: 1585/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:13:24] epoch: 1585/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:24] epoch: 1585/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:13:30] epoch: 1586/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:13:30] epoch: 1586/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:30] epoch: 1586/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:13:35] epoch: 1587/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:13:35] epoch: 1587/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:35] epoch: 1587/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:13:40] epoch: 1588/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:13:40] epoch: 1588/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:40] epoch: 1588/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:13:45] epoch: 1589/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:13:45] epoch: 1589/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:45] epoch: 1589/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:13:51] epoch: 1590/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:13:51] epoch: 1590/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:51] epoch: 1590/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:13:56] epoch: 1591/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-21:13:56] epoch: 1591/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:13:56] epoch: 1591/5000, generator loss: 0.6930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:14:01] epoch: 1592/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-21:14:01] epoch: 1592/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:14:01] epoch: 1592/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:14:07] epoch: 1593/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-21:14:07] epoch: 1593/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:14:07] epoch: 1593/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:14:12] epoch: 1594/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200404-21:14:12] epoch: 1594/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:14:12] epoch: 1594/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:14:17] epoch: 1595/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-21:14:17] epoch: 1595/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:14:17] epoch: 1595/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:14:23] epoch: 1596/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-21:14:23] epoch: 1596/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:14:23] epoch: 1596/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:14:28] epoch: 1597/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:14:28] epoch: 1597/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:14:28] epoch: 1597/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:14:33] epoch: 1598/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:14:33] epoch: 1598/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:14:33] epoch: 1598/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:14:39] epoch: 1599/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:14:39] epoch: 1599/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:14:39] epoch: 1599/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:14:44] epoch: 1600/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:14:44] epoch: 1600/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:14:44] epoch: 1600/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:14:49] epoch: 1601/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:14:49] epoch: 1601/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:14:49] epoch: 1601/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:14:55] epoch: 1602/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:14:55] epoch: 1602/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:14:55] epoch: 1602/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:15:00] epoch: 1603/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:15:00] epoch: 1603/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:15:00] epoch: 1603/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:15:06] epoch: 1604/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:15:06] epoch: 1604/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:15:06] epoch: 1604/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:15:11] epoch: 1605/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:15:11] epoch: 1605/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:15:11] epoch: 1605/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:15:16] epoch: 1606/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:15:16] epoch: 1606/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:15:16] epoch: 1606/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-21:15:22] epoch: 1607/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:15:22] epoch: 1607/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:15:22] epoch: 1607/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:15:27] epoch: 1608/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:15:27] epoch: 1608/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:15:27] epoch: 1608/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-21:15:32] epoch: 1609/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:15:32] epoch: 1609/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:15:32] epoch: 1609/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-21:15:38] epoch: 1610/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:15:38] epoch: 1610/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:15:38] epoch: 1610/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-21:15:43] epoch: 1611/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:15:43] epoch: 1611/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:15:43] epoch: 1611/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-21:15:48] epoch: 1612/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:15:48] epoch: 1612/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:15:48] epoch: 1612/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-21:15:53] epoch: 1613/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:15:53] epoch: 1613/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:15:53] epoch: 1613/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-21:15:59] epoch: 1614/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:15:59] epoch: 1614/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:15:59] epoch: 1614/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:16:04] epoch: 1615/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:16:04] epoch: 1615/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:04] epoch: 1615/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-21:16:10] epoch: 1616/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:16:10] epoch: 1616/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:10] epoch: 1616/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:16:15] epoch: 1617/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:16:15] epoch: 1617/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:15] epoch: 1617/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:16:20] epoch: 1618/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:16:20] epoch: 1618/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:20] epoch: 1618/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:16:25] epoch: 1619/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:16:25] epoch: 1619/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:25] epoch: 1619/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:16:31] epoch: 1620/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:16:31] epoch: 1620/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:31] epoch: 1620/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:16:36] epoch: 1621/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:16:36] epoch: 1621/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:36] epoch: 1621/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:16:41] epoch: 1622/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:16:41] epoch: 1622/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:41] epoch: 1622/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:16:47] epoch: 1623/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:16:47] epoch: 1623/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:47] epoch: 1623/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:16:52] epoch: 1624/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:16:52] epoch: 1624/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:52] epoch: 1624/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:16:57] epoch: 1625/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:16:57] epoch: 1625/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:16:57] epoch: 1625/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:17:02] epoch: 1626/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-21:17:02] epoch: 1626/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:17:02] epoch: 1626/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:17:08] epoch: 1627/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-21:17:08] epoch: 1627/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:17:08] epoch: 1627/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:17:13] epoch: 1628/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-21:17:13] epoch: 1628/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:17:13] epoch: 1628/5000, generator loss: 0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:17:18] epoch: 1629/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-21:17:18] epoch: 1629/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:17:18] epoch: 1629/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:17:24] epoch: 1630/5000, reconstruction loss: 0.0221\n",
      "[LOG TRAIN 20200404-21:17:24] epoch: 1630/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:17:24] epoch: 1630/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:17:29] epoch: 1631/5000, reconstruction loss: 0.0219\n",
      "[LOG TRAIN 20200404-21:17:29] epoch: 1631/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:17:29] epoch: 1631/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:17:34] epoch: 1632/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-21:17:34] epoch: 1632/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:17:34] epoch: 1632/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:17:40] epoch: 1633/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-21:17:40] epoch: 1633/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:17:40] epoch: 1633/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:17:45] epoch: 1634/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-21:17:45] epoch: 1634/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:17:45] epoch: 1634/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:17:50] epoch: 1635/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:17:50] epoch: 1635/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:17:50] epoch: 1635/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:17:56] epoch: 1636/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:17:56] epoch: 1636/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:17:56] epoch: 1636/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:18:01] epoch: 1637/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:18:01] epoch: 1637/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:18:01] epoch: 1637/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-21:18:06] epoch: 1638/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:18:06] epoch: 1638/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:18:06] epoch: 1638/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-21:18:12] epoch: 1639/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:18:12] epoch: 1639/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:18:12] epoch: 1639/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-21:18:17] epoch: 1640/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:18:17] epoch: 1640/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:18:17] epoch: 1640/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-21:18:22] epoch: 1641/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:18:22] epoch: 1641/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:18:22] epoch: 1641/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-21:18:28] epoch: 1642/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:18:28] epoch: 1642/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:18:28] epoch: 1642/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-21:18:33] epoch: 1643/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:18:33] epoch: 1643/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:18:33] epoch: 1643/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:18:38] epoch: 1644/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:18:38] epoch: 1644/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:18:38] epoch: 1644/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:18:43] epoch: 1645/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:18:43] epoch: 1645/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:18:43] epoch: 1645/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:18:49] epoch: 1646/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:18:49] epoch: 1646/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:18:49] epoch: 1646/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:18:54] epoch: 1647/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:18:54] epoch: 1647/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:18:54] epoch: 1647/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:18:59] epoch: 1648/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:18:59] epoch: 1648/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:18:59] epoch: 1648/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:19:05] epoch: 1649/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:19:05] epoch: 1649/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:05] epoch: 1649/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:19:10] epoch: 1650/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:19:10] epoch: 1650/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:10] epoch: 1650/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:19:15] epoch: 1651/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:19:15] epoch: 1651/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:15] epoch: 1651/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:19:20] epoch: 1652/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:19:20] epoch: 1652/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:20] epoch: 1652/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:19:26] epoch: 1653/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:19:26] epoch: 1653/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:26] epoch: 1653/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:19:31] epoch: 1654/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:19:31] epoch: 1654/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:31] epoch: 1654/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:19:36] epoch: 1655/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:19:36] epoch: 1655/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:36] epoch: 1655/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:19:41] epoch: 1656/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:19:41] epoch: 1656/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:41] epoch: 1656/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:19:47] epoch: 1657/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:19:47] epoch: 1657/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:47] epoch: 1657/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:19:52] epoch: 1658/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:19:52] epoch: 1658/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:52] epoch: 1658/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:19:57] epoch: 1659/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:19:57] epoch: 1659/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:19:57] epoch: 1659/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:20:03] epoch: 1660/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:20:03] epoch: 1660/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:03] epoch: 1660/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:20:08] epoch: 1661/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:20:08] epoch: 1661/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:08] epoch: 1661/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:20:13] epoch: 1662/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:20:13] epoch: 1662/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:13] epoch: 1662/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:20:19] epoch: 1663/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:20:19] epoch: 1663/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:19] epoch: 1663/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:20:24] epoch: 1664/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:20:24] epoch: 1664/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:24] epoch: 1664/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:20:29] epoch: 1665/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:20:29] epoch: 1665/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:29] epoch: 1665/5000, generator loss: 0.6941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:20:35] epoch: 1666/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:20:35] epoch: 1666/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:35] epoch: 1666/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:20:40] epoch: 1667/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:20:40] epoch: 1667/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:40] epoch: 1667/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:20:45] epoch: 1668/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:20:45] epoch: 1668/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:45] epoch: 1668/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:20:51] epoch: 1669/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:20:51] epoch: 1669/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:51] epoch: 1669/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:20:56] epoch: 1670/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:20:56] epoch: 1670/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:20:56] epoch: 1670/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:21:02] epoch: 1671/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:21:02] epoch: 1671/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:21:02] epoch: 1671/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:21:07] epoch: 1672/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:21:07] epoch: 1672/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:21:07] epoch: 1672/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:21:12] epoch: 1673/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:21:12] epoch: 1673/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:21:12] epoch: 1673/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:21:18] epoch: 1674/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:21:18] epoch: 1674/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:21:18] epoch: 1674/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:21:23] epoch: 1675/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:21:23] epoch: 1675/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:21:23] epoch: 1675/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:21:28] epoch: 1676/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:21:28] epoch: 1676/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:21:28] epoch: 1676/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:21:34] epoch: 1677/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-21:21:34] epoch: 1677/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:21:34] epoch: 1677/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:21:39] epoch: 1678/5000, reconstruction loss: 0.0355\n",
      "[LOG TRAIN 20200404-21:21:39] epoch: 1678/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:21:39] epoch: 1678/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:21:44] epoch: 1679/5000, reconstruction loss: 0.0303\n",
      "[LOG TRAIN 20200404-21:21:44] epoch: 1679/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:21:44] epoch: 1679/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:21:50] epoch: 1680/5000, reconstruction loss: 0.0239\n",
      "[LOG TRAIN 20200404-21:21:50] epoch: 1680/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:21:50] epoch: 1680/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:21:55] epoch: 1681/5000, reconstruction loss: 0.0207\n",
      "[LOG TRAIN 20200404-21:21:55] epoch: 1681/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:21:55] epoch: 1681/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:22:00] epoch: 1682/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200404-21:22:00] epoch: 1682/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:22:00] epoch: 1682/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:22:06] epoch: 1683/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-21:22:06] epoch: 1683/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:22:06] epoch: 1683/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:22:11] epoch: 1684/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:22:11] epoch: 1684/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:22:11] epoch: 1684/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:22:16] epoch: 1685/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:22:16] epoch: 1685/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:22:16] epoch: 1685/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:22:21] epoch: 1686/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:22:21] epoch: 1686/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:22:21] epoch: 1686/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:22:27] epoch: 1687/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:22:27] epoch: 1687/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:22:27] epoch: 1687/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:22:32] epoch: 1688/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:22:32] epoch: 1688/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:22:32] epoch: 1688/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:22:37] epoch: 1689/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:22:37] epoch: 1689/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:22:37] epoch: 1689/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:22:43] epoch: 1690/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:22:43] epoch: 1690/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:22:43] epoch: 1690/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:22:48] epoch: 1691/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:22:48] epoch: 1691/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:22:48] epoch: 1691/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:22:53] epoch: 1692/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:22:53] epoch: 1692/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:22:53] epoch: 1692/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:22:58] epoch: 1693/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:22:58] epoch: 1693/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:22:58] epoch: 1693/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:23:04] epoch: 1694/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:04] epoch: 1694/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:04] epoch: 1694/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:23:09] epoch: 1695/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:09] epoch: 1695/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:09] epoch: 1695/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:23:14] epoch: 1696/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:14] epoch: 1696/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:14] epoch: 1696/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:23:20] epoch: 1697/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:20] epoch: 1697/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:20] epoch: 1697/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:23:25] epoch: 1698/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:25] epoch: 1698/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:25] epoch: 1698/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:23:31] epoch: 1699/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:31] epoch: 1699/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:31] epoch: 1699/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:23:36] epoch: 1700/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:36] epoch: 1700/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:36] epoch: 1700/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:23:41] epoch: 1701/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:41] epoch: 1701/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:41] epoch: 1701/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:23:46] epoch: 1702/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:46] epoch: 1702/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:46] epoch: 1702/5000, generator loss: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:23:52] epoch: 1703/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:52] epoch: 1703/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:52] epoch: 1703/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:23:57] epoch: 1704/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:23:57] epoch: 1704/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:23:57] epoch: 1704/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:24:03] epoch: 1705/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:03] epoch: 1705/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:24:03] epoch: 1705/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:24:08] epoch: 1706/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:08] epoch: 1706/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:24:08] epoch: 1706/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:24:13] epoch: 1707/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:13] epoch: 1707/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:24:13] epoch: 1707/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:24:19] epoch: 1708/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:19] epoch: 1708/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:24:19] epoch: 1708/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:24:24] epoch: 1709/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:24] epoch: 1709/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:24:24] epoch: 1709/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:24:29] epoch: 1710/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:29] epoch: 1710/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:24:29] epoch: 1710/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:24:34] epoch: 1711/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:34] epoch: 1711/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:24:34] epoch: 1711/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:24:40] epoch: 1712/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:40] epoch: 1712/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:24:40] epoch: 1712/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:24:45] epoch: 1713/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:45] epoch: 1713/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:24:45] epoch: 1713/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:24:50] epoch: 1714/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:50] epoch: 1714/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:24:50] epoch: 1714/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:24:56] epoch: 1715/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:24:56] epoch: 1715/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:24:56] epoch: 1715/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:25:01] epoch: 1716/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:25:01] epoch: 1716/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:25:01] epoch: 1716/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:25:06] epoch: 1717/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:25:06] epoch: 1717/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:25:06] epoch: 1717/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:25:12] epoch: 1718/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:25:12] epoch: 1718/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:25:12] epoch: 1718/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:25:17] epoch: 1719/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:25:17] epoch: 1719/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:25:17] epoch: 1719/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:25:22] epoch: 1720/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:25:22] epoch: 1720/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:25:22] epoch: 1720/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:25:27] epoch: 1721/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:25:27] epoch: 1721/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:25:27] epoch: 1721/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:25:33] epoch: 1722/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:25:33] epoch: 1722/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:25:33] epoch: 1722/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:25:38] epoch: 1723/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:25:38] epoch: 1723/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:25:38] epoch: 1723/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:25:43] epoch: 1724/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:25:43] epoch: 1724/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:25:43] epoch: 1724/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:25:48] epoch: 1725/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:25:48] epoch: 1725/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:25:48] epoch: 1725/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:25:54] epoch: 1726/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:25:54] epoch: 1726/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:25:54] epoch: 1726/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:25:59] epoch: 1727/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:25:59] epoch: 1727/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:25:59] epoch: 1727/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:26:04] epoch: 1728/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:26:04] epoch: 1728/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:26:04] epoch: 1728/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:26:10] epoch: 1729/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:26:10] epoch: 1729/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:26:10] epoch: 1729/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:26:15] epoch: 1730/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:26:15] epoch: 1730/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:26:15] epoch: 1730/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:26:20] epoch: 1731/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:26:20] epoch: 1731/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:26:20] epoch: 1731/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:26:25] epoch: 1732/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:26:25] epoch: 1732/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:26:25] epoch: 1732/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:26:31] epoch: 1733/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:26:31] epoch: 1733/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:26:31] epoch: 1733/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:26:36] epoch: 1734/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:26:36] epoch: 1734/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:26:36] epoch: 1734/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:26:41] epoch: 1735/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:26:41] epoch: 1735/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:26:41] epoch: 1735/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:26:46] epoch: 1736/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:26:46] epoch: 1736/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:26:46] epoch: 1736/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:26:52] epoch: 1737/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:26:52] epoch: 1737/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:26:52] epoch: 1737/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:26:57] epoch: 1738/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:26:57] epoch: 1738/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:26:57] epoch: 1738/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:27:03] epoch: 1739/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:27:03] epoch: 1739/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:27:03] epoch: 1739/5000, generator loss: 0.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:27:08] epoch: 1740/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:27:08] epoch: 1740/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:27:08] epoch: 1740/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:27:13] epoch: 1741/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:27:13] epoch: 1741/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:27:13] epoch: 1741/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:27:19] epoch: 1742/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:27:19] epoch: 1742/5000, discriminator loss: 1.3853\n",
      "[LOG TRAIN 20200404-21:27:19] epoch: 1742/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:27:24] epoch: 1743/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:27:24] epoch: 1743/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:27:24] epoch: 1743/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:27:29] epoch: 1744/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:27:29] epoch: 1744/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:27:29] epoch: 1744/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:27:35] epoch: 1745/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:27:35] epoch: 1745/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:27:35] epoch: 1745/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:27:40] epoch: 1746/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:27:40] epoch: 1746/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:27:40] epoch: 1746/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:27:45] epoch: 1747/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:27:45] epoch: 1747/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:27:45] epoch: 1747/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:27:50] epoch: 1748/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:27:50] epoch: 1748/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:27:50] epoch: 1748/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:27:56] epoch: 1749/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:27:56] epoch: 1749/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:27:56] epoch: 1749/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:28:01] epoch: 1750/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:28:01] epoch: 1750/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:01] epoch: 1750/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:28:06] epoch: 1751/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:28:06] epoch: 1751/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:06] epoch: 1751/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:28:12] epoch: 1752/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:28:12] epoch: 1752/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:12] epoch: 1752/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:28:17] epoch: 1753/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:28:17] epoch: 1753/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:17] epoch: 1753/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:28:22] epoch: 1754/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:28:22] epoch: 1754/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:22] epoch: 1754/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:28:28] epoch: 1755/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:28:28] epoch: 1755/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:28] epoch: 1755/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:28:33] epoch: 1756/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:28:33] epoch: 1756/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:33] epoch: 1756/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:28:38] epoch: 1757/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:28:38] epoch: 1757/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:38] epoch: 1757/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:28:43] epoch: 1758/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:28:43] epoch: 1758/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:43] epoch: 1758/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:28:49] epoch: 1759/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:28:49] epoch: 1759/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:49] epoch: 1759/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:28:54] epoch: 1760/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-21:28:54] epoch: 1760/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:28:54] epoch: 1760/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:28:59] epoch: 1761/5000, reconstruction loss: 0.0245\n",
      "[LOG TRAIN 20200404-21:28:59] epoch: 1761/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:28:59] epoch: 1761/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:29:05] epoch: 1762/5000, reconstruction loss: 0.0224\n",
      "[LOG TRAIN 20200404-21:29:05] epoch: 1762/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:29:05] epoch: 1762/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:29:10] epoch: 1763/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-21:29:10] epoch: 1763/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:29:10] epoch: 1763/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:29:15] epoch: 1764/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200404-21:29:15] epoch: 1764/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:29:15] epoch: 1764/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:29:21] epoch: 1765/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-21:29:21] epoch: 1765/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:29:21] epoch: 1765/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:29:26] epoch: 1766/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:29:26] epoch: 1766/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:29:26] epoch: 1766/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:29:31] epoch: 1767/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:29:31] epoch: 1767/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:29:31] epoch: 1767/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:29:36] epoch: 1768/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:29:36] epoch: 1768/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:29:36] epoch: 1768/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:29:42] epoch: 1769/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:29:42] epoch: 1769/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:29:42] epoch: 1769/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:29:47] epoch: 1770/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:29:47] epoch: 1770/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:29:47] epoch: 1770/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:29:52] epoch: 1771/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:29:52] epoch: 1771/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:29:52] epoch: 1771/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:29:58] epoch: 1772/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:29:58] epoch: 1772/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:29:58] epoch: 1772/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:30:03] epoch: 1773/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:30:03] epoch: 1773/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:03] epoch: 1773/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:30:09] epoch: 1774/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:30:09] epoch: 1774/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:09] epoch: 1774/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:30:14] epoch: 1775/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:30:14] epoch: 1775/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:14] epoch: 1775/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:30:19] epoch: 1776/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:30:19] epoch: 1776/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:19] epoch: 1776/5000, generator loss: 0.6934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:30:24] epoch: 1777/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:30:24] epoch: 1777/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:24] epoch: 1777/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:30:30] epoch: 1778/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:30:30] epoch: 1778/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:30] epoch: 1778/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:30:35] epoch: 1779/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:30:35] epoch: 1779/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:35] epoch: 1779/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:30:40] epoch: 1780/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:30:40] epoch: 1780/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:40] epoch: 1780/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:30:45] epoch: 1781/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:30:45] epoch: 1781/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:45] epoch: 1781/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:30:51] epoch: 1782/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:30:51] epoch: 1782/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:51] epoch: 1782/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:30:56] epoch: 1783/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:30:56] epoch: 1783/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:30:56] epoch: 1783/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:31:01] epoch: 1784/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:31:01] epoch: 1784/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:01] epoch: 1784/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:31:06] epoch: 1785/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:31:06] epoch: 1785/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:06] epoch: 1785/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:31:12] epoch: 1786/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:31:12] epoch: 1786/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:12] epoch: 1786/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:31:17] epoch: 1787/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:31:17] epoch: 1787/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:17] epoch: 1787/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:31:22] epoch: 1788/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:31:22] epoch: 1788/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:22] epoch: 1788/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:31:28] epoch: 1789/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:31:28] epoch: 1789/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:28] epoch: 1789/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:31:33] epoch: 1790/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:31:33] epoch: 1790/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:33] epoch: 1790/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:31:38] epoch: 1791/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:31:38] epoch: 1791/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:38] epoch: 1791/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:31:43] epoch: 1792/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:31:43] epoch: 1792/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:43] epoch: 1792/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:31:49] epoch: 1793/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:31:49] epoch: 1793/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:49] epoch: 1793/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:31:54] epoch: 1794/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:31:54] epoch: 1794/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:54] epoch: 1794/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:31:59] epoch: 1795/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:31:59] epoch: 1795/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:31:59] epoch: 1795/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:32:05] epoch: 1796/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:32:05] epoch: 1796/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:05] epoch: 1796/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:32:10] epoch: 1797/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:32:10] epoch: 1797/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:10] epoch: 1797/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:32:15] epoch: 1798/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:32:15] epoch: 1798/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:15] epoch: 1798/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:32:20] epoch: 1799/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:32:20] epoch: 1799/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:20] epoch: 1799/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:32:26] epoch: 1800/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:32:26] epoch: 1800/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:26] epoch: 1800/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:32:31] epoch: 1801/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:32:31] epoch: 1801/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:31] epoch: 1801/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:32:36] epoch: 1802/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:32:36] epoch: 1802/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:36] epoch: 1802/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:32:41] epoch: 1803/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:32:41] epoch: 1803/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:41] epoch: 1803/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:32:47] epoch: 1804/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:32:47] epoch: 1804/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:47] epoch: 1804/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:32:52] epoch: 1805/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:32:52] epoch: 1805/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:52] epoch: 1805/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:32:58] epoch: 1806/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:32:58] epoch: 1806/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:32:58] epoch: 1806/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:33:03] epoch: 1807/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:33:03] epoch: 1807/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:33:03] epoch: 1807/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:33:08] epoch: 1808/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-21:33:08] epoch: 1808/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:33:08] epoch: 1808/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:33:14] epoch: 1809/5000, reconstruction loss: 0.0240\n",
      "[LOG TRAIN 20200404-21:33:14] epoch: 1809/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:33:14] epoch: 1809/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:33:19] epoch: 1810/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200404-21:33:19] epoch: 1810/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:33:19] epoch: 1810/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:33:24] epoch: 1811/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-21:33:24] epoch: 1811/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:33:24] epoch: 1811/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:33:30] epoch: 1812/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-21:33:30] epoch: 1812/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:33:30] epoch: 1812/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:33:35] epoch: 1813/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-21:33:35] epoch: 1813/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:33:35] epoch: 1813/5000, generator loss: 0.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:33:40] epoch: 1814/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:33:40] epoch: 1814/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:33:40] epoch: 1814/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:33:46] epoch: 1815/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:33:46] epoch: 1815/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:33:46] epoch: 1815/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:33:51] epoch: 1816/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:33:51] epoch: 1816/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:33:51] epoch: 1816/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:33:56] epoch: 1817/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:33:56] epoch: 1817/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:33:56] epoch: 1817/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:34:01] epoch: 1818/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:01] epoch: 1818/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:01] epoch: 1818/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:34:07] epoch: 1819/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:07] epoch: 1819/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:07] epoch: 1819/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:34:12] epoch: 1820/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:12] epoch: 1820/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:12] epoch: 1820/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:34:17] epoch: 1821/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:17] epoch: 1821/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:17] epoch: 1821/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:34:23] epoch: 1822/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:23] epoch: 1822/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:23] epoch: 1822/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:34:28] epoch: 1823/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:28] epoch: 1823/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:28] epoch: 1823/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:34:33] epoch: 1824/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:33] epoch: 1824/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:33] epoch: 1824/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:34:38] epoch: 1825/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:38] epoch: 1825/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:38] epoch: 1825/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:34:44] epoch: 1826/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:44] epoch: 1826/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:44] epoch: 1826/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:34:49] epoch: 1827/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:49] epoch: 1827/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:49] epoch: 1827/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:34:54] epoch: 1828/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:54] epoch: 1828/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:34:54] epoch: 1828/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:34:59] epoch: 1829/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:34:59] epoch: 1829/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:34:59] epoch: 1829/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:35:05] epoch: 1830/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:35:05] epoch: 1830/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:05] epoch: 1830/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:35:10] epoch: 1831/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:35:10] epoch: 1831/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:10] epoch: 1831/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:35:15] epoch: 1832/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:35:15] epoch: 1832/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:15] epoch: 1832/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:35:21] epoch: 1833/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:35:21] epoch: 1833/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:21] epoch: 1833/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:35:26] epoch: 1834/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:35:26] epoch: 1834/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:26] epoch: 1834/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:35:31] epoch: 1835/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:35:31] epoch: 1835/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:31] epoch: 1835/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:35:36] epoch: 1836/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:35:36] epoch: 1836/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:36] epoch: 1836/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:35:42] epoch: 1837/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:35:42] epoch: 1837/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:42] epoch: 1837/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:35:47] epoch: 1838/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:35:47] epoch: 1838/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:47] epoch: 1838/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:35:52] epoch: 1839/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:35:52] epoch: 1839/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:52] epoch: 1839/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:35:58] epoch: 1840/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:35:58] epoch: 1840/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:35:58] epoch: 1840/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:36:03] epoch: 1841/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:36:03] epoch: 1841/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:36:03] epoch: 1841/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:36:08] epoch: 1842/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:36:08] epoch: 1842/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:36:08] epoch: 1842/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:36:14] epoch: 1843/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:36:14] epoch: 1843/5000, discriminator loss: 1.3852\n",
      "[LOG TRAIN 20200404-21:36:14] epoch: 1843/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:36:19] epoch: 1844/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:36:19] epoch: 1844/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:36:19] epoch: 1844/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:36:24] epoch: 1845/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:36:24] epoch: 1845/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:36:24] epoch: 1845/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-21:36:30] epoch: 1846/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:36:30] epoch: 1846/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:36:30] epoch: 1846/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-21:36:35] epoch: 1847/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:36:35] epoch: 1847/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:36:35] epoch: 1847/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-21:36:40] epoch: 1848/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:36:40] epoch: 1848/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:36:40] epoch: 1848/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:36:45] epoch: 1849/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:36:45] epoch: 1849/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:36:45] epoch: 1849/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:36:51] epoch: 1850/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:36:51] epoch: 1850/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:36:51] epoch: 1850/5000, generator loss: 0.6927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:36:56] epoch: 1851/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:36:56] epoch: 1851/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:36:56] epoch: 1851/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:37:01] epoch: 1852/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:37:01] epoch: 1852/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:01] epoch: 1852/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:37:07] epoch: 1853/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:37:07] epoch: 1853/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:07] epoch: 1853/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:37:12] epoch: 1854/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:37:12] epoch: 1854/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:12] epoch: 1854/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:37:17] epoch: 1855/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:37:17] epoch: 1855/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:17] epoch: 1855/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:37:22] epoch: 1856/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:37:22] epoch: 1856/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:22] epoch: 1856/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-21:37:28] epoch: 1857/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:37:28] epoch: 1857/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:28] epoch: 1857/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:37:33] epoch: 1858/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:37:33] epoch: 1858/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:33] epoch: 1858/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:37:38] epoch: 1859/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:37:38] epoch: 1859/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:38] epoch: 1859/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:37:44] epoch: 1860/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:37:44] epoch: 1860/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:44] epoch: 1860/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:37:49] epoch: 1861/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:37:49] epoch: 1861/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:49] epoch: 1861/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:37:54] epoch: 1862/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:37:54] epoch: 1862/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:54] epoch: 1862/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:37:59] epoch: 1863/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:37:59] epoch: 1863/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:37:59] epoch: 1863/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:38:05] epoch: 1864/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:38:05] epoch: 1864/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:05] epoch: 1864/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:38:10] epoch: 1865/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:38:10] epoch: 1865/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:10] epoch: 1865/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:38:15] epoch: 1866/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:38:15] epoch: 1866/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:15] epoch: 1866/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:38:20] epoch: 1867/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:38:20] epoch: 1867/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:20] epoch: 1867/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:38:25] epoch: 1868/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:38:25] epoch: 1868/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:25] epoch: 1868/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:38:31] epoch: 1869/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:38:31] epoch: 1869/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:31] epoch: 1869/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:38:36] epoch: 1870/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:38:36] epoch: 1870/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:36] epoch: 1870/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:38:41] epoch: 1871/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:38:41] epoch: 1871/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:41] epoch: 1871/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:38:47] epoch: 1872/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:38:47] epoch: 1872/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:47] epoch: 1872/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:38:52] epoch: 1873/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:38:52] epoch: 1873/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:52] epoch: 1873/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:38:57] epoch: 1874/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:38:57] epoch: 1874/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:38:57] epoch: 1874/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:39:03] epoch: 1875/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:39:03] epoch: 1875/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:39:03] epoch: 1875/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:39:08] epoch: 1876/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:39:08] epoch: 1876/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:39:08] epoch: 1876/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:39:13] epoch: 1877/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:39:13] epoch: 1877/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:39:13] epoch: 1877/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:39:19] epoch: 1878/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:39:19] epoch: 1878/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:39:19] epoch: 1878/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:39:24] epoch: 1879/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:39:24] epoch: 1879/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:39:24] epoch: 1879/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:39:29] epoch: 1880/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:39:29] epoch: 1880/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:39:29] epoch: 1880/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:39:35] epoch: 1881/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:39:35] epoch: 1881/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:39:35] epoch: 1881/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:39:40] epoch: 1882/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:39:40] epoch: 1882/5000, discriminator loss: 1.3851\n",
      "[LOG TRAIN 20200404-21:39:40] epoch: 1882/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:39:45] epoch: 1883/5000, reconstruction loss: 0.0269\n",
      "[LOG TRAIN 20200404-21:39:45] epoch: 1883/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:39:45] epoch: 1883/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:39:50] epoch: 1884/5000, reconstruction loss: 0.0264\n",
      "[LOG TRAIN 20200404-21:39:50] epoch: 1884/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:39:50] epoch: 1884/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:39:56] epoch: 1885/5000, reconstruction loss: 0.0237\n",
      "[LOG TRAIN 20200404-21:39:56] epoch: 1885/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:39:56] epoch: 1885/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:40:01] epoch: 1886/5000, reconstruction loss: 0.0274\n",
      "[LOG TRAIN 20200404-21:40:01] epoch: 1886/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:40:01] epoch: 1886/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:40:06] epoch: 1887/5000, reconstruction loss: 0.0239\n",
      "[LOG TRAIN 20200404-21:40:06] epoch: 1887/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:40:06] epoch: 1887/5000, generator loss: 0.6930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:40:11] epoch: 1888/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-21:40:11] epoch: 1888/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:40:11] epoch: 1888/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:40:17] epoch: 1889/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-21:40:17] epoch: 1889/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:40:17] epoch: 1889/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:40:22] epoch: 1890/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-21:40:22] epoch: 1890/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:40:22] epoch: 1890/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-21:40:27] epoch: 1891/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:40:27] epoch: 1891/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:40:27] epoch: 1891/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:40:33] epoch: 1892/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:40:33] epoch: 1892/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:40:33] epoch: 1892/5000, generator loss: 0.6926\n",
      "[LOG TRAIN 20200404-21:40:38] epoch: 1893/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:40:38] epoch: 1893/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:40:38] epoch: 1893/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-21:40:43] epoch: 1894/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:40:43] epoch: 1894/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:40:43] epoch: 1894/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-21:40:48] epoch: 1895/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:40:48] epoch: 1895/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:40:48] epoch: 1895/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-21:40:54] epoch: 1896/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:40:54] epoch: 1896/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:40:54] epoch: 1896/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-21:40:59] epoch: 1897/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:40:59] epoch: 1897/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:40:59] epoch: 1897/5000, generator loss: 0.6925\n",
      "[LOG TRAIN 20200404-21:41:04] epoch: 1898/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:41:04] epoch: 1898/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:04] epoch: 1898/5000, generator loss: 0.6927\n",
      "[LOG TRAIN 20200404-21:41:10] epoch: 1899/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:41:10] epoch: 1899/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:10] epoch: 1899/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-21:41:15] epoch: 1900/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:41:15] epoch: 1900/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:15] epoch: 1900/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:41:20] epoch: 1901/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:41:20] epoch: 1901/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:20] epoch: 1901/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:41:25] epoch: 1902/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:41:25] epoch: 1902/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:25] epoch: 1902/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:41:31] epoch: 1903/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:41:31] epoch: 1903/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:31] epoch: 1903/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:41:36] epoch: 1904/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:41:36] epoch: 1904/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:36] epoch: 1904/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:41:41] epoch: 1905/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:41:41] epoch: 1905/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:41] epoch: 1905/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:41:46] epoch: 1906/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:41:46] epoch: 1906/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:46] epoch: 1906/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:41:52] epoch: 1907/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:41:52] epoch: 1907/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:52] epoch: 1907/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-21:41:57] epoch: 1908/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:41:57] epoch: 1908/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:41:57] epoch: 1908/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:42:03] epoch: 1909/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:03] epoch: 1909/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:03] epoch: 1909/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:42:08] epoch: 1910/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:08] epoch: 1910/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:08] epoch: 1910/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:42:13] epoch: 1911/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:13] epoch: 1911/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:13] epoch: 1911/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-21:42:18] epoch: 1912/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:18] epoch: 1912/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:18] epoch: 1912/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-21:42:24] epoch: 1913/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:24] epoch: 1913/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:24] epoch: 1913/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:42:29] epoch: 1914/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:29] epoch: 1914/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:29] epoch: 1914/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:42:34] epoch: 1915/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:34] epoch: 1915/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:34] epoch: 1915/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:42:39] epoch: 1916/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:39] epoch: 1916/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:39] epoch: 1916/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-21:42:45] epoch: 1917/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:45] epoch: 1917/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:45] epoch: 1917/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-21:42:50] epoch: 1918/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:50] epoch: 1918/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:50] epoch: 1918/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:42:55] epoch: 1919/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:42:55] epoch: 1919/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:42:55] epoch: 1919/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:43:00] epoch: 1920/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:00] epoch: 1920/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:00] epoch: 1920/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:43:06] epoch: 1921/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:06] epoch: 1921/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:06] epoch: 1921/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:43:11] epoch: 1922/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:11] epoch: 1922/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:11] epoch: 1922/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:43:16] epoch: 1923/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:16] epoch: 1923/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:16] epoch: 1923/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:43:22] epoch: 1924/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:22] epoch: 1924/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:22] epoch: 1924/5000, generator loss: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:43:27] epoch: 1925/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:27] epoch: 1925/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:27] epoch: 1925/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:43:32] epoch: 1926/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:32] epoch: 1926/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:32] epoch: 1926/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:43:37] epoch: 1927/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:37] epoch: 1927/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:37] epoch: 1927/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:43:43] epoch: 1928/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:43] epoch: 1928/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:43] epoch: 1928/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:43:48] epoch: 1929/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:43:48] epoch: 1929/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:48] epoch: 1929/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:43:53] epoch: 1930/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:53] epoch: 1930/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:53] epoch: 1930/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:43:58] epoch: 1931/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:43:58] epoch: 1931/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:43:58] epoch: 1931/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:44:04] epoch: 1932/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:44:04] epoch: 1932/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:04] epoch: 1932/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:44:09] epoch: 1933/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:44:09] epoch: 1933/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:09] epoch: 1933/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:44:14] epoch: 1934/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:44:14] epoch: 1934/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:14] epoch: 1934/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:44:19] epoch: 1935/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:44:19] epoch: 1935/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:19] epoch: 1935/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:44:25] epoch: 1936/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:44:25] epoch: 1936/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:25] epoch: 1936/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:44:30] epoch: 1937/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:44:30] epoch: 1937/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:30] epoch: 1937/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:44:36] epoch: 1938/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:44:36] epoch: 1938/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:36] epoch: 1938/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:44:41] epoch: 1939/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:44:41] epoch: 1939/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:41] epoch: 1939/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:44:46] epoch: 1940/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:44:46] epoch: 1940/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:46] epoch: 1940/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:44:51] epoch: 1941/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:44:51] epoch: 1941/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:51] epoch: 1941/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:44:56] epoch: 1942/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:44:56] epoch: 1942/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:44:56] epoch: 1942/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:45:02] epoch: 1943/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:45:02] epoch: 1943/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:02] epoch: 1943/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:45:07] epoch: 1944/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:45:07] epoch: 1944/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:07] epoch: 1944/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:45:13] epoch: 1945/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:45:13] epoch: 1945/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:13] epoch: 1945/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:45:18] epoch: 1946/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:45:18] epoch: 1946/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:18] epoch: 1946/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:45:23] epoch: 1947/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:45:23] epoch: 1947/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:23] epoch: 1947/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:45:29] epoch: 1948/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:45:29] epoch: 1948/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:29] epoch: 1948/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:45:34] epoch: 1949/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:45:34] epoch: 1949/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:34] epoch: 1949/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:45:39] epoch: 1950/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:45:39] epoch: 1950/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:39] epoch: 1950/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:45:44] epoch: 1951/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:45:44] epoch: 1951/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:44] epoch: 1951/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:45:50] epoch: 1952/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:45:50] epoch: 1952/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:50] epoch: 1952/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:45:55] epoch: 1953/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:45:55] epoch: 1953/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:45:55] epoch: 1953/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:46:00] epoch: 1954/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:46:00] epoch: 1954/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:00] epoch: 1954/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:46:05] epoch: 1955/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:46:05] epoch: 1955/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:05] epoch: 1955/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:46:11] epoch: 1956/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:46:11] epoch: 1956/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:11] epoch: 1956/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:46:16] epoch: 1957/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:46:16] epoch: 1957/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:16] epoch: 1957/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:46:21] epoch: 1958/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-21:46:21] epoch: 1958/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:21] epoch: 1958/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:46:27] epoch: 1959/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:46:27] epoch: 1959/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:27] epoch: 1959/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:46:32] epoch: 1960/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:46:32] epoch: 1960/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:32] epoch: 1960/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:46:37] epoch: 1961/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:46:37] epoch: 1961/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:37] epoch: 1961/5000, generator loss: 0.6943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:46:43] epoch: 1962/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:46:43] epoch: 1962/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:43] epoch: 1962/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:46:48] epoch: 1963/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:46:48] epoch: 1963/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:48] epoch: 1963/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:46:53] epoch: 1964/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:46:53] epoch: 1964/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:53] epoch: 1964/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:46:58] epoch: 1965/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:46:58] epoch: 1965/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:46:58] epoch: 1965/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:47:04] epoch: 1966/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:47:04] epoch: 1966/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:47:04] epoch: 1966/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:47:09] epoch: 1967/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:47:09] epoch: 1967/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:47:09] epoch: 1967/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:47:14] epoch: 1968/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-21:47:14] epoch: 1968/5000, discriminator loss: 1.3850\n",
      "[LOG TRAIN 20200404-21:47:14] epoch: 1968/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:47:20] epoch: 1969/5000, reconstruction loss: 0.0233\n",
      "[LOG TRAIN 20200404-21:47:20] epoch: 1969/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:47:20] epoch: 1969/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:47:25] epoch: 1970/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-21:47:25] epoch: 1970/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:47:25] epoch: 1970/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:47:30] epoch: 1971/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-21:47:30] epoch: 1971/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:47:30] epoch: 1971/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:47:35] epoch: 1972/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-21:47:35] epoch: 1972/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:47:35] epoch: 1972/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:47:41] epoch: 1973/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-21:47:41] epoch: 1973/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:47:41] epoch: 1973/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:47:46] epoch: 1974/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:47:46] epoch: 1974/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:47:46] epoch: 1974/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:47:51] epoch: 1975/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:47:51] epoch: 1975/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:47:51] epoch: 1975/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:47:57] epoch: 1976/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:47:57] epoch: 1976/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:47:57] epoch: 1976/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:48:02] epoch: 1977/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:48:02] epoch: 1977/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:02] epoch: 1977/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:48:07] epoch: 1978/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:48:07] epoch: 1978/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:07] epoch: 1978/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:48:13] epoch: 1979/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:48:13] epoch: 1979/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:13] epoch: 1979/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:48:18] epoch: 1980/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:48:18] epoch: 1980/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:18] epoch: 1980/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:48:23] epoch: 1981/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:48:23] epoch: 1981/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:23] epoch: 1981/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:48:28] epoch: 1982/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:48:28] epoch: 1982/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:28] epoch: 1982/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:48:34] epoch: 1983/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:48:34] epoch: 1983/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:34] epoch: 1983/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:48:39] epoch: 1984/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:48:39] epoch: 1984/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:39] epoch: 1984/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:48:44] epoch: 1985/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:48:44] epoch: 1985/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:44] epoch: 1985/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:48:50] epoch: 1986/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:48:50] epoch: 1986/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:50] epoch: 1986/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:48:55] epoch: 1987/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:48:55] epoch: 1987/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:48:55] epoch: 1987/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:00] epoch: 1988/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:49:00] epoch: 1988/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:00] epoch: 1988/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:05] epoch: 1989/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:49:05] epoch: 1989/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:05] epoch: 1989/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:11] epoch: 1990/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:49:11] epoch: 1990/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:11] epoch: 1990/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:16] epoch: 1991/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:49:16] epoch: 1991/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:16] epoch: 1991/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:21] epoch: 1992/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:49:21] epoch: 1992/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:21] epoch: 1992/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:26] epoch: 1993/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:49:26] epoch: 1993/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:26] epoch: 1993/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:32] epoch: 1994/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:49:32] epoch: 1994/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:32] epoch: 1994/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:37] epoch: 1995/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:49:37] epoch: 1995/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:37] epoch: 1995/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:42] epoch: 1996/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:49:42] epoch: 1996/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:42] epoch: 1996/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:47] epoch: 1997/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:49:47] epoch: 1997/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:47] epoch: 1997/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:49:53] epoch: 1998/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:49:53] epoch: 1998/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:53] epoch: 1998/5000, generator loss: 0.6937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:49:58] epoch: 1999/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:49:58] epoch: 1999/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:49:58] epoch: 1999/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:50:03] epoch: 2000/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:50:03] epoch: 2000/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:03] epoch: 2000/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:50:09] epoch: 2001/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:50:09] epoch: 2001/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:09] epoch: 2001/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:50:14] epoch: 2002/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:50:14] epoch: 2002/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:14] epoch: 2002/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:50:19] epoch: 2003/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:50:19] epoch: 2003/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:19] epoch: 2003/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:50:24] epoch: 2004/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:50:24] epoch: 2004/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:24] epoch: 2004/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:50:30] epoch: 2005/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:50:30] epoch: 2005/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:30] epoch: 2005/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:50:35] epoch: 2006/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:50:35] epoch: 2006/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:35] epoch: 2006/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:50:40] epoch: 2007/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:50:40] epoch: 2007/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:40] epoch: 2007/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:50:46] epoch: 2008/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:50:46] epoch: 2008/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:46] epoch: 2008/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:50:51] epoch: 2009/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:50:51] epoch: 2009/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:51] epoch: 2009/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:50:56] epoch: 2010/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:50:56] epoch: 2010/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:50:56] epoch: 2010/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:51:02] epoch: 2011/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:51:02] epoch: 2011/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:02] epoch: 2011/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:51:07] epoch: 2012/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:51:07] epoch: 2012/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:07] epoch: 2012/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:51:12] epoch: 2013/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:51:12] epoch: 2013/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:12] epoch: 2013/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:51:18] epoch: 2014/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:51:18] epoch: 2014/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:18] epoch: 2014/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:51:23] epoch: 2015/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:51:23] epoch: 2015/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:23] epoch: 2015/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:51:28] epoch: 2016/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:51:28] epoch: 2016/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:28] epoch: 2016/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:51:34] epoch: 2017/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:51:34] epoch: 2017/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:34] epoch: 2017/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:51:39] epoch: 2018/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:51:39] epoch: 2018/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:39] epoch: 2018/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:51:44] epoch: 2019/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-21:51:44] epoch: 2019/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:44] epoch: 2019/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:51:49] epoch: 2020/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:51:49] epoch: 2020/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:49] epoch: 2020/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:51:55] epoch: 2021/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:51:55] epoch: 2021/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:51:55] epoch: 2021/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:52:00] epoch: 2022/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:52:00] epoch: 2022/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:00] epoch: 2022/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:52:05] epoch: 2023/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:52:05] epoch: 2023/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:05] epoch: 2023/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:52:10] epoch: 2024/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:52:10] epoch: 2024/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:10] epoch: 2024/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:52:16] epoch: 2025/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:52:16] epoch: 2025/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:16] epoch: 2025/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:52:21] epoch: 2026/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:52:21] epoch: 2026/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:21] epoch: 2026/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:52:26] epoch: 2027/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:52:26] epoch: 2027/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:26] epoch: 2027/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:52:32] epoch: 2028/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:52:32] epoch: 2028/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:32] epoch: 2028/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:52:37] epoch: 2029/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:52:37] epoch: 2029/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:37] epoch: 2029/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:52:42] epoch: 2030/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:52:42] epoch: 2030/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:42] epoch: 2030/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:52:47] epoch: 2031/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:52:47] epoch: 2031/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:47] epoch: 2031/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:52:53] epoch: 2032/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:52:53] epoch: 2032/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:53] epoch: 2032/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:52:58] epoch: 2033/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:52:58] epoch: 2033/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:52:58] epoch: 2033/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:53:03] epoch: 2034/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:53:03] epoch: 2034/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:53:03] epoch: 2034/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:53:08] epoch: 2035/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:53:08] epoch: 2035/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:53:08] epoch: 2035/5000, generator loss: 0.6938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:53:14] epoch: 2036/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:53:14] epoch: 2036/5000, discriminator loss: 1.3849\n",
      "[LOG TRAIN 20200404-21:53:14] epoch: 2036/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:53:19] epoch: 2037/5000, reconstruction loss: 0.0248\n",
      "[LOG TRAIN 20200404-21:53:19] epoch: 2037/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:53:19] epoch: 2037/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:53:24] epoch: 2038/5000, reconstruction loss: 0.0215\n",
      "[LOG TRAIN 20200404-21:53:24] epoch: 2038/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-21:53:24] epoch: 2038/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:53:30] epoch: 2039/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-21:53:30] epoch: 2039/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-21:53:30] epoch: 2039/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:53:35] epoch: 2040/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-21:53:35] epoch: 2040/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:53:35] epoch: 2040/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:53:40] epoch: 2041/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-21:53:40] epoch: 2041/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:53:40] epoch: 2041/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:53:45] epoch: 2042/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:53:45] epoch: 2042/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:53:45] epoch: 2042/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:53:51] epoch: 2043/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:53:51] epoch: 2043/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:53:51] epoch: 2043/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:53:56] epoch: 2044/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:53:56] epoch: 2044/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:53:56] epoch: 2044/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:54:02] epoch: 2045/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:02] epoch: 2045/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:02] epoch: 2045/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:54:07] epoch: 2046/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:07] epoch: 2046/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:07] epoch: 2046/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:54:12] epoch: 2047/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:12] epoch: 2047/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:12] epoch: 2047/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:54:17] epoch: 2048/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:17] epoch: 2048/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:17] epoch: 2048/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:54:23] epoch: 2049/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:23] epoch: 2049/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:23] epoch: 2049/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:54:28] epoch: 2050/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:28] epoch: 2050/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:28] epoch: 2050/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:54:33] epoch: 2051/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:33] epoch: 2051/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:33] epoch: 2051/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:54:38] epoch: 2052/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:38] epoch: 2052/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:38] epoch: 2052/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:54:44] epoch: 2053/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:44] epoch: 2053/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:44] epoch: 2053/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:54:49] epoch: 2054/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:49] epoch: 2054/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:49] epoch: 2054/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:54:54] epoch: 2055/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:54:54] epoch: 2055/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:54] epoch: 2055/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:54:59] epoch: 2056/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:54:59] epoch: 2056/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:54:59] epoch: 2056/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:55:05] epoch: 2057/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:55:05] epoch: 2057/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:05] epoch: 2057/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:55:10] epoch: 2058/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:55:10] epoch: 2058/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:10] epoch: 2058/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:55:15] epoch: 2059/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:55:15] epoch: 2059/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:15] epoch: 2059/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:55:21] epoch: 2060/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:55:21] epoch: 2060/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:21] epoch: 2060/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:55:26] epoch: 2061/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:55:26] epoch: 2061/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:26] epoch: 2061/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:55:31] epoch: 2062/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:55:31] epoch: 2062/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:31] epoch: 2062/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:55:37] epoch: 2063/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:55:37] epoch: 2063/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:37] epoch: 2063/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:55:42] epoch: 2064/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:55:42] epoch: 2064/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:42] epoch: 2064/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:55:47] epoch: 2065/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:55:47] epoch: 2065/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:47] epoch: 2065/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:55:52] epoch: 2066/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:55:52] epoch: 2066/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:52] epoch: 2066/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:55:58] epoch: 2067/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:55:58] epoch: 2067/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:55:58] epoch: 2067/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:56:03] epoch: 2068/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:56:03] epoch: 2068/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:03] epoch: 2068/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:56:08] epoch: 2069/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:56:08] epoch: 2069/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:08] epoch: 2069/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:56:14] epoch: 2070/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:56:14] epoch: 2070/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:14] epoch: 2070/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:56:19] epoch: 2071/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:56:19] epoch: 2071/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:19] epoch: 2071/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:56:24] epoch: 2072/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:56:24] epoch: 2072/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:24] epoch: 2072/5000, generator loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:56:29] epoch: 2073/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:56:29] epoch: 2073/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:29] epoch: 2073/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:56:35] epoch: 2074/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:56:35] epoch: 2074/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:35] epoch: 2074/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:56:40] epoch: 2075/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:56:40] epoch: 2075/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:40] epoch: 2075/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:56:45] epoch: 2076/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:56:45] epoch: 2076/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:45] epoch: 2076/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:56:51] epoch: 2077/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:56:51] epoch: 2077/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:51] epoch: 2077/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:56:56] epoch: 2078/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:56:56] epoch: 2078/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:56:56] epoch: 2078/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-21:57:01] epoch: 2079/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:57:01] epoch: 2079/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:01] epoch: 2079/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:57:07] epoch: 2080/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:57:07] epoch: 2080/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:07] epoch: 2080/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:57:12] epoch: 2081/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:57:12] epoch: 2081/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:12] epoch: 2081/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-21:57:17] epoch: 2082/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:57:17] epoch: 2082/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:17] epoch: 2082/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:57:23] epoch: 2083/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:57:23] epoch: 2083/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:23] epoch: 2083/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:57:28] epoch: 2084/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:57:28] epoch: 2084/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:28] epoch: 2084/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:57:33] epoch: 2085/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:57:33] epoch: 2085/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:33] epoch: 2085/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-21:57:38] epoch: 2086/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:57:38] epoch: 2086/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:38] epoch: 2086/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:57:44] epoch: 2087/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:57:44] epoch: 2087/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:44] epoch: 2087/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:57:49] epoch: 2088/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-21:57:49] epoch: 2088/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:49] epoch: 2088/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:57:54] epoch: 2089/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-21:57:54] epoch: 2089/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:57:54] epoch: 2089/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-21:58:00] epoch: 2090/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:58:00] epoch: 2090/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:00] epoch: 2090/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-21:58:05] epoch: 2091/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:58:05] epoch: 2091/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:05] epoch: 2091/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-21:58:10] epoch: 2092/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:58:10] epoch: 2092/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:10] epoch: 2092/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-21:58:15] epoch: 2093/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:58:15] epoch: 2093/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:15] epoch: 2093/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-21:58:21] epoch: 2094/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:58:21] epoch: 2094/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:21] epoch: 2094/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-21:58:26] epoch: 2095/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:58:26] epoch: 2095/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:26] epoch: 2095/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-21:58:31] epoch: 2096/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:58:31] epoch: 2096/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:31] epoch: 2096/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-21:58:37] epoch: 2097/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:58:37] epoch: 2097/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:37] epoch: 2097/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-21:58:42] epoch: 2098/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:58:42] epoch: 2098/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:42] epoch: 2098/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-21:58:47] epoch: 2099/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-21:58:47] epoch: 2099/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:47] epoch: 2099/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-21:58:52] epoch: 2100/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-21:58:52] epoch: 2100/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:52] epoch: 2100/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:58:58] epoch: 2101/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-21:58:58] epoch: 2101/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:58:58] epoch: 2101/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:59:03] epoch: 2102/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:59:03] epoch: 2102/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:59:03] epoch: 2102/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-21:59:08] epoch: 2103/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:59:08] epoch: 2103/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:59:08] epoch: 2103/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-21:59:13] epoch: 2104/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:59:13] epoch: 2104/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:59:13] epoch: 2104/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:59:19] epoch: 2105/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:59:19] epoch: 2105/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:59:19] epoch: 2105/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:59:24] epoch: 2106/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:59:24] epoch: 2106/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:59:24] epoch: 2106/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:59:29] epoch: 2107/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-21:59:29] epoch: 2107/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:59:29] epoch: 2107/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-21:59:34] epoch: 2108/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-21:59:34] epoch: 2108/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:59:34] epoch: 2108/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-21:59:40] epoch: 2109/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-21:59:40] epoch: 2109/5000, discriminator loss: 1.3848\n",
      "[LOG TRAIN 20200404-21:59:40] epoch: 2109/5000, generator loss: 0.6932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-21:59:45] epoch: 2110/5000, reconstruction loss: 0.0302\n",
      "[LOG TRAIN 20200404-21:59:45] epoch: 2110/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-21:59:45] epoch: 2110/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:59:50] epoch: 2111/5000, reconstruction loss: 0.0210\n",
      "[LOG TRAIN 20200404-21:59:50] epoch: 2111/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-21:59:50] epoch: 2111/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-21:59:55] epoch: 2112/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-21:59:55] epoch: 2112/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-21:59:55] epoch: 2112/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:00:01] epoch: 2113/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-22:00:01] epoch: 2113/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:00:01] epoch: 2113/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:00:06] epoch: 2114/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-22:00:06] epoch: 2114/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:00:06] epoch: 2114/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:00:12] epoch: 2115/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200404-22:00:12] epoch: 2115/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:00:12] epoch: 2115/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:00:17] epoch: 2116/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-22:00:17] epoch: 2116/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:00:17] epoch: 2116/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:00:22] epoch: 2117/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-22:00:22] epoch: 2117/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:00:22] epoch: 2117/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:00:27] epoch: 2118/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-22:00:27] epoch: 2118/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:00:27] epoch: 2118/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:00:33] epoch: 2119/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:00:33] epoch: 2119/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:00:33] epoch: 2119/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:00:38] epoch: 2120/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:00:38] epoch: 2120/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:00:38] epoch: 2120/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:00:43] epoch: 2121/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:00:43] epoch: 2121/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:00:43] epoch: 2121/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:00:48] epoch: 2122/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:00:48] epoch: 2122/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:00:48] epoch: 2122/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:00:54] epoch: 2123/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:00:54] epoch: 2123/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:00:54] epoch: 2123/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-22:00:59] epoch: 2124/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:00:59] epoch: 2124/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:00:59] epoch: 2124/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-22:01:04] epoch: 2125/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:01:04] epoch: 2125/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:04] epoch: 2125/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:01:10] epoch: 2126/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:01:10] epoch: 2126/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:10] epoch: 2126/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:01:15] epoch: 2127/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:01:15] epoch: 2127/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:15] epoch: 2127/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:01:20] epoch: 2128/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:01:20] epoch: 2128/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:20] epoch: 2128/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:01:26] epoch: 2129/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:01:26] epoch: 2129/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:26] epoch: 2129/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:01:31] epoch: 2130/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:01:31] epoch: 2130/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:31] epoch: 2130/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:01:36] epoch: 2131/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:01:36] epoch: 2131/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:36] epoch: 2131/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:01:41] epoch: 2132/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:01:41] epoch: 2132/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:41] epoch: 2132/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:01:47] epoch: 2133/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:01:47] epoch: 2133/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:47] epoch: 2133/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:01:52] epoch: 2134/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:01:52] epoch: 2134/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:52] epoch: 2134/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:01:57] epoch: 2135/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:01:57] epoch: 2135/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:01:57] epoch: 2135/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:02:03] epoch: 2136/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:02:03] epoch: 2136/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:03] epoch: 2136/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:02:08] epoch: 2137/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:02:08] epoch: 2137/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:08] epoch: 2137/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:02:13] epoch: 2138/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:02:13] epoch: 2138/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:13] epoch: 2138/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:02:18] epoch: 2139/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:02:18] epoch: 2139/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:18] epoch: 2139/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:02:24] epoch: 2140/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:02:24] epoch: 2140/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:24] epoch: 2140/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-22:02:29] epoch: 2141/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:02:29] epoch: 2141/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:29] epoch: 2141/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-22:02:34] epoch: 2142/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:02:34] epoch: 2142/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:34] epoch: 2142/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-22:02:40] epoch: 2143/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:02:40] epoch: 2143/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:40] epoch: 2143/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-22:02:45] epoch: 2144/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-22:02:45] epoch: 2144/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:45] epoch: 2144/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-22:02:50] epoch: 2145/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:02:50] epoch: 2145/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:50] epoch: 2145/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-22:02:56] epoch: 2146/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:02:56] epoch: 2146/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:02:56] epoch: 2146/5000, generator loss: 0.6929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:03:01] epoch: 2147/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:03:01] epoch: 2147/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:03:01] epoch: 2147/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-22:03:06] epoch: 2148/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:03:06] epoch: 2148/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:03:06] epoch: 2148/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-22:03:12] epoch: 2149/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:03:12] epoch: 2149/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:03:12] epoch: 2149/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:03:17] epoch: 2150/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:03:17] epoch: 2150/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:03:17] epoch: 2150/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:03:22] epoch: 2151/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:03:22] epoch: 2151/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:03:22] epoch: 2151/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:03:27] epoch: 2152/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:03:27] epoch: 2152/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:03:27] epoch: 2152/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:03:33] epoch: 2153/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:03:33] epoch: 2153/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:03:33] epoch: 2153/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:03:38] epoch: 2154/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-22:03:38] epoch: 2154/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:03:38] epoch: 2154/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:03:43] epoch: 2155/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:03:43] epoch: 2155/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:03:43] epoch: 2155/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:03:49] epoch: 2156/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:03:49] epoch: 2156/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:03:49] epoch: 2156/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:03:54] epoch: 2157/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:03:54] epoch: 2157/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:03:54] epoch: 2157/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:03:59] epoch: 2158/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:03:59] epoch: 2158/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:03:59] epoch: 2158/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:04:04] epoch: 2159/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:04:04] epoch: 2159/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:04:04] epoch: 2159/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:04:10] epoch: 2160/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:04:10] epoch: 2160/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:04:10] epoch: 2160/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:04:15] epoch: 2161/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:04:15] epoch: 2161/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:04:15] epoch: 2161/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-22:04:20] epoch: 2162/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:04:20] epoch: 2162/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:04:20] epoch: 2162/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-22:04:25] epoch: 2163/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:04:25] epoch: 2163/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:04:25] epoch: 2163/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-22:04:31] epoch: 2164/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:04:31] epoch: 2164/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:04:31] epoch: 2164/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-22:04:36] epoch: 2165/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:04:36] epoch: 2165/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:04:36] epoch: 2165/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-22:04:41] epoch: 2166/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:04:41] epoch: 2166/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:04:41] epoch: 2166/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-22:04:46] epoch: 2167/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:04:46] epoch: 2167/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:04:46] epoch: 2167/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:04:52] epoch: 2168/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:04:52] epoch: 2168/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:04:52] epoch: 2168/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-22:04:57] epoch: 2169/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:04:57] epoch: 2169/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:04:57] epoch: 2169/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:05:02] epoch: 2170/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-22:05:02] epoch: 2170/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:05:02] epoch: 2170/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:05:07] epoch: 2171/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-22:05:07] epoch: 2171/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:05:07] epoch: 2171/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:05:13] epoch: 2172/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:05:13] epoch: 2172/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:05:13] epoch: 2172/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:05:18] epoch: 2173/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:05:18] epoch: 2173/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:05:18] epoch: 2173/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:05:23] epoch: 2174/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:05:23] epoch: 2174/5000, discriminator loss: 1.3847\n",
      "[LOG TRAIN 20200404-22:05:23] epoch: 2174/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:05:28] epoch: 2175/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:05:28] epoch: 2175/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:05:28] epoch: 2175/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:05:34] epoch: 2176/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:05:34] epoch: 2176/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:05:34] epoch: 2176/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:05:39] epoch: 2177/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:05:39] epoch: 2177/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:05:39] epoch: 2177/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:05:44] epoch: 2178/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-22:05:44] epoch: 2178/5000, discriminator loss: 1.3846\n",
      "[LOG TRAIN 20200404-22:05:44] epoch: 2178/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:05:49] epoch: 2179/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-22:05:49] epoch: 2179/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:05:49] epoch: 2179/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:05:55] epoch: 2180/5000, reconstruction loss: 0.0234\n",
      "[LOG TRAIN 20200404-22:05:55] epoch: 2180/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:05:55] epoch: 2180/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:06:00] epoch: 2181/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200404-22:06:00] epoch: 2181/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:00] epoch: 2181/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:06:06] epoch: 2182/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200404-22:06:06] epoch: 2182/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:06] epoch: 2182/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-22:06:11] epoch: 2183/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-22:06:11] epoch: 2183/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:11] epoch: 2183/5000, generator loss: 0.6930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:06:16] epoch: 2184/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-22:06:16] epoch: 2184/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:16] epoch: 2184/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:06:22] epoch: 2185/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-22:06:22] epoch: 2185/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:22] epoch: 2185/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:06:27] epoch: 2186/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-22:06:27] epoch: 2186/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:27] epoch: 2186/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:06:32] epoch: 2187/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:06:32] epoch: 2187/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:32] epoch: 2187/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:06:37] epoch: 2188/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:06:37] epoch: 2188/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:37] epoch: 2188/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:06:43] epoch: 2189/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:06:43] epoch: 2189/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:43] epoch: 2189/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:06:48] epoch: 2190/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:06:48] epoch: 2190/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:48] epoch: 2190/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:06:53] epoch: 2191/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:06:53] epoch: 2191/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:53] epoch: 2191/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:06:58] epoch: 2192/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:06:58] epoch: 2192/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:06:58] epoch: 2192/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:07:04] epoch: 2193/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:07:04] epoch: 2193/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:04] epoch: 2193/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:07:09] epoch: 2194/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:07:09] epoch: 2194/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:09] epoch: 2194/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:07:15] epoch: 2195/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:07:15] epoch: 2195/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:15] epoch: 2195/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:07:20] epoch: 2196/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:07:20] epoch: 2196/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:20] epoch: 2196/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-22:07:25] epoch: 2197/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:07:25] epoch: 2197/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:25] epoch: 2197/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-22:07:30] epoch: 2198/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:07:30] epoch: 2198/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:30] epoch: 2198/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:07:36] epoch: 2199/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:07:36] epoch: 2199/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:36] epoch: 2199/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-22:07:41] epoch: 2200/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:07:41] epoch: 2200/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:41] epoch: 2200/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:07:46] epoch: 2201/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:07:46] epoch: 2201/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:46] epoch: 2201/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:07:51] epoch: 2202/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:07:51] epoch: 2202/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:51] epoch: 2202/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:07:57] epoch: 2203/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:07:57] epoch: 2203/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:07:57] epoch: 2203/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:08:02] epoch: 2204/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:08:02] epoch: 2204/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:02] epoch: 2204/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:08:07] epoch: 2205/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:08:07] epoch: 2205/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:07] epoch: 2205/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:08:12] epoch: 2206/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:08:12] epoch: 2206/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:12] epoch: 2206/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:08:18] epoch: 2207/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:08:18] epoch: 2207/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:18] epoch: 2207/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:08:23] epoch: 2208/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:08:23] epoch: 2208/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:23] epoch: 2208/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:08:28] epoch: 2209/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:08:28] epoch: 2209/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:28] epoch: 2209/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:08:33] epoch: 2210/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:08:33] epoch: 2210/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:33] epoch: 2210/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:08:39] epoch: 2211/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:08:39] epoch: 2211/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:39] epoch: 2211/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:08:44] epoch: 2212/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:08:44] epoch: 2212/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:44] epoch: 2212/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:08:49] epoch: 2213/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:08:49] epoch: 2213/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:49] epoch: 2213/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:08:54] epoch: 2214/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:08:54] epoch: 2214/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:08:54] epoch: 2214/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:09:00] epoch: 2215/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:09:00] epoch: 2215/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:09:00] epoch: 2215/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:09:05] epoch: 2216/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:09:05] epoch: 2216/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:09:05] epoch: 2216/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:09:11] epoch: 2217/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:09:11] epoch: 2217/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:09:11] epoch: 2217/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:09:16] epoch: 2218/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:09:16] epoch: 2218/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:09:16] epoch: 2218/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-22:09:21] epoch: 2219/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:09:21] epoch: 2219/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:09:21] epoch: 2219/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:09:26] epoch: 2220/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:09:26] epoch: 2220/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:09:26] epoch: 2220/5000, generator loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:09:32] epoch: 2221/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:09:32] epoch: 2221/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:09:32] epoch: 2221/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:09:37] epoch: 2222/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:09:37] epoch: 2222/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:09:37] epoch: 2222/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:09:42] epoch: 2223/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:09:42] epoch: 2223/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:09:42] epoch: 2223/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:09:47] epoch: 2224/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:09:47] epoch: 2224/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:09:47] epoch: 2224/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:09:53] epoch: 2225/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:09:53] epoch: 2225/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:09:53] epoch: 2225/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:09:58] epoch: 2226/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:09:58] epoch: 2226/5000, discriminator loss: 1.3845\n",
      "[LOG TRAIN 20200404-22:09:58] epoch: 2226/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:10:03] epoch: 2227/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:10:03] epoch: 2227/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:10:03] epoch: 2227/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:10:09] epoch: 2228/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:10:09] epoch: 2228/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:10:09] epoch: 2228/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:10:14] epoch: 2229/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:10:14] epoch: 2229/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:10:14] epoch: 2229/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:10:19] epoch: 2230/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-22:10:19] epoch: 2230/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:10:19] epoch: 2230/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:10:24] epoch: 2231/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-22:10:24] epoch: 2231/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:10:24] epoch: 2231/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:10:30] epoch: 2232/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-22:10:30] epoch: 2232/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:10:30] epoch: 2232/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:10:35] epoch: 2233/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-22:10:35] epoch: 2233/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:10:35] epoch: 2233/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:10:40] epoch: 2234/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-22:10:40] epoch: 2234/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:10:40] epoch: 2234/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:10:46] epoch: 2235/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-22:10:46] epoch: 2235/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:10:46] epoch: 2235/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:10:51] epoch: 2236/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-22:10:51] epoch: 2236/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:10:51] epoch: 2236/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:10:56] epoch: 2237/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:10:56] epoch: 2237/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:10:56] epoch: 2237/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:11:01] epoch: 2238/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:11:01] epoch: 2238/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:11:01] epoch: 2238/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:11:07] epoch: 2239/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:11:07] epoch: 2239/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:11:07] epoch: 2239/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:11:12] epoch: 2240/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:11:12] epoch: 2240/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:11:12] epoch: 2240/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:11:17] epoch: 2241/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:11:17] epoch: 2241/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:11:17] epoch: 2241/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:11:23] epoch: 2242/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:11:23] epoch: 2242/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:11:23] epoch: 2242/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:11:28] epoch: 2243/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:11:28] epoch: 2243/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:11:28] epoch: 2243/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:11:33] epoch: 2244/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:11:33] epoch: 2244/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:11:33] epoch: 2244/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:11:38] epoch: 2245/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:11:38] epoch: 2245/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:11:38] epoch: 2245/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:11:44] epoch: 2246/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:11:44] epoch: 2246/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:11:44] epoch: 2246/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:11:49] epoch: 2247/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:11:49] epoch: 2247/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:11:49] epoch: 2247/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:11:54] epoch: 2248/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:11:54] epoch: 2248/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:11:54] epoch: 2248/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:12:00] epoch: 2249/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:12:00] epoch: 2249/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:12:00] epoch: 2249/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:12:05] epoch: 2250/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:12:05] epoch: 2250/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:12:05] epoch: 2250/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:12:11] epoch: 2251/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:12:11] epoch: 2251/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:12:11] epoch: 2251/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:12:16] epoch: 2252/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:12:16] epoch: 2252/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:12:16] epoch: 2252/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:12:21] epoch: 2253/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:12:21] epoch: 2253/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:12:21] epoch: 2253/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:12:26] epoch: 2254/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:12:26] epoch: 2254/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:12:26] epoch: 2254/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:12:32] epoch: 2255/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:12:32] epoch: 2255/5000, discriminator loss: 1.3844\n",
      "[LOG TRAIN 20200404-22:12:32] epoch: 2255/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:12:37] epoch: 2256/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:12:37] epoch: 2256/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:12:37] epoch: 2256/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:12:42] epoch: 2257/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:12:42] epoch: 2257/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:12:42] epoch: 2257/5000, generator loss: 0.6929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:12:48] epoch: 2258/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:12:48] epoch: 2258/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:12:48] epoch: 2258/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200404-22:12:53] epoch: 2259/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:12:53] epoch: 2259/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:12:53] epoch: 2259/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200404-22:12:58] epoch: 2260/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:12:58] epoch: 2260/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:12:58] epoch: 2260/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:13:04] epoch: 2261/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-22:13:04] epoch: 2261/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:13:04] epoch: 2261/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:13:09] epoch: 2262/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:13:09] epoch: 2262/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:13:09] epoch: 2262/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:13:14] epoch: 2263/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:13:14] epoch: 2263/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:13:14] epoch: 2263/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:13:19] epoch: 2264/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:13:19] epoch: 2264/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:13:19] epoch: 2264/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200404-22:13:25] epoch: 2265/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:13:25] epoch: 2265/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:13:25] epoch: 2265/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:13:30] epoch: 2266/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:13:30] epoch: 2266/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:13:30] epoch: 2266/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:13:35] epoch: 2267/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:13:35] epoch: 2267/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:13:35] epoch: 2267/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:13:41] epoch: 2268/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:13:41] epoch: 2268/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:13:41] epoch: 2268/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:13:46] epoch: 2269/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:13:46] epoch: 2269/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:13:46] epoch: 2269/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:13:51] epoch: 2270/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:13:51] epoch: 2270/5000, discriminator loss: 1.3843\n",
      "[LOG TRAIN 20200404-22:13:51] epoch: 2270/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:13:56] epoch: 2271/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:13:56] epoch: 2271/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:13:56] epoch: 2271/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:14:02] epoch: 2272/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:14:02] epoch: 2272/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:02] epoch: 2272/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:14:07] epoch: 2273/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:14:07] epoch: 2273/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:07] epoch: 2273/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:14:12] epoch: 2274/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:14:12] epoch: 2274/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:12] epoch: 2274/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:14:18] epoch: 2275/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:14:18] epoch: 2275/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:18] epoch: 2275/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:14:23] epoch: 2276/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:14:23] epoch: 2276/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:23] epoch: 2276/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:14:28] epoch: 2277/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:14:28] epoch: 2277/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:28] epoch: 2277/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:14:33] epoch: 2278/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:14:33] epoch: 2278/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:33] epoch: 2278/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:14:39] epoch: 2279/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:14:39] epoch: 2279/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:39] epoch: 2279/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:14:44] epoch: 2280/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-22:14:44] epoch: 2280/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:44] epoch: 2280/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:14:49] epoch: 2281/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:14:49] epoch: 2281/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:49] epoch: 2281/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:14:55] epoch: 2282/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:14:55] epoch: 2282/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:14:55] epoch: 2282/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:15:00] epoch: 2283/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:15:00] epoch: 2283/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:15:00] epoch: 2283/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:15:06] epoch: 2284/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:15:06] epoch: 2284/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:15:06] epoch: 2284/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:15:11] epoch: 2285/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:15:11] epoch: 2285/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:15:11] epoch: 2285/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:15:16] epoch: 2286/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:15:16] epoch: 2286/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:15:16] epoch: 2286/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:15:22] epoch: 2287/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:15:22] epoch: 2287/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:15:22] epoch: 2287/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:15:27] epoch: 2288/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:15:27] epoch: 2288/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:15:27] epoch: 2288/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:15:32] epoch: 2289/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:15:32] epoch: 2289/5000, discriminator loss: 1.3842\n",
      "[LOG TRAIN 20200404-22:15:32] epoch: 2289/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:15:37] epoch: 2290/5000, reconstruction loss: 0.0220\n",
      "[LOG TRAIN 20200404-22:15:37] epoch: 2290/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:15:37] epoch: 2290/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:15:43] epoch: 2291/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-22:15:43] epoch: 2291/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:15:43] epoch: 2291/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:15:48] epoch: 2292/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-22:15:48] epoch: 2292/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:15:48] epoch: 2292/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:15:53] epoch: 2293/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-22:15:53] epoch: 2293/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:15:53] epoch: 2293/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:15:59] epoch: 2294/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-22:15:59] epoch: 2294/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:15:59] epoch: 2294/5000, generator loss: 0.6932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:16:04] epoch: 2295/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:16:04] epoch: 2295/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:04] epoch: 2295/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:16:09] epoch: 2296/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:16:09] epoch: 2296/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:09] epoch: 2296/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:16:14] epoch: 2297/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:16:14] epoch: 2297/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:14] epoch: 2297/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:16:20] epoch: 2298/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:16:20] epoch: 2298/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:20] epoch: 2298/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:16:25] epoch: 2299/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:16:25] epoch: 2299/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:25] epoch: 2299/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:16:30] epoch: 2300/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:16:30] epoch: 2300/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:30] epoch: 2300/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:16:36] epoch: 2301/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:16:36] epoch: 2301/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:36] epoch: 2301/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:16:41] epoch: 2302/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:16:41] epoch: 2302/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:41] epoch: 2302/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:16:46] epoch: 2303/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:16:46] epoch: 2303/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:46] epoch: 2303/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:16:52] epoch: 2304/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:16:52] epoch: 2304/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:52] epoch: 2304/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:16:57] epoch: 2305/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:16:57] epoch: 2305/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:16:57] epoch: 2305/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:17:02] epoch: 2306/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:17:02] epoch: 2306/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:02] epoch: 2306/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:17:07] epoch: 2307/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:17:07] epoch: 2307/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:07] epoch: 2307/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:17:13] epoch: 2308/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:17:13] epoch: 2308/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:13] epoch: 2308/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:17:18] epoch: 2309/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:17:18] epoch: 2309/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:18] epoch: 2309/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:17:23] epoch: 2310/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:17:23] epoch: 2310/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:23] epoch: 2310/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:17:29] epoch: 2311/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:17:29] epoch: 2311/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:29] epoch: 2311/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:17:34] epoch: 2312/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:17:34] epoch: 2312/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:34] epoch: 2312/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:17:39] epoch: 2313/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:17:39] epoch: 2313/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:39] epoch: 2313/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:17:44] epoch: 2314/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-22:17:44] epoch: 2314/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:44] epoch: 2314/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:17:50] epoch: 2315/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:17:50] epoch: 2315/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:50] epoch: 2315/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:17:55] epoch: 2316/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:17:55] epoch: 2316/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:17:55] epoch: 2316/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:18:01] epoch: 2317/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:18:01] epoch: 2317/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:18:01] epoch: 2317/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:18:06] epoch: 2318/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:18:06] epoch: 2318/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:18:06] epoch: 2318/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:18:11] epoch: 2319/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:18:11] epoch: 2319/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:18:11] epoch: 2319/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:18:17] epoch: 2320/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:18:17] epoch: 2320/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:18:17] epoch: 2320/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:18:22] epoch: 2321/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:18:22] epoch: 2321/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:18:22] epoch: 2321/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:18:27] epoch: 2322/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:18:27] epoch: 2322/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:18:27] epoch: 2322/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:18:32] epoch: 2323/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:18:32] epoch: 2323/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:18:32] epoch: 2323/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:18:38] epoch: 2324/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:18:38] epoch: 2324/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:18:38] epoch: 2324/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:18:43] epoch: 2325/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:18:43] epoch: 2325/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:18:43] epoch: 2325/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:18:49] epoch: 2326/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:18:49] epoch: 2326/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:18:49] epoch: 2326/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:18:54] epoch: 2327/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:18:54] epoch: 2327/5000, discriminator loss: 1.3841\n",
      "[LOG TRAIN 20200404-22:18:54] epoch: 2327/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:18:59] epoch: 2328/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:18:59] epoch: 2328/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:18:59] epoch: 2328/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:19:04] epoch: 2329/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:19:04] epoch: 2329/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:04] epoch: 2329/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:19:10] epoch: 2330/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:19:10] epoch: 2330/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:10] epoch: 2330/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:19:15] epoch: 2331/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:19:15] epoch: 2331/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:15] epoch: 2331/5000, generator loss: 0.6933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:19:20] epoch: 2332/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:19:20] epoch: 2332/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:20] epoch: 2332/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200404-22:19:26] epoch: 2333/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:19:26] epoch: 2333/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:26] epoch: 2333/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:19:31] epoch: 2334/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:19:31] epoch: 2334/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:31] epoch: 2334/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:19:36] epoch: 2335/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-22:19:36] epoch: 2335/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:36] epoch: 2335/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:19:42] epoch: 2336/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:19:42] epoch: 2336/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:42] epoch: 2336/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:19:47] epoch: 2337/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:19:47] epoch: 2337/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:47] epoch: 2337/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:19:52] epoch: 2338/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:19:52] epoch: 2338/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:52] epoch: 2338/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:19:58] epoch: 2339/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:19:58] epoch: 2339/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:19:58] epoch: 2339/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:20:03] epoch: 2340/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:20:03] epoch: 2340/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:03] epoch: 2340/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:20:08] epoch: 2341/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:20:08] epoch: 2341/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:08] epoch: 2341/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:20:13] epoch: 2342/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:20:13] epoch: 2342/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:13] epoch: 2342/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:20:19] epoch: 2343/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:20:19] epoch: 2343/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:19] epoch: 2343/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:20:24] epoch: 2344/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:20:24] epoch: 2344/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:24] epoch: 2344/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:20:29] epoch: 2345/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:20:29] epoch: 2345/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:29] epoch: 2345/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:20:35] epoch: 2346/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:20:35] epoch: 2346/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:35] epoch: 2346/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:20:40] epoch: 2347/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:20:40] epoch: 2347/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:40] epoch: 2347/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:20:45] epoch: 2348/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:20:45] epoch: 2348/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:45] epoch: 2348/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:20:51] epoch: 2349/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:20:51] epoch: 2349/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:51] epoch: 2349/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:20:56] epoch: 2350/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:20:56] epoch: 2350/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:20:56] epoch: 2350/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:21:02] epoch: 2351/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:21:02] epoch: 2351/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:21:02] epoch: 2351/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:21:07] epoch: 2352/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:21:07] epoch: 2352/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:21:07] epoch: 2352/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:21:13] epoch: 2353/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:21:13] epoch: 2353/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:21:13] epoch: 2353/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:21:18] epoch: 2354/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:21:18] epoch: 2354/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:21:18] epoch: 2354/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:21:23] epoch: 2355/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:21:23] epoch: 2355/5000, discriminator loss: 1.3840\n",
      "[LOG TRAIN 20200404-22:21:23] epoch: 2355/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:21:28] epoch: 2356/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:21:28] epoch: 2356/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:21:28] epoch: 2356/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:21:34] epoch: 2357/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:21:34] epoch: 2357/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:21:34] epoch: 2357/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:21:39] epoch: 2358/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:21:39] epoch: 2358/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:21:39] epoch: 2358/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:21:44] epoch: 2359/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-22:21:44] epoch: 2359/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:21:44] epoch: 2359/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:21:49] epoch: 2360/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:21:49] epoch: 2360/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:21:49] epoch: 2360/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:21:55] epoch: 2361/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:21:55] epoch: 2361/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:21:55] epoch: 2361/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:22:00] epoch: 2362/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:22:00] epoch: 2362/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:00] epoch: 2362/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:22:05] epoch: 2363/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:22:05] epoch: 2363/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:05] epoch: 2363/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:22:10] epoch: 2364/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:22:10] epoch: 2364/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:10] epoch: 2364/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:22:16] epoch: 2365/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:22:16] epoch: 2365/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:16] epoch: 2365/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:22:21] epoch: 2366/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-22:22:21] epoch: 2366/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:21] epoch: 2366/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:22:26] epoch: 2367/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:22:26] epoch: 2367/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:26] epoch: 2367/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:22:32] epoch: 2368/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:22:32] epoch: 2368/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:32] epoch: 2368/5000, generator loss: 0.6938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:22:37] epoch: 2369/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:22:37] epoch: 2369/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:37] epoch: 2369/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:22:42] epoch: 2370/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:22:42] epoch: 2370/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:42] epoch: 2370/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:22:48] epoch: 2371/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:22:48] epoch: 2371/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:48] epoch: 2371/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:22:53] epoch: 2372/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:22:53] epoch: 2372/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:22:53] epoch: 2372/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:22:58] epoch: 2373/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-22:22:58] epoch: 2373/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:22:58] epoch: 2373/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:23:04] epoch: 2374/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-22:23:04] epoch: 2374/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:04] epoch: 2374/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:23:09] epoch: 2375/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-22:23:09] epoch: 2375/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:09] epoch: 2375/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:23:14] epoch: 2376/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:23:14] epoch: 2376/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:14] epoch: 2376/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:23:19] epoch: 2377/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:23:19] epoch: 2377/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:19] epoch: 2377/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:23:25] epoch: 2378/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:23:25] epoch: 2378/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:25] epoch: 2378/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:23:30] epoch: 2379/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:23:30] epoch: 2379/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:30] epoch: 2379/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:23:35] epoch: 2380/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:23:35] epoch: 2380/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:35] epoch: 2380/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:23:41] epoch: 2381/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:23:41] epoch: 2381/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:41] epoch: 2381/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:23:46] epoch: 2382/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:23:46] epoch: 2382/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:46] epoch: 2382/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:23:51] epoch: 2383/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:23:51] epoch: 2383/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:51] epoch: 2383/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:23:57] epoch: 2384/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:23:57] epoch: 2384/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:23:57] epoch: 2384/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:24:02] epoch: 2385/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:24:02] epoch: 2385/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:24:02] epoch: 2385/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:24:08] epoch: 2386/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:24:08] epoch: 2386/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:24:08] epoch: 2386/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:24:13] epoch: 2387/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:24:13] epoch: 2387/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:24:13] epoch: 2387/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:24:18] epoch: 2388/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:24:18] epoch: 2388/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:24:18] epoch: 2388/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:24:23] epoch: 2389/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:24:23] epoch: 2389/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:24:23] epoch: 2389/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:24:29] epoch: 2390/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:24:29] epoch: 2390/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:24:29] epoch: 2390/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:24:34] epoch: 2391/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:24:34] epoch: 2391/5000, discriminator loss: 1.3839\n",
      "[LOG TRAIN 20200404-22:24:34] epoch: 2391/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:24:39] epoch: 2392/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:24:39] epoch: 2392/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:24:39] epoch: 2392/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:24:44] epoch: 2393/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:24:44] epoch: 2393/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:24:44] epoch: 2393/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:24:50] epoch: 2394/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-22:24:50] epoch: 2394/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:24:50] epoch: 2394/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:24:55] epoch: 2395/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200404-22:24:55] epoch: 2395/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:24:55] epoch: 2395/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:25:00] epoch: 2396/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-22:25:00] epoch: 2396/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:25:00] epoch: 2396/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:25:05] epoch: 2397/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-22:25:05] epoch: 2397/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:25:05] epoch: 2397/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:25:11] epoch: 2398/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:25:11] epoch: 2398/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:25:11] epoch: 2398/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:25:16] epoch: 2399/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:25:16] epoch: 2399/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:25:16] epoch: 2399/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:25:21] epoch: 2400/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:25:21] epoch: 2400/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:25:21] epoch: 2400/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:25:26] epoch: 2401/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:25:26] epoch: 2401/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:25:26] epoch: 2401/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:25:32] epoch: 2402/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:25:32] epoch: 2402/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:25:32] epoch: 2402/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:25:37] epoch: 2403/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:25:37] epoch: 2403/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:25:37] epoch: 2403/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:25:42] epoch: 2404/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:25:42] epoch: 2404/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:25:42] epoch: 2404/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:25:47] epoch: 2405/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:25:47] epoch: 2405/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:25:47] epoch: 2405/5000, generator loss: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:25:53] epoch: 2406/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:25:53] epoch: 2406/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:25:53] epoch: 2406/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:25:58] epoch: 2407/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:25:58] epoch: 2407/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:25:58] epoch: 2407/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:26:03] epoch: 2408/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:26:03] epoch: 2408/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:03] epoch: 2408/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:26:09] epoch: 2409/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:26:09] epoch: 2409/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:09] epoch: 2409/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:26:14] epoch: 2410/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:26:14] epoch: 2410/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:14] epoch: 2410/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:26:19] epoch: 2411/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:26:19] epoch: 2411/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:19] epoch: 2411/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:26:24] epoch: 2412/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:26:24] epoch: 2412/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:24] epoch: 2412/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:26:30] epoch: 2413/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:26:30] epoch: 2413/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:30] epoch: 2413/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:26:35] epoch: 2414/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:26:35] epoch: 2414/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:35] epoch: 2414/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:26:40] epoch: 2415/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:26:40] epoch: 2415/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:40] epoch: 2415/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:26:46] epoch: 2416/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:26:46] epoch: 2416/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:46] epoch: 2416/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:26:51] epoch: 2417/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:26:51] epoch: 2417/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:51] epoch: 2417/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:26:56] epoch: 2418/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:26:56] epoch: 2418/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:26:56] epoch: 2418/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:27:02] epoch: 2419/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:27:02] epoch: 2419/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:02] epoch: 2419/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:27:07] epoch: 2420/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:27:07] epoch: 2420/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:07] epoch: 2420/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:27:13] epoch: 2421/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:27:13] epoch: 2421/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:13] epoch: 2421/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:27:18] epoch: 2422/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:27:18] epoch: 2422/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:18] epoch: 2422/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:27:23] epoch: 2423/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:27:23] epoch: 2423/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:23] epoch: 2423/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:27:28] epoch: 2424/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-22:27:28] epoch: 2424/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:28] epoch: 2424/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:27:34] epoch: 2425/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:27:34] epoch: 2425/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:34] epoch: 2425/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:27:39] epoch: 2426/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:27:39] epoch: 2426/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:39] epoch: 2426/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:27:44] epoch: 2427/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:27:44] epoch: 2427/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:44] epoch: 2427/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:27:50] epoch: 2428/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:27:50] epoch: 2428/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:50] epoch: 2428/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:27:55] epoch: 2429/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:27:55] epoch: 2429/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:27:55] epoch: 2429/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:28:00] epoch: 2430/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:28:00] epoch: 2430/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:28:00] epoch: 2430/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:28:05] epoch: 2431/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:28:05] epoch: 2431/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:28:05] epoch: 2431/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:28:11] epoch: 2432/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:28:11] epoch: 2432/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:28:11] epoch: 2432/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:28:16] epoch: 2433/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:28:16] epoch: 2433/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:28:16] epoch: 2433/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:28:21] epoch: 2434/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:28:21] epoch: 2434/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:28:21] epoch: 2434/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:28:26] epoch: 2435/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:28:26] epoch: 2435/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:28:26] epoch: 2435/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:28:32] epoch: 2436/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:28:32] epoch: 2436/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:28:32] epoch: 2436/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:28:37] epoch: 2437/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:28:37] epoch: 2437/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:28:37] epoch: 2437/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:28:42] epoch: 2438/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:28:42] epoch: 2438/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:28:42] epoch: 2438/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:28:48] epoch: 2439/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:28:48] epoch: 2439/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:28:48] epoch: 2439/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:28:53] epoch: 2440/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:28:53] epoch: 2440/5000, discriminator loss: 1.3838\n",
      "[LOG TRAIN 20200404-22:28:53] epoch: 2440/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:28:58] epoch: 2441/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-22:28:58] epoch: 2441/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:28:58] epoch: 2441/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:29:03] epoch: 2442/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-22:29:03] epoch: 2442/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:29:03] epoch: 2442/5000, generator loss: 0.6949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:29:09] epoch: 2443/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200404-22:29:09] epoch: 2443/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:29:09] epoch: 2443/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-22:29:14] epoch: 2444/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-22:29:14] epoch: 2444/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:29:14] epoch: 2444/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:29:20] epoch: 2445/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-22:29:20] epoch: 2445/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:29:20] epoch: 2445/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:29:25] epoch: 2446/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-22:29:25] epoch: 2446/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:29:25] epoch: 2446/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-22:29:30] epoch: 2447/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-22:29:30] epoch: 2447/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:29:30] epoch: 2447/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-22:29:35] epoch: 2448/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-22:29:35] epoch: 2448/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:29:35] epoch: 2448/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-22:29:41] epoch: 2449/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-22:29:41] epoch: 2449/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:29:41] epoch: 2449/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:29:46] epoch: 2450/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:29:46] epoch: 2450/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:29:46] epoch: 2450/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:29:51] epoch: 2451/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:29:51] epoch: 2451/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:29:51] epoch: 2451/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-22:29:57] epoch: 2452/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:29:57] epoch: 2452/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:29:57] epoch: 2452/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:30:02] epoch: 2453/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:30:02] epoch: 2453/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:30:02] epoch: 2453/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:30:07] epoch: 2454/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:30:07] epoch: 2454/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:30:07] epoch: 2454/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:30:13] epoch: 2455/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:30:13] epoch: 2455/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:30:13] epoch: 2455/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:30:18] epoch: 2456/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:30:18] epoch: 2456/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:30:18] epoch: 2456/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:30:23] epoch: 2457/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:30:23] epoch: 2457/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:30:23] epoch: 2457/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:30:29] epoch: 2458/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:30:29] epoch: 2458/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:30:29] epoch: 2458/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-22:30:34] epoch: 2459/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:30:34] epoch: 2459/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:30:34] epoch: 2459/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:30:39] epoch: 2460/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:30:39] epoch: 2460/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:30:39] epoch: 2460/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-22:30:44] epoch: 2461/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:30:44] epoch: 2461/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:30:44] epoch: 2461/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200404-22:30:50] epoch: 2462/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:30:50] epoch: 2462/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:30:50] epoch: 2462/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200404-22:30:55] epoch: 2463/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:30:55] epoch: 2463/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:30:55] epoch: 2463/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200404-22:31:00] epoch: 2464/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:31:00] epoch: 2464/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:00] epoch: 2464/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200404-22:31:05] epoch: 2465/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:31:05] epoch: 2465/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:05] epoch: 2465/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200404-22:31:11] epoch: 2466/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:31:11] epoch: 2466/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:11] epoch: 2466/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200404-22:31:16] epoch: 2467/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:31:16] epoch: 2467/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:16] epoch: 2467/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200404-22:31:21] epoch: 2468/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:31:21] epoch: 2468/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:21] epoch: 2468/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200404-22:31:26] epoch: 2469/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:31:26] epoch: 2469/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:26] epoch: 2469/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-22:31:32] epoch: 2470/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:31:32] epoch: 2470/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:32] epoch: 2470/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-22:31:37] epoch: 2471/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:31:37] epoch: 2471/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:37] epoch: 2471/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-22:31:42] epoch: 2472/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:31:42] epoch: 2472/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:42] epoch: 2472/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:31:48] epoch: 2473/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:31:48] epoch: 2473/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:48] epoch: 2473/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:31:53] epoch: 2474/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:31:53] epoch: 2474/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:53] epoch: 2474/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:31:58] epoch: 2475/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:31:58] epoch: 2475/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:31:58] epoch: 2475/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:32:03] epoch: 2476/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:32:03] epoch: 2476/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:03] epoch: 2476/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:32:09] epoch: 2477/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:32:09] epoch: 2477/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:09] epoch: 2477/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:32:14] epoch: 2478/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:32:14] epoch: 2478/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:14] epoch: 2478/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:32:19] epoch: 2479/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:32:19] epoch: 2479/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:19] epoch: 2479/5000, generator loss: 0.6945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:32:24] epoch: 2480/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:32:24] epoch: 2480/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:24] epoch: 2480/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:32:30] epoch: 2481/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:32:30] epoch: 2481/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:30] epoch: 2481/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:32:35] epoch: 2482/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:32:35] epoch: 2482/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:35] epoch: 2482/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:32:40] epoch: 2483/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:32:40] epoch: 2483/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:40] epoch: 2483/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:32:45] epoch: 2484/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:32:45] epoch: 2484/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:45] epoch: 2484/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:32:51] epoch: 2485/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:32:51] epoch: 2485/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:51] epoch: 2485/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:32:56] epoch: 2486/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:32:56] epoch: 2486/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:32:56] epoch: 2486/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:33:02] epoch: 2487/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:33:02] epoch: 2487/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:33:02] epoch: 2487/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:33:07] epoch: 2488/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:33:07] epoch: 2488/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:33:07] epoch: 2488/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:33:12] epoch: 2489/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:33:12] epoch: 2489/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:33:12] epoch: 2489/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:33:17] epoch: 2490/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:33:17] epoch: 2490/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:33:17] epoch: 2490/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:33:23] epoch: 2491/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:33:23] epoch: 2491/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:33:23] epoch: 2491/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:33:28] epoch: 2492/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:33:28] epoch: 2492/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:33:28] epoch: 2492/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:33:33] epoch: 2493/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:33:33] epoch: 2493/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:33:33] epoch: 2493/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:33:39] epoch: 2494/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:33:39] epoch: 2494/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:33:39] epoch: 2494/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:33:44] epoch: 2495/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:33:44] epoch: 2495/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:33:44] epoch: 2495/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:33:49] epoch: 2496/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:33:49] epoch: 2496/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200404-22:33:49] epoch: 2496/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:33:54] epoch: 2497/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200404-22:33:54] epoch: 2497/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:33:54] epoch: 2497/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:34:00] epoch: 2498/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-22:34:00] epoch: 2498/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:34:00] epoch: 2498/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:34:05] epoch: 2499/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-22:34:05] epoch: 2499/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:34:05] epoch: 2499/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:34:10] epoch: 2500/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-22:34:10] epoch: 2500/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:34:10] epoch: 2500/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:34:16] epoch: 2501/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:34:16] epoch: 2501/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:34:16] epoch: 2501/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:34:21] epoch: 2502/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:34:21] epoch: 2502/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:34:21] epoch: 2502/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:34:26] epoch: 2503/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:34:26] epoch: 2503/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:34:26] epoch: 2503/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:34:31] epoch: 2504/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:34:31] epoch: 2504/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:34:31] epoch: 2504/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:34:37] epoch: 2505/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:34:37] epoch: 2505/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:34:37] epoch: 2505/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:34:42] epoch: 2506/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:34:42] epoch: 2506/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:34:42] epoch: 2506/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:34:47] epoch: 2507/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:34:47] epoch: 2507/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:34:47] epoch: 2507/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:34:53] epoch: 2508/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:34:53] epoch: 2508/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:34:53] epoch: 2508/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:34:58] epoch: 2509/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:34:58] epoch: 2509/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:34:58] epoch: 2509/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:35:03] epoch: 2510/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:35:03] epoch: 2510/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:03] epoch: 2510/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:35:08] epoch: 2511/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:35:08] epoch: 2511/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:08] epoch: 2511/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:35:14] epoch: 2512/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:35:14] epoch: 2512/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:14] epoch: 2512/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:35:19] epoch: 2513/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:35:19] epoch: 2513/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:19] epoch: 2513/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:35:24] epoch: 2514/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:35:24] epoch: 2514/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:24] epoch: 2514/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:35:29] epoch: 2515/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:35:29] epoch: 2515/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:29] epoch: 2515/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:35:35] epoch: 2516/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:35:35] epoch: 2516/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:35] epoch: 2516/5000, generator loss: 0.6943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:35:40] epoch: 2517/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:35:40] epoch: 2517/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:40] epoch: 2517/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:35:45] epoch: 2518/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:35:45] epoch: 2518/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:45] epoch: 2518/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:35:50] epoch: 2519/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:35:50] epoch: 2519/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:50] epoch: 2519/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:35:56] epoch: 2520/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:35:56] epoch: 2520/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:35:56] epoch: 2520/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:36:02] epoch: 2521/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:36:02] epoch: 2521/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:02] epoch: 2521/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:36:07] epoch: 2522/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:36:07] epoch: 2522/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:07] epoch: 2522/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:36:12] epoch: 2523/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:36:12] epoch: 2523/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:12] epoch: 2523/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:36:17] epoch: 2524/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:36:17] epoch: 2524/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:17] epoch: 2524/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:36:23] epoch: 2525/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:36:23] epoch: 2525/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:23] epoch: 2525/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:36:28] epoch: 2526/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:36:28] epoch: 2526/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:28] epoch: 2526/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:36:33] epoch: 2527/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:36:33] epoch: 2527/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:33] epoch: 2527/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:36:38] epoch: 2528/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:36:38] epoch: 2528/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:38] epoch: 2528/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:36:44] epoch: 2529/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:36:44] epoch: 2529/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:44] epoch: 2529/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:36:49] epoch: 2530/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:36:49] epoch: 2530/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:49] epoch: 2530/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:36:54] epoch: 2531/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:36:54] epoch: 2531/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:54] epoch: 2531/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:36:59] epoch: 2532/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:36:59] epoch: 2532/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:36:59] epoch: 2532/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:37:05] epoch: 2533/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:37:05] epoch: 2533/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200404-22:37:05] epoch: 2533/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:37:10] epoch: 2534/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:37:10] epoch: 2534/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:37:10] epoch: 2534/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:37:15] epoch: 2535/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:37:15] epoch: 2535/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:37:15] epoch: 2535/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:37:20] epoch: 2536/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:37:20] epoch: 2536/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:37:20] epoch: 2536/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:37:25] epoch: 2537/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:37:25] epoch: 2537/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:37:25] epoch: 2537/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:37:31] epoch: 2538/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:37:31] epoch: 2538/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:37:31] epoch: 2538/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:37:36] epoch: 2539/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:37:36] epoch: 2539/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:37:36] epoch: 2539/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:37:41] epoch: 2540/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200404-22:37:41] epoch: 2540/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:37:41] epoch: 2540/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:37:47] epoch: 2541/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-22:37:47] epoch: 2541/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:37:47] epoch: 2541/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:37:52] epoch: 2542/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-22:37:52] epoch: 2542/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:37:52] epoch: 2542/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:37:57] epoch: 2543/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-22:37:57] epoch: 2543/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:37:57] epoch: 2543/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:38:02] epoch: 2544/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:38:02] epoch: 2544/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:38:02] epoch: 2544/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:38:08] epoch: 2545/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:38:08] epoch: 2545/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:38:08] epoch: 2545/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:38:13] epoch: 2546/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:38:13] epoch: 2546/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:38:13] epoch: 2546/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:38:18] epoch: 2547/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:38:18] epoch: 2547/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:38:18] epoch: 2547/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:38:23] epoch: 2548/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:38:23] epoch: 2548/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:38:23] epoch: 2548/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:38:29] epoch: 2549/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:38:29] epoch: 2549/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:38:29] epoch: 2549/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:38:34] epoch: 2550/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:38:34] epoch: 2550/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:38:34] epoch: 2550/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:38:39] epoch: 2551/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:38:39] epoch: 2551/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:38:39] epoch: 2551/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:38:44] epoch: 2552/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:38:44] epoch: 2552/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:38:44] epoch: 2552/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:38:50] epoch: 2553/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:38:50] epoch: 2553/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:38:50] epoch: 2553/5000, generator loss: 0.6947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:38:55] epoch: 2554/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:38:55] epoch: 2554/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:38:55] epoch: 2554/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:39:01] epoch: 2555/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:39:01] epoch: 2555/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:01] epoch: 2555/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:39:06] epoch: 2556/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:39:06] epoch: 2556/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:06] epoch: 2556/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:39:11] epoch: 2557/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:39:11] epoch: 2557/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:11] epoch: 2557/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:39:16] epoch: 2558/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:39:16] epoch: 2558/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:16] epoch: 2558/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:39:22] epoch: 2559/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:39:22] epoch: 2559/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:22] epoch: 2559/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:39:27] epoch: 2560/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:39:27] epoch: 2560/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:27] epoch: 2560/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:39:32] epoch: 2561/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:39:32] epoch: 2561/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:32] epoch: 2561/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:39:37] epoch: 2562/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:39:37] epoch: 2562/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:37] epoch: 2562/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:39:43] epoch: 2563/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:39:43] epoch: 2563/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:43] epoch: 2563/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:39:48] epoch: 2564/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:39:48] epoch: 2564/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:48] epoch: 2564/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:39:53] epoch: 2565/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:39:53] epoch: 2565/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:53] epoch: 2565/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:39:59] epoch: 2566/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:39:59] epoch: 2566/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:39:59] epoch: 2566/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:40:04] epoch: 2567/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:40:04] epoch: 2567/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:40:04] epoch: 2567/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:40:09] epoch: 2568/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:40:09] epoch: 2568/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:40:09] epoch: 2568/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:40:14] epoch: 2569/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:40:14] epoch: 2569/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200404-22:40:14] epoch: 2569/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:40:20] epoch: 2570/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:40:20] epoch: 2570/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:40:20] epoch: 2570/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:40:25] epoch: 2571/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:40:25] epoch: 2571/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:40:25] epoch: 2571/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:40:30] epoch: 2572/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:40:30] epoch: 2572/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:40:30] epoch: 2572/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:40:36] epoch: 2573/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:40:36] epoch: 2573/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:40:36] epoch: 2573/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:40:41] epoch: 2574/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:40:41] epoch: 2574/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:40:41] epoch: 2574/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:40:46] epoch: 2575/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:40:46] epoch: 2575/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:40:46] epoch: 2575/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-22:40:51] epoch: 2576/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:40:51] epoch: 2576/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:40:51] epoch: 2576/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:40:57] epoch: 2577/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-22:40:57] epoch: 2577/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:40:57] epoch: 2577/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:41:02] epoch: 2578/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:41:02] epoch: 2578/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:02] epoch: 2578/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:41:07] epoch: 2579/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:41:07] epoch: 2579/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:07] epoch: 2579/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:41:12] epoch: 2580/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:41:12] epoch: 2580/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:12] epoch: 2580/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:41:18] epoch: 2581/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:41:18] epoch: 2581/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:18] epoch: 2581/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:41:23] epoch: 2582/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:41:23] epoch: 2582/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:23] epoch: 2582/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:41:28] epoch: 2583/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:41:28] epoch: 2583/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:28] epoch: 2583/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:41:34] epoch: 2584/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:41:34] epoch: 2584/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:34] epoch: 2584/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:41:39] epoch: 2585/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:41:39] epoch: 2585/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:39] epoch: 2585/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:41:44] epoch: 2586/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-22:41:44] epoch: 2586/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:44] epoch: 2586/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:41:49] epoch: 2587/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:41:49] epoch: 2587/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:49] epoch: 2587/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:41:55] epoch: 2588/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:41:55] epoch: 2588/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:41:55] epoch: 2588/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:42:00] epoch: 2589/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:42:00] epoch: 2589/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:42:00] epoch: 2589/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:42:05] epoch: 2590/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:42:05] epoch: 2590/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:42:05] epoch: 2590/5000, generator loss: 0.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:42:11] epoch: 2591/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:42:11] epoch: 2591/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:42:11] epoch: 2591/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:42:16] epoch: 2592/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:42:16] epoch: 2592/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:42:16] epoch: 2592/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:42:21] epoch: 2593/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:42:21] epoch: 2593/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:42:21] epoch: 2593/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:42:27] epoch: 2594/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:42:27] epoch: 2594/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:42:27] epoch: 2594/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:42:32] epoch: 2595/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:42:32] epoch: 2595/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:42:32] epoch: 2595/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:42:37] epoch: 2596/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:42:37] epoch: 2596/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:42:37] epoch: 2596/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:42:42] epoch: 2597/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:42:42] epoch: 2597/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200404-22:42:42] epoch: 2597/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:42:48] epoch: 2598/5000, reconstruction loss: 0.0223\n",
      "[LOG TRAIN 20200404-22:42:48] epoch: 2598/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:42:48] epoch: 2598/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:42:53] epoch: 2599/5000, reconstruction loss: 0.0225\n",
      "[LOG TRAIN 20200404-22:42:53] epoch: 2599/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:42:53] epoch: 2599/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:42:58] epoch: 2600/5000, reconstruction loss: 0.0219\n",
      "[LOG TRAIN 20200404-22:42:58] epoch: 2600/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:42:58] epoch: 2600/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:43:03] epoch: 2601/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-22:43:03] epoch: 2601/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:43:03] epoch: 2601/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:43:09] epoch: 2602/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-22:43:09] epoch: 2602/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:43:09] epoch: 2602/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200404-22:43:14] epoch: 2603/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-22:43:14] epoch: 2603/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:43:14] epoch: 2603/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-22:43:19] epoch: 2604/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:43:19] epoch: 2604/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:43:19] epoch: 2604/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200404-22:43:25] epoch: 2605/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:43:25] epoch: 2605/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:43:25] epoch: 2605/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200404-22:43:30] epoch: 2606/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:43:30] epoch: 2606/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:43:30] epoch: 2606/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:43:35] epoch: 2607/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:43:35] epoch: 2607/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:43:35] epoch: 2607/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:43:40] epoch: 2608/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:43:40] epoch: 2608/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:43:40] epoch: 2608/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:43:46] epoch: 2609/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:43:46] epoch: 2609/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:43:46] epoch: 2609/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:43:51] epoch: 2610/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:43:51] epoch: 2610/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:43:51] epoch: 2610/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200404-22:43:56] epoch: 2611/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:43:56] epoch: 2611/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:43:56] epoch: 2611/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:44:02] epoch: 2612/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:02] epoch: 2612/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:44:02] epoch: 2612/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:44:07] epoch: 2613/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:07] epoch: 2613/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:44:07] epoch: 2613/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:44:12] epoch: 2614/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:12] epoch: 2614/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:44:12] epoch: 2614/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:44:17] epoch: 2615/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:17] epoch: 2615/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:44:17] epoch: 2615/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:44:23] epoch: 2616/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:23] epoch: 2616/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:44:23] epoch: 2616/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:44:28] epoch: 2617/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:28] epoch: 2617/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:44:28] epoch: 2617/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:44:33] epoch: 2618/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:33] epoch: 2618/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:44:33] epoch: 2618/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:44:39] epoch: 2619/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:39] epoch: 2619/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:44:39] epoch: 2619/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:44:44] epoch: 2620/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:44] epoch: 2620/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:44:44] epoch: 2620/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:44:49] epoch: 2621/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:49] epoch: 2621/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:44:49] epoch: 2621/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:44:54] epoch: 2622/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:44:54] epoch: 2622/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:44:54] epoch: 2622/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:45:00] epoch: 2623/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:45:00] epoch: 2623/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:00] epoch: 2623/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:45:06] epoch: 2624/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:45:06] epoch: 2624/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:06] epoch: 2624/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:45:11] epoch: 2625/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:45:11] epoch: 2625/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:11] epoch: 2625/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:45:16] epoch: 2626/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:45:16] epoch: 2626/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:16] epoch: 2626/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:45:21] epoch: 2627/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:45:21] epoch: 2627/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:21] epoch: 2627/5000, generator loss: 0.6941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:45:27] epoch: 2628/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:45:27] epoch: 2628/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:27] epoch: 2628/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:45:32] epoch: 2629/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:45:32] epoch: 2629/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:32] epoch: 2629/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:45:37] epoch: 2630/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:45:37] epoch: 2630/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:37] epoch: 2630/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:45:42] epoch: 2631/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:45:42] epoch: 2631/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:42] epoch: 2631/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:45:48] epoch: 2632/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:45:48] epoch: 2632/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:48] epoch: 2632/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:45:53] epoch: 2633/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:45:53] epoch: 2633/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:53] epoch: 2633/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:45:58] epoch: 2634/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:45:58] epoch: 2634/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:45:58] epoch: 2634/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:46:03] epoch: 2635/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:46:03] epoch: 2635/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200404-22:46:03] epoch: 2635/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:46:09] epoch: 2636/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-22:46:09] epoch: 2636/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:46:09] epoch: 2636/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:46:14] epoch: 2637/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-22:46:14] epoch: 2637/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:46:14] epoch: 2637/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:46:19] epoch: 2638/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-22:46:19] epoch: 2638/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:46:19] epoch: 2638/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:46:24] epoch: 2639/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:46:24] epoch: 2639/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:46:24] epoch: 2639/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200404-22:46:30] epoch: 2640/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:46:30] epoch: 2640/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:46:30] epoch: 2640/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:46:35] epoch: 2641/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:46:35] epoch: 2641/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:46:35] epoch: 2641/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:46:40] epoch: 2642/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:46:40] epoch: 2642/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:46:40] epoch: 2642/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:46:45] epoch: 2643/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:46:45] epoch: 2643/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:46:45] epoch: 2643/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:46:51] epoch: 2644/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:46:51] epoch: 2644/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:46:51] epoch: 2644/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:46:56] epoch: 2645/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:46:56] epoch: 2645/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:46:56] epoch: 2645/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:47:01] epoch: 2646/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:47:01] epoch: 2646/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:01] epoch: 2646/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:47:06] epoch: 2647/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:47:06] epoch: 2647/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:06] epoch: 2647/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:47:12] epoch: 2648/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:47:12] epoch: 2648/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:12] epoch: 2648/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:47:17] epoch: 2649/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:47:17] epoch: 2649/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:17] epoch: 2649/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:47:22] epoch: 2650/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:47:22] epoch: 2650/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:22] epoch: 2650/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:47:27] epoch: 2651/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:47:27] epoch: 2651/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:27] epoch: 2651/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:47:32] epoch: 2652/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:47:32] epoch: 2652/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:32] epoch: 2652/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:47:38] epoch: 2653/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:47:38] epoch: 2653/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:38] epoch: 2653/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:47:43] epoch: 2654/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:47:43] epoch: 2654/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:43] epoch: 2654/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:47:48] epoch: 2655/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:47:48] epoch: 2655/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:48] epoch: 2655/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:47:53] epoch: 2656/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:47:53] epoch: 2656/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:53] epoch: 2656/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:47:59] epoch: 2657/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:47:59] epoch: 2657/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:47:59] epoch: 2657/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:48:04] epoch: 2658/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:48:04] epoch: 2658/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:48:04] epoch: 2658/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:48:10] epoch: 2659/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:48:10] epoch: 2659/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:48:10] epoch: 2659/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:48:15] epoch: 2660/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:48:15] epoch: 2660/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:48:15] epoch: 2660/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:48:20] epoch: 2661/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:48:20] epoch: 2661/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:48:20] epoch: 2661/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:48:26] epoch: 2662/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:48:26] epoch: 2662/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:48:26] epoch: 2662/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:48:31] epoch: 2663/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:48:31] epoch: 2663/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:48:31] epoch: 2663/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:48:36] epoch: 2664/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:48:36] epoch: 2664/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:48:36] epoch: 2664/5000, generator loss: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:48:41] epoch: 2665/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:48:41] epoch: 2665/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:48:41] epoch: 2665/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:48:47] epoch: 2666/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:48:47] epoch: 2666/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:48:47] epoch: 2666/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:48:52] epoch: 2667/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-22:48:52] epoch: 2667/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200404-22:48:52] epoch: 2667/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:48:57] epoch: 2668/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-22:48:57] epoch: 2668/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:48:57] epoch: 2668/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:49:02] epoch: 2669/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-22:49:02] epoch: 2669/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:49:02] epoch: 2669/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:49:08] epoch: 2670/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:49:08] epoch: 2670/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:49:08] epoch: 2670/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:49:13] epoch: 2671/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:49:13] epoch: 2671/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:49:13] epoch: 2671/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:49:18] epoch: 2672/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:49:18] epoch: 2672/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:49:18] epoch: 2672/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:49:23] epoch: 2673/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:49:23] epoch: 2673/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:49:23] epoch: 2673/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:49:29] epoch: 2674/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:49:29] epoch: 2674/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:49:29] epoch: 2674/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:49:34] epoch: 2675/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:49:34] epoch: 2675/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:49:34] epoch: 2675/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:49:39] epoch: 2676/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:49:39] epoch: 2676/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:49:39] epoch: 2676/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:49:44] epoch: 2677/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:49:44] epoch: 2677/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:49:44] epoch: 2677/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:49:50] epoch: 2678/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:49:50] epoch: 2678/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:49:50] epoch: 2678/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:49:55] epoch: 2679/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:49:55] epoch: 2679/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:49:55] epoch: 2679/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:50:00] epoch: 2680/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:50:00] epoch: 2680/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:00] epoch: 2680/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:50:05] epoch: 2681/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:50:05] epoch: 2681/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:05] epoch: 2681/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:50:11] epoch: 2682/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:50:11] epoch: 2682/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:11] epoch: 2682/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:50:16] epoch: 2683/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:50:16] epoch: 2683/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:16] epoch: 2683/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:50:21] epoch: 2684/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:50:21] epoch: 2684/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:21] epoch: 2684/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:50:26] epoch: 2685/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:50:26] epoch: 2685/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:26] epoch: 2685/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:50:32] epoch: 2686/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:50:32] epoch: 2686/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:32] epoch: 2686/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:50:37] epoch: 2687/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:50:37] epoch: 2687/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:37] epoch: 2687/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:50:42] epoch: 2688/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:50:42] epoch: 2688/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:42] epoch: 2688/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:50:47] epoch: 2689/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:50:47] epoch: 2689/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:47] epoch: 2689/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:50:53] epoch: 2690/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:50:53] epoch: 2690/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:53] epoch: 2690/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:50:58] epoch: 2691/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:50:58] epoch: 2691/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:50:58] epoch: 2691/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:51:04] epoch: 2692/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:51:04] epoch: 2692/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:51:04] epoch: 2692/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:51:09] epoch: 2693/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:51:09] epoch: 2693/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:51:09] epoch: 2693/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:51:14] epoch: 2694/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:51:14] epoch: 2694/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:51:14] epoch: 2694/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:51:20] epoch: 2695/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:51:20] epoch: 2695/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:51:20] epoch: 2695/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:51:25] epoch: 2696/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:51:25] epoch: 2696/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:51:25] epoch: 2696/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:51:30] epoch: 2697/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:51:30] epoch: 2697/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:51:30] epoch: 2697/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:51:35] epoch: 2698/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-22:51:35] epoch: 2698/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:51:35] epoch: 2698/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:51:41] epoch: 2699/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-22:51:41] epoch: 2699/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:51:41] epoch: 2699/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:51:46] epoch: 2700/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-22:51:46] epoch: 2700/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:51:46] epoch: 2700/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:51:51] epoch: 2701/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:51:51] epoch: 2701/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:51:51] epoch: 2701/5000, generator loss: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:51:56] epoch: 2702/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:51:56] epoch: 2702/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:51:56] epoch: 2702/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:52:02] epoch: 2703/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:52:02] epoch: 2703/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:52:02] epoch: 2703/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:52:07] epoch: 2704/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:52:07] epoch: 2704/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200404-22:52:07] epoch: 2704/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:52:12] epoch: 2705/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-22:52:12] epoch: 2705/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:52:12] epoch: 2705/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:52:17] epoch: 2706/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-22:52:17] epoch: 2706/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:52:17] epoch: 2706/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:52:23] epoch: 2707/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-22:52:23] epoch: 2707/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:52:23] epoch: 2707/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:52:28] epoch: 2708/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-22:52:28] epoch: 2708/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:52:28] epoch: 2708/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:52:33] epoch: 2709/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:52:33] epoch: 2709/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:52:33] epoch: 2709/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:52:38] epoch: 2710/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:52:38] epoch: 2710/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:52:38] epoch: 2710/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:52:44] epoch: 2711/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:52:44] epoch: 2711/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:52:44] epoch: 2711/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:52:49] epoch: 2712/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:52:49] epoch: 2712/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:52:49] epoch: 2712/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:52:54] epoch: 2713/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:52:54] epoch: 2713/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:52:54] epoch: 2713/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:52:59] epoch: 2714/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:52:59] epoch: 2714/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:52:59] epoch: 2714/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:53:05] epoch: 2715/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:53:05] epoch: 2715/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:05] epoch: 2715/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:53:10] epoch: 2716/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:53:10] epoch: 2716/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:10] epoch: 2716/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:53:15] epoch: 2717/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:53:15] epoch: 2717/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:15] epoch: 2717/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-22:53:20] epoch: 2718/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:53:20] epoch: 2718/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:20] epoch: 2718/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-22:53:26] epoch: 2719/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:53:26] epoch: 2719/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:26] epoch: 2719/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:53:31] epoch: 2720/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:53:31] epoch: 2720/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:31] epoch: 2720/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:53:36] epoch: 2721/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:53:36] epoch: 2721/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:36] epoch: 2721/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-22:53:41] epoch: 2722/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:53:41] epoch: 2722/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:41] epoch: 2722/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:53:47] epoch: 2723/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:53:47] epoch: 2723/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:47] epoch: 2723/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:53:52] epoch: 2724/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:53:52] epoch: 2724/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:52] epoch: 2724/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:53:57] epoch: 2725/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:53:57] epoch: 2725/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:53:57] epoch: 2725/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:54:03] epoch: 2726/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:54:03] epoch: 2726/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:54:03] epoch: 2726/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:54:08] epoch: 2727/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:54:08] epoch: 2727/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200404-22:54:08] epoch: 2727/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:54:14] epoch: 2728/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:54:14] epoch: 2728/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:54:14] epoch: 2728/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:54:19] epoch: 2729/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:54:19] epoch: 2729/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:54:19] epoch: 2729/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:54:24] epoch: 2730/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:54:24] epoch: 2730/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:54:24] epoch: 2730/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:54:29] epoch: 2731/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-22:54:29] epoch: 2731/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:54:29] epoch: 2731/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:54:35] epoch: 2732/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:54:35] epoch: 2732/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:54:35] epoch: 2732/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:54:40] epoch: 2733/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:54:40] epoch: 2733/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:54:40] epoch: 2733/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:54:45] epoch: 2734/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:54:45] epoch: 2734/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:54:45] epoch: 2734/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:54:50] epoch: 2735/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:54:50] epoch: 2735/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:54:50] epoch: 2735/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:54:56] epoch: 2736/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:54:56] epoch: 2736/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:54:56] epoch: 2736/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:55:01] epoch: 2737/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:55:01] epoch: 2737/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:01] epoch: 2737/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:55:06] epoch: 2738/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:55:06] epoch: 2738/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:06] epoch: 2738/5000, generator loss: 0.6945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:55:12] epoch: 2739/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:55:12] epoch: 2739/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:12] epoch: 2739/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:55:17] epoch: 2740/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:55:17] epoch: 2740/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:17] epoch: 2740/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:55:22] epoch: 2741/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:55:22] epoch: 2741/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:22] epoch: 2741/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:55:27] epoch: 2742/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:55:27] epoch: 2742/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:27] epoch: 2742/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:55:33] epoch: 2743/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:55:33] epoch: 2743/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:33] epoch: 2743/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:55:38] epoch: 2744/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:55:38] epoch: 2744/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:38] epoch: 2744/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:55:43] epoch: 2745/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:55:43] epoch: 2745/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:43] epoch: 2745/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:55:48] epoch: 2746/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:55:48] epoch: 2746/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:48] epoch: 2746/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:55:54] epoch: 2747/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:55:54] epoch: 2747/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:54] epoch: 2747/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:55:59] epoch: 2748/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-22:55:59] epoch: 2748/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:55:59] epoch: 2748/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:56:04] epoch: 2749/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200404-22:56:04] epoch: 2749/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-22:56:04] epoch: 2749/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:56:09] epoch: 2750/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-22:56:09] epoch: 2750/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:56:09] epoch: 2750/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:56:15] epoch: 2751/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-22:56:15] epoch: 2751/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-22:56:15] epoch: 2751/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:56:20] epoch: 2752/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:56:20] epoch: 2752/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:56:20] epoch: 2752/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:56:25] epoch: 2753/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:56:25] epoch: 2753/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:56:25] epoch: 2753/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:56:30] epoch: 2754/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:56:30] epoch: 2754/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:56:30] epoch: 2754/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:56:36] epoch: 2755/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:56:36] epoch: 2755/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:56:36] epoch: 2755/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:56:41] epoch: 2756/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:56:41] epoch: 2756/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:56:41] epoch: 2756/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:56:46] epoch: 2757/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:56:46] epoch: 2757/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:56:46] epoch: 2757/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:56:52] epoch: 2758/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:56:52] epoch: 2758/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:56:52] epoch: 2758/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-22:56:57] epoch: 2759/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:56:57] epoch: 2759/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:56:57] epoch: 2759/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-22:57:03] epoch: 2760/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:57:03] epoch: 2760/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:57:03] epoch: 2760/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:57:08] epoch: 2761/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:57:08] epoch: 2761/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:57:08] epoch: 2761/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-22:57:13] epoch: 2762/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-22:57:13] epoch: 2762/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:57:13] epoch: 2762/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:57:19] epoch: 2763/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:57:19] epoch: 2763/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:57:19] epoch: 2763/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:57:24] epoch: 2764/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:57:24] epoch: 2764/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:57:24] epoch: 2764/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:57:29] epoch: 2765/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:57:29] epoch: 2765/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:57:29] epoch: 2765/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-22:57:34] epoch: 2766/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:57:34] epoch: 2766/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:57:34] epoch: 2766/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:57:40] epoch: 2767/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:57:40] epoch: 2767/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:57:40] epoch: 2767/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:57:45] epoch: 2768/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:57:45] epoch: 2768/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:57:45] epoch: 2768/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:57:50] epoch: 2769/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:57:50] epoch: 2769/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:57:50] epoch: 2769/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:57:55] epoch: 2770/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:57:55] epoch: 2770/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:57:55] epoch: 2770/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:58:00] epoch: 2771/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:58:00] epoch: 2771/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200404-22:58:00] epoch: 2771/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:58:06] epoch: 2772/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-22:58:06] epoch: 2772/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:06] epoch: 2772/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:58:11] epoch: 2773/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:58:11] epoch: 2773/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:11] epoch: 2773/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:58:16] epoch: 2774/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-22:58:16] epoch: 2774/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:16] epoch: 2774/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:58:22] epoch: 2775/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:58:22] epoch: 2775/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:22] epoch: 2775/5000, generator loss: 0.6941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-22:58:27] epoch: 2776/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:58:27] epoch: 2776/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:27] epoch: 2776/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-22:58:32] epoch: 2777/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:58:32] epoch: 2777/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:32] epoch: 2777/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:58:38] epoch: 2778/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:58:38] epoch: 2778/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:38] epoch: 2778/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:58:43] epoch: 2779/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-22:58:43] epoch: 2779/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:43] epoch: 2779/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:58:48] epoch: 2780/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:58:48] epoch: 2780/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:48] epoch: 2780/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-22:58:53] epoch: 2781/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-22:58:53] epoch: 2781/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:53] epoch: 2781/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:58:59] epoch: 2782/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:58:59] epoch: 2782/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:58:59] epoch: 2782/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:59:04] epoch: 2783/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:59:04] epoch: 2783/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:59:04] epoch: 2783/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:59:09] epoch: 2784/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:59:09] epoch: 2784/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:59:09] epoch: 2784/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-22:59:14] epoch: 2785/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-22:59:14] epoch: 2785/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:59:14] epoch: 2785/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:59:20] epoch: 2786/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-22:59:20] epoch: 2786/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-22:59:20] epoch: 2786/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-22:59:25] epoch: 2787/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200404-22:59:25] epoch: 2787/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-22:59:25] epoch: 2787/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-22:59:30] epoch: 2788/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200404-22:59:30] epoch: 2788/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-22:59:30] epoch: 2788/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:59:35] epoch: 2789/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200404-22:59:35] epoch: 2789/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-22:59:35] epoch: 2789/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-22:59:41] epoch: 2790/5000, reconstruction loss: 0.0269\n",
      "[LOG TRAIN 20200404-22:59:41] epoch: 2790/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-22:59:41] epoch: 2790/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-22:59:46] epoch: 2791/5000, reconstruction loss: 0.0294\n",
      "[LOG TRAIN 20200404-22:59:46] epoch: 2791/5000, discriminator loss: 1.3813\n",
      "[LOG TRAIN 20200404-22:59:46] epoch: 2791/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200404-22:59:51] epoch: 2792/5000, reconstruction loss: 0.0234\n",
      "[LOG TRAIN 20200404-22:59:51] epoch: 2792/5000, discriminator loss: 1.3816\n",
      "[LOG TRAIN 20200404-22:59:51] epoch: 2792/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-22:59:57] epoch: 2793/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200404-22:59:57] epoch: 2793/5000, discriminator loss: 1.3820\n",
      "[LOG TRAIN 20200404-22:59:57] epoch: 2793/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-23:00:02] epoch: 2794/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200404-23:00:02] epoch: 2794/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:00:02] epoch: 2794/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200404-23:00:08] epoch: 2795/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-23:00:08] epoch: 2795/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:00:08] epoch: 2795/5000, generator loss: 0.6924\n",
      "[LOG TRAIN 20200404-23:00:13] epoch: 2796/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-23:00:13] epoch: 2796/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:00:13] epoch: 2796/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200404-23:00:18] epoch: 2797/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:00:18] epoch: 2797/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:00:18] epoch: 2797/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:00:23] epoch: 2798/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:00:23] epoch: 2798/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:00:23] epoch: 2798/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200404-23:00:29] epoch: 2799/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:00:29] epoch: 2799/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:00:29] epoch: 2799/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:00:34] epoch: 2800/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:00:34] epoch: 2800/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:00:34] epoch: 2800/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:00:39] epoch: 2801/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:00:39] epoch: 2801/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:00:39] epoch: 2801/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:00:44] epoch: 2802/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:00:44] epoch: 2802/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:00:44] epoch: 2802/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:00:50] epoch: 2803/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:00:50] epoch: 2803/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:00:50] epoch: 2803/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200404-23:00:55] epoch: 2804/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:00:55] epoch: 2804/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:00:55] epoch: 2804/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200404-23:01:00] epoch: 2805/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-23:01:00] epoch: 2805/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:00] epoch: 2805/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:01:05] epoch: 2806/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:01:05] epoch: 2806/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:05] epoch: 2806/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:01:11] epoch: 2807/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-23:01:11] epoch: 2807/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:11] epoch: 2807/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:01:16] epoch: 2808/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:01:16] epoch: 2808/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:16] epoch: 2808/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:01:21] epoch: 2809/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:01:21] epoch: 2809/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:21] epoch: 2809/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:01:27] epoch: 2810/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-23:01:27] epoch: 2810/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:27] epoch: 2810/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:01:32] epoch: 2811/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-23:01:32] epoch: 2811/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:32] epoch: 2811/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:01:37] epoch: 2812/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:01:37] epoch: 2812/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:37] epoch: 2812/5000, generator loss: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:01:42] epoch: 2813/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:01:42] epoch: 2813/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:42] epoch: 2813/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:01:47] epoch: 2814/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-23:01:47] epoch: 2814/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:47] epoch: 2814/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:01:53] epoch: 2815/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-23:01:53] epoch: 2815/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:53] epoch: 2815/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:01:58] epoch: 2816/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:01:58] epoch: 2816/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:01:58] epoch: 2816/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:02:03] epoch: 2817/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:02:03] epoch: 2817/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:02:03] epoch: 2817/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:02:09] epoch: 2818/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-23:02:09] epoch: 2818/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:02:09] epoch: 2818/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:02:14] epoch: 2819/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:02:14] epoch: 2819/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:02:14] epoch: 2819/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:02:19] epoch: 2820/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:02:19] epoch: 2820/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:02:19] epoch: 2820/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:02:25] epoch: 2821/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:02:25] epoch: 2821/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:02:25] epoch: 2821/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:02:30] epoch: 2822/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:02:30] epoch: 2822/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-23:02:30] epoch: 2822/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:02:35] epoch: 2823/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:02:35] epoch: 2823/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:02:35] epoch: 2823/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:02:41] epoch: 2824/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:02:41] epoch: 2824/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:02:41] epoch: 2824/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:02:46] epoch: 2825/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:02:46] epoch: 2825/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:02:46] epoch: 2825/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:02:51] epoch: 2826/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:02:51] epoch: 2826/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-23:02:51] epoch: 2826/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:02:56] epoch: 2827/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:02:56] epoch: 2827/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:02:56] epoch: 2827/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:03:02] epoch: 2828/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:03:02] epoch: 2828/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:03:02] epoch: 2828/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:03:08] epoch: 2829/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:03:08] epoch: 2829/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:03:08] epoch: 2829/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:03:13] epoch: 2830/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:03:13] epoch: 2830/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:03:13] epoch: 2830/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:03:18] epoch: 2831/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-23:03:18] epoch: 2831/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-23:03:18] epoch: 2831/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:03:23] epoch: 2832/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:03:23] epoch: 2832/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-23:03:23] epoch: 2832/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:03:29] epoch: 2833/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:03:29] epoch: 2833/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:03:29] epoch: 2833/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:03:34] epoch: 2834/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:03:34] epoch: 2834/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:03:34] epoch: 2834/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:03:39] epoch: 2835/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:03:39] epoch: 2835/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:03:39] epoch: 2835/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:03:44] epoch: 2836/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:03:44] epoch: 2836/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:03:44] epoch: 2836/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:03:50] epoch: 2837/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:03:50] epoch: 2837/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:03:50] epoch: 2837/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:03:55] epoch: 2838/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:03:55] epoch: 2838/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:03:55] epoch: 2838/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:04:00] epoch: 2839/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:04:00] epoch: 2839/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:00] epoch: 2839/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:04:06] epoch: 2840/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:04:06] epoch: 2840/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:06] epoch: 2840/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:04:11] epoch: 2841/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:04:11] epoch: 2841/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:11] epoch: 2841/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:04:16] epoch: 2842/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:04:16] epoch: 2842/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:16] epoch: 2842/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:04:22] epoch: 2843/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:04:22] epoch: 2843/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:22] epoch: 2843/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:04:27] epoch: 2844/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:04:27] epoch: 2844/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:27] epoch: 2844/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:04:32] epoch: 2845/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:04:32] epoch: 2845/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:32] epoch: 2845/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:04:38] epoch: 2846/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:04:38] epoch: 2846/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:38] epoch: 2846/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:04:43] epoch: 2847/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:04:43] epoch: 2847/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:43] epoch: 2847/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:04:48] epoch: 2848/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:04:48] epoch: 2848/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:48] epoch: 2848/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:04:54] epoch: 2849/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:04:54] epoch: 2849/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:54] epoch: 2849/5000, generator loss: 0.6948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:04:59] epoch: 2850/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:04:59] epoch: 2850/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:04:59] epoch: 2850/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:05:04] epoch: 2851/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:05:04] epoch: 2851/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200404-23:05:04] epoch: 2851/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:05:09] epoch: 2852/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:05:09] epoch: 2852/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:05:09] epoch: 2852/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:05:15] epoch: 2853/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:05:15] epoch: 2853/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:05:15] epoch: 2853/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:05:20] epoch: 2854/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-23:05:20] epoch: 2854/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:05:20] epoch: 2854/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:05:25] epoch: 2855/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-23:05:25] epoch: 2855/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:05:25] epoch: 2855/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:05:30] epoch: 2856/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200404-23:05:30] epoch: 2856/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:05:30] epoch: 2856/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:05:36] epoch: 2857/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-23:05:36] epoch: 2857/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:05:36] epoch: 2857/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:05:41] epoch: 2858/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:05:41] epoch: 2858/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:05:41] epoch: 2858/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:05:46] epoch: 2859/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:05:46] epoch: 2859/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:05:46] epoch: 2859/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:05:52] epoch: 2860/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:05:52] epoch: 2860/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:05:52] epoch: 2860/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:05:57] epoch: 2861/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:05:57] epoch: 2861/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:05:57] epoch: 2861/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:06:02] epoch: 2862/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:06:02] epoch: 2862/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:06:02] epoch: 2862/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:06:08] epoch: 2863/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:06:08] epoch: 2863/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:06:08] epoch: 2863/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:06:13] epoch: 2864/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-23:06:13] epoch: 2864/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:06:13] epoch: 2864/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:06:18] epoch: 2865/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:06:18] epoch: 2865/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:06:18] epoch: 2865/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:06:24] epoch: 2866/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:06:24] epoch: 2866/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:06:24] epoch: 2866/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:06:29] epoch: 2867/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:06:29] epoch: 2867/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:06:29] epoch: 2867/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:06:35] epoch: 2868/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:06:35] epoch: 2868/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:06:35] epoch: 2868/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:06:40] epoch: 2869/5000, reconstruction loss: 0.0155\n",
      "[LOG TRAIN 20200404-23:06:40] epoch: 2869/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:06:40] epoch: 2869/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:06:45] epoch: 2870/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:06:45] epoch: 2870/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:06:45] epoch: 2870/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:06:51] epoch: 2871/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:06:51] epoch: 2871/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:06:51] epoch: 2871/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:06:56] epoch: 2872/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:06:56] epoch: 2872/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:06:56] epoch: 2872/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:07:01] epoch: 2873/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:07:01] epoch: 2873/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:01] epoch: 2873/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:07:06] epoch: 2874/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:07:06] epoch: 2874/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:06] epoch: 2874/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:07:12] epoch: 2875/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:07:12] epoch: 2875/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:12] epoch: 2875/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:07:17] epoch: 2876/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:07:17] epoch: 2876/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:17] epoch: 2876/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:07:22] epoch: 2877/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:07:22] epoch: 2877/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:22] epoch: 2877/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:07:28] epoch: 2878/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:07:28] epoch: 2878/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:28] epoch: 2878/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:07:33] epoch: 2879/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:07:33] epoch: 2879/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:33] epoch: 2879/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:07:38] epoch: 2880/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:07:38] epoch: 2880/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:38] epoch: 2880/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:07:44] epoch: 2881/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:07:44] epoch: 2881/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:44] epoch: 2881/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:07:49] epoch: 2882/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:07:49] epoch: 2882/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:49] epoch: 2882/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:07:54] epoch: 2883/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:07:54] epoch: 2883/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:54] epoch: 2883/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:07:59] epoch: 2884/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:07:59] epoch: 2884/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:07:59] epoch: 2884/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:08:05] epoch: 2885/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:08:05] epoch: 2885/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:08:05] epoch: 2885/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:08:10] epoch: 2886/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:08:10] epoch: 2886/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:08:10] epoch: 2886/5000, generator loss: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:08:15] epoch: 2887/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:08:15] epoch: 2887/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:08:15] epoch: 2887/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:08:20] epoch: 2888/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:08:20] epoch: 2888/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:08:20] epoch: 2888/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:08:26] epoch: 2889/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-23:08:26] epoch: 2889/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:08:26] epoch: 2889/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:08:31] epoch: 2890/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-23:08:31] epoch: 2890/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:08:31] epoch: 2890/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:08:36] epoch: 2891/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-23:08:36] epoch: 2891/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:08:36] epoch: 2891/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:08:42] epoch: 2892/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-23:08:42] epoch: 2892/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:08:42] epoch: 2892/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:08:47] epoch: 2893/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-23:08:47] epoch: 2893/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:08:47] epoch: 2893/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:08:52] epoch: 2894/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-23:08:52] epoch: 2894/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:08:52] epoch: 2894/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:08:58] epoch: 2895/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-23:08:58] epoch: 2895/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:08:58] epoch: 2895/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:09:03] epoch: 2896/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200404-23:09:03] epoch: 2896/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:09:03] epoch: 2896/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:09:09] epoch: 2897/5000, reconstruction loss: 0.0225\n",
      "[LOG TRAIN 20200404-23:09:09] epoch: 2897/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:09:09] epoch: 2897/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:09:14] epoch: 2898/5000, reconstruction loss: 0.0217\n",
      "[LOG TRAIN 20200404-23:09:14] epoch: 2898/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:09:14] epoch: 2898/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:09:19] epoch: 2899/5000, reconstruction loss: 0.0220\n",
      "[LOG TRAIN 20200404-23:09:19] epoch: 2899/5000, discriminator loss: 1.3820\n",
      "[LOG TRAIN 20200404-23:09:19] epoch: 2899/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:09:25] epoch: 2900/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200404-23:09:25] epoch: 2900/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:09:25] epoch: 2900/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:09:30] epoch: 2901/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-23:09:30] epoch: 2901/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:09:30] epoch: 2901/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:09:35] epoch: 2902/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-23:09:35] epoch: 2902/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:09:35] epoch: 2902/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:09:40] epoch: 2903/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:09:40] epoch: 2903/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:09:40] epoch: 2903/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:09:46] epoch: 2904/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:09:46] epoch: 2904/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:09:46] epoch: 2904/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:09:51] epoch: 2905/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:09:51] epoch: 2905/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:09:51] epoch: 2905/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:09:56] epoch: 2906/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:09:56] epoch: 2906/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:09:56] epoch: 2906/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200404-23:10:02] epoch: 2907/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:02] epoch: 2907/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:10:02] epoch: 2907/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200404-23:10:07] epoch: 2908/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:07] epoch: 2908/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:10:07] epoch: 2908/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:10:12] epoch: 2909/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:12] epoch: 2909/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:10:12] epoch: 2909/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:10:18] epoch: 2910/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:18] epoch: 2910/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:10:18] epoch: 2910/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:10:23] epoch: 2911/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:23] epoch: 2911/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:10:23] epoch: 2911/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:10:28] epoch: 2912/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:28] epoch: 2912/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:10:28] epoch: 2912/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:10:33] epoch: 2913/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:33] epoch: 2913/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:10:33] epoch: 2913/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:10:39] epoch: 2914/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:39] epoch: 2914/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:10:39] epoch: 2914/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:10:44] epoch: 2915/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:44] epoch: 2915/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:10:44] epoch: 2915/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:10:49] epoch: 2916/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:49] epoch: 2916/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:10:49] epoch: 2916/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:10:55] epoch: 2917/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:10:55] epoch: 2917/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:10:55] epoch: 2917/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:11:00] epoch: 2918/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:11:00] epoch: 2918/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:11:00] epoch: 2918/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:11:05] epoch: 2919/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:11:05] epoch: 2919/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:11:05] epoch: 2919/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:11:10] epoch: 2920/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:11:10] epoch: 2920/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:11:10] epoch: 2920/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:11:16] epoch: 2921/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:11:16] epoch: 2921/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:11:16] epoch: 2921/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:11:21] epoch: 2922/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:11:21] epoch: 2922/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:11:21] epoch: 2922/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:11:26] epoch: 2923/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:11:26] epoch: 2923/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:11:26] epoch: 2923/5000, generator loss: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:11:32] epoch: 2924/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:11:32] epoch: 2924/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:11:32] epoch: 2924/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:11:37] epoch: 2925/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:11:37] epoch: 2925/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:11:37] epoch: 2925/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:11:42] epoch: 2926/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:11:42] epoch: 2926/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:11:42] epoch: 2926/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:11:48] epoch: 2927/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:11:48] epoch: 2927/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:11:48] epoch: 2927/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:11:53] epoch: 2928/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:11:53] epoch: 2928/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:11:53] epoch: 2928/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:11:58] epoch: 2929/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:11:58] epoch: 2929/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:11:58] epoch: 2929/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:12:04] epoch: 2930/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:12:04] epoch: 2930/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:12:04] epoch: 2930/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:12:09] epoch: 2931/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:12:09] epoch: 2931/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:12:09] epoch: 2931/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:12:14] epoch: 2932/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:12:14] epoch: 2932/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:12:14] epoch: 2932/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:12:20] epoch: 2933/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:12:20] epoch: 2933/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:12:20] epoch: 2933/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:12:25] epoch: 2934/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:12:25] epoch: 2934/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:12:25] epoch: 2934/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:12:30] epoch: 2935/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:12:30] epoch: 2935/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:12:30] epoch: 2935/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:12:36] epoch: 2936/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:12:36] epoch: 2936/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:12:36] epoch: 2936/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:12:41] epoch: 2937/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:12:41] epoch: 2937/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:12:41] epoch: 2937/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:12:46] epoch: 2938/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:12:46] epoch: 2938/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:12:46] epoch: 2938/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:12:52] epoch: 2939/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:12:52] epoch: 2939/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:12:52] epoch: 2939/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:12:57] epoch: 2940/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:12:57] epoch: 2940/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:12:57] epoch: 2940/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:13:02] epoch: 2941/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:13:02] epoch: 2941/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:13:02] epoch: 2941/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:13:08] epoch: 2942/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:13:08] epoch: 2942/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:13:08] epoch: 2942/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:13:13] epoch: 2943/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:13:13] epoch: 2943/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:13:13] epoch: 2943/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:13:18] epoch: 2944/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:13:18] epoch: 2944/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:13:18] epoch: 2944/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:13:24] epoch: 2945/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:13:24] epoch: 2945/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:13:24] epoch: 2945/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:13:29] epoch: 2946/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:13:29] epoch: 2946/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:13:29] epoch: 2946/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:13:34] epoch: 2947/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:13:34] epoch: 2947/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:13:34] epoch: 2947/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:13:39] epoch: 2948/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:13:39] epoch: 2948/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:13:39] epoch: 2948/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:13:45] epoch: 2949/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:13:45] epoch: 2949/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:13:45] epoch: 2949/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:13:50] epoch: 2950/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:13:50] epoch: 2950/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:13:50] epoch: 2950/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:13:55] epoch: 2951/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:13:55] epoch: 2951/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:13:55] epoch: 2951/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:14:01] epoch: 2952/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:14:01] epoch: 2952/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:14:01] epoch: 2952/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:14:06] epoch: 2953/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:14:06] epoch: 2953/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:14:06] epoch: 2953/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:14:11] epoch: 2954/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:14:11] epoch: 2954/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:14:11] epoch: 2954/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:14:17] epoch: 2955/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:14:17] epoch: 2955/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200404-23:14:17] epoch: 2955/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:14:22] epoch: 2956/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:14:22] epoch: 2956/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:14:22] epoch: 2956/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:14:27] epoch: 2957/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:14:27] epoch: 2957/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:14:27] epoch: 2957/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:14:32] epoch: 2958/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:14:32] epoch: 2958/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:14:32] epoch: 2958/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:14:38] epoch: 2959/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:14:38] epoch: 2959/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:14:38] epoch: 2959/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:14:43] epoch: 2960/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:14:43] epoch: 2960/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:14:43] epoch: 2960/5000, generator loss: 0.6950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:14:48] epoch: 2961/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:14:48] epoch: 2961/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:14:48] epoch: 2961/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:14:54] epoch: 2962/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-23:14:54] epoch: 2962/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:14:54] epoch: 2962/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:15:00] epoch: 2963/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:15:00] epoch: 2963/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:00] epoch: 2963/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:15:05] epoch: 2964/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:15:05] epoch: 2964/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:05] epoch: 2964/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:15:10] epoch: 2965/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:15:10] epoch: 2965/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:10] epoch: 2965/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:15:15] epoch: 2966/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:15:15] epoch: 2966/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:15] epoch: 2966/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:15:21] epoch: 2967/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:15:21] epoch: 2967/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:21] epoch: 2967/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:15:26] epoch: 2968/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:15:26] epoch: 2968/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:26] epoch: 2968/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:15:31] epoch: 2969/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:15:31] epoch: 2969/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:31] epoch: 2969/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:15:37] epoch: 2970/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:15:37] epoch: 2970/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:37] epoch: 2970/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:15:42] epoch: 2971/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:15:42] epoch: 2971/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:42] epoch: 2971/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:15:47] epoch: 2972/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:15:47] epoch: 2972/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:47] epoch: 2972/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:15:53] epoch: 2973/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:15:53] epoch: 2973/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:53] epoch: 2973/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:15:58] epoch: 2974/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:15:58] epoch: 2974/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:15:58] epoch: 2974/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:16:03] epoch: 2975/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:16:03] epoch: 2975/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:16:03] epoch: 2975/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:16:09] epoch: 2976/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-23:16:09] epoch: 2976/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:16:09] epoch: 2976/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:16:14] epoch: 2977/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-23:16:14] epoch: 2977/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:16:14] epoch: 2977/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:16:19] epoch: 2978/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200404-23:16:19] epoch: 2978/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:16:19] epoch: 2978/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:16:24] epoch: 2979/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:16:24] epoch: 2979/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:16:24] epoch: 2979/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:16:30] epoch: 2980/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:16:30] epoch: 2980/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:16:30] epoch: 2980/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:16:35] epoch: 2981/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:16:35] epoch: 2981/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:16:35] epoch: 2981/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:16:40] epoch: 2982/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:16:40] epoch: 2982/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:16:40] epoch: 2982/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:16:46] epoch: 2983/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:16:46] epoch: 2983/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:16:46] epoch: 2983/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:16:51] epoch: 2984/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:16:51] epoch: 2984/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:16:51] epoch: 2984/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:16:56] epoch: 2985/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-23:16:56] epoch: 2985/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:16:56] epoch: 2985/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:17:02] epoch: 2986/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:17:02] epoch: 2986/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:02] epoch: 2986/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:17:07] epoch: 2987/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:17:07] epoch: 2987/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:07] epoch: 2987/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:17:12] epoch: 2988/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:17:12] epoch: 2988/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:12] epoch: 2988/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:17:17] epoch: 2989/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:17:17] epoch: 2989/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:17] epoch: 2989/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:17:23] epoch: 2990/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:17:23] epoch: 2990/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:23] epoch: 2990/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:17:28] epoch: 2991/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:17:28] epoch: 2991/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:28] epoch: 2991/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:17:33] epoch: 2992/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:17:33] epoch: 2992/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:33] epoch: 2992/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:17:38] epoch: 2993/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:17:38] epoch: 2993/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:38] epoch: 2993/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:17:44] epoch: 2994/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:17:44] epoch: 2994/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:44] epoch: 2994/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:17:49] epoch: 2995/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:17:49] epoch: 2995/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:49] epoch: 2995/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:17:54] epoch: 2996/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:17:54] epoch: 2996/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:17:54] epoch: 2996/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:18:00] epoch: 2997/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:18:00] epoch: 2997/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:00] epoch: 2997/5000, generator loss: 0.6947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:18:05] epoch: 2998/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:18:05] epoch: 2998/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:05] epoch: 2998/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:18:10] epoch: 2999/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:18:10] epoch: 2999/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:10] epoch: 2999/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:18:16] epoch: 3000/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:18:16] epoch: 3000/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:16] epoch: 3000/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:18:21] epoch: 3001/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:18:21] epoch: 3001/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:21] epoch: 3001/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:18:26] epoch: 3002/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:18:26] epoch: 3002/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:26] epoch: 3002/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:18:32] epoch: 3003/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:18:32] epoch: 3003/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:32] epoch: 3003/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:18:37] epoch: 3004/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:18:37] epoch: 3004/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:37] epoch: 3004/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:18:42] epoch: 3005/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:18:42] epoch: 3005/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:42] epoch: 3005/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:18:48] epoch: 3006/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:18:48] epoch: 3006/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:48] epoch: 3006/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:18:53] epoch: 3007/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:18:53] epoch: 3007/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:53] epoch: 3007/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:18:58] epoch: 3008/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:18:58] epoch: 3008/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:18:58] epoch: 3008/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:19:03] epoch: 3009/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-23:19:03] epoch: 3009/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:19:03] epoch: 3009/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:19:09] epoch: 3010/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:19:09] epoch: 3010/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:19:09] epoch: 3010/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:19:14] epoch: 3011/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:19:14] epoch: 3011/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:19:14] epoch: 3011/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:19:19] epoch: 3012/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:19:19] epoch: 3012/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:19:19] epoch: 3012/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:19:24] epoch: 3013/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:19:24] epoch: 3013/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:19:24] epoch: 3013/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:19:30] epoch: 3014/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:19:30] epoch: 3014/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:19:30] epoch: 3014/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:19:35] epoch: 3015/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:19:35] epoch: 3015/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:19:35] epoch: 3015/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:19:40] epoch: 3016/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:19:40] epoch: 3016/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:19:40] epoch: 3016/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:19:46] epoch: 3017/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:19:46] epoch: 3017/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:19:46] epoch: 3017/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:19:51] epoch: 3018/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:19:51] epoch: 3018/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:19:51] epoch: 3018/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:19:56] epoch: 3019/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:19:56] epoch: 3019/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:19:56] epoch: 3019/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:20:02] epoch: 3020/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:20:02] epoch: 3020/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:20:02] epoch: 3020/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:20:07] epoch: 3021/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:20:07] epoch: 3021/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:20:07] epoch: 3021/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:20:12] epoch: 3022/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:20:12] epoch: 3022/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:20:12] epoch: 3022/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:20:18] epoch: 3023/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:20:18] epoch: 3023/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:20:18] epoch: 3023/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:20:23] epoch: 3024/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:20:23] epoch: 3024/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:20:23] epoch: 3024/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:20:28] epoch: 3025/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:20:28] epoch: 3025/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:20:28] epoch: 3025/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:20:34] epoch: 3026/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:20:34] epoch: 3026/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:20:34] epoch: 3026/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:20:39] epoch: 3027/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:20:39] epoch: 3027/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:20:39] epoch: 3027/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:20:44] epoch: 3028/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-23:20:44] epoch: 3028/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:20:44] epoch: 3028/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:20:49] epoch: 3029/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200404-23:20:49] epoch: 3029/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:20:49] epoch: 3029/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:20:55] epoch: 3030/5000, reconstruction loss: 0.0278\n",
      "[LOG TRAIN 20200404-23:20:55] epoch: 3030/5000, discriminator loss: 1.3819\n",
      "[LOG TRAIN 20200404-23:20:55] epoch: 3030/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:21:00] epoch: 3031/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200404-23:21:00] epoch: 3031/5000, discriminator loss: 1.3821\n",
      "[LOG TRAIN 20200404-23:21:00] epoch: 3031/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:21:06] epoch: 3032/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-23:21:06] epoch: 3032/5000, discriminator loss: 1.3821\n",
      "[LOG TRAIN 20200404-23:21:06] epoch: 3032/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:21:11] epoch: 3033/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-23:21:11] epoch: 3033/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:21:11] epoch: 3033/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:21:16] epoch: 3034/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:21:16] epoch: 3034/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:21:16] epoch: 3034/5000, generator loss: 0.6941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:21:22] epoch: 3035/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:21:22] epoch: 3035/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:21:22] epoch: 3035/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:21:27] epoch: 3036/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:21:27] epoch: 3036/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:21:27] epoch: 3036/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:21:32] epoch: 3037/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:21:32] epoch: 3037/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:21:32] epoch: 3037/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:21:38] epoch: 3038/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:21:38] epoch: 3038/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:21:38] epoch: 3038/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:21:43] epoch: 3039/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:21:43] epoch: 3039/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:21:43] epoch: 3039/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:21:48] epoch: 3040/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:21:48] epoch: 3040/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:21:48] epoch: 3040/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:21:54] epoch: 3041/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:21:54] epoch: 3041/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:21:54] epoch: 3041/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:21:59] epoch: 3042/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:21:59] epoch: 3042/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:21:59] epoch: 3042/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:22:04] epoch: 3043/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:22:04] epoch: 3043/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:22:04] epoch: 3043/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:22:10] epoch: 3044/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:22:10] epoch: 3044/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:22:10] epoch: 3044/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:22:15] epoch: 3045/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:22:15] epoch: 3045/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:22:15] epoch: 3045/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:22:20] epoch: 3046/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:22:20] epoch: 3046/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:22:20] epoch: 3046/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:22:25] epoch: 3047/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:22:25] epoch: 3047/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:22:25] epoch: 3047/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:22:31] epoch: 3048/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:22:31] epoch: 3048/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:22:31] epoch: 3048/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:22:36] epoch: 3049/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:22:36] epoch: 3049/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:22:36] epoch: 3049/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:22:41] epoch: 3050/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:22:41] epoch: 3050/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:22:41] epoch: 3050/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:22:47] epoch: 3051/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:22:47] epoch: 3051/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:22:47] epoch: 3051/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:22:52] epoch: 3052/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:22:52] epoch: 3052/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:22:52] epoch: 3052/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:22:57] epoch: 3053/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:22:57] epoch: 3053/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:22:57] epoch: 3053/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:23:03] epoch: 3054/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:23:03] epoch: 3054/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:03] epoch: 3054/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:23:08] epoch: 3055/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:23:08] epoch: 3055/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:08] epoch: 3055/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:23:13] epoch: 3056/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:23:13] epoch: 3056/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:13] epoch: 3056/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:23:19] epoch: 3057/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:23:19] epoch: 3057/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:19] epoch: 3057/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:23:24] epoch: 3058/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:23:24] epoch: 3058/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:24] epoch: 3058/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:23:29] epoch: 3059/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:23:29] epoch: 3059/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:29] epoch: 3059/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:23:35] epoch: 3060/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:23:35] epoch: 3060/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:35] epoch: 3060/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:23:40] epoch: 3061/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:23:40] epoch: 3061/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:40] epoch: 3061/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:23:45] epoch: 3062/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:23:45] epoch: 3062/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:45] epoch: 3062/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:23:50] epoch: 3063/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:23:50] epoch: 3063/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:50] epoch: 3063/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:23:56] epoch: 3064/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:23:56] epoch: 3064/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:23:56] epoch: 3064/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:24:01] epoch: 3065/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:24:01] epoch: 3065/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:24:01] epoch: 3065/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:24:07] epoch: 3066/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-23:24:07] epoch: 3066/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:24:07] epoch: 3066/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:24:12] epoch: 3067/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:24:12] epoch: 3067/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:24:12] epoch: 3067/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:24:17] epoch: 3068/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:24:17] epoch: 3068/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:24:17] epoch: 3068/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:24:23] epoch: 3069/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:24:23] epoch: 3069/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:24:23] epoch: 3069/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:24:28] epoch: 3070/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:24:28] epoch: 3070/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:24:28] epoch: 3070/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:24:33] epoch: 3071/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:24:33] epoch: 3071/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:24:33] epoch: 3071/5000, generator loss: 0.6948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:24:39] epoch: 3072/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:24:39] epoch: 3072/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:24:39] epoch: 3072/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:24:44] epoch: 3073/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:24:44] epoch: 3073/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:24:44] epoch: 3073/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:24:49] epoch: 3074/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:24:49] epoch: 3074/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:24:49] epoch: 3074/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:24:55] epoch: 3075/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:24:55] epoch: 3075/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:24:55] epoch: 3075/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:25:00] epoch: 3076/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:25:00] epoch: 3076/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:25:00] epoch: 3076/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:25:05] epoch: 3077/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:25:05] epoch: 3077/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:25:05] epoch: 3077/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:25:11] epoch: 3078/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-23:25:11] epoch: 3078/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:25:11] epoch: 3078/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:25:16] epoch: 3079/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-23:25:16] epoch: 3079/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:25:16] epoch: 3079/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:25:21] epoch: 3080/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-23:25:21] epoch: 3080/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:25:21] epoch: 3080/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:25:27] epoch: 3081/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:25:27] epoch: 3081/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:25:27] epoch: 3081/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:25:32] epoch: 3082/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:25:32] epoch: 3082/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:25:32] epoch: 3082/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:25:37] epoch: 3083/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:25:37] epoch: 3083/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:25:37] epoch: 3083/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:25:42] epoch: 3084/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:25:42] epoch: 3084/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:25:42] epoch: 3084/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:25:48] epoch: 3085/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:25:48] epoch: 3085/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:25:48] epoch: 3085/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:25:53] epoch: 3086/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:25:53] epoch: 3086/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:25:53] epoch: 3086/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:25:58] epoch: 3087/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:25:58] epoch: 3087/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:25:58] epoch: 3087/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:26:04] epoch: 3088/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:26:04] epoch: 3088/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:26:04] epoch: 3088/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:26:09] epoch: 3089/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:26:09] epoch: 3089/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:26:09] epoch: 3089/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:26:14] epoch: 3090/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:26:14] epoch: 3090/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:26:14] epoch: 3090/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:26:20] epoch: 3091/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:26:20] epoch: 3091/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:26:20] epoch: 3091/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:26:25] epoch: 3092/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:26:25] epoch: 3092/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:26:25] epoch: 3092/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:26:30] epoch: 3093/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:26:30] epoch: 3093/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:26:30] epoch: 3093/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:26:35] epoch: 3094/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:26:35] epoch: 3094/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:26:35] epoch: 3094/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:26:41] epoch: 3095/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:26:41] epoch: 3095/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:26:41] epoch: 3095/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:26:46] epoch: 3096/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:26:46] epoch: 3096/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:26:46] epoch: 3096/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:26:51] epoch: 3097/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:26:51] epoch: 3097/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:26:51] epoch: 3097/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:26:57] epoch: 3098/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:26:57] epoch: 3098/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:26:57] epoch: 3098/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:27:03] epoch: 3099/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:27:03] epoch: 3099/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:27:03] epoch: 3099/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:27:08] epoch: 3100/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:27:08] epoch: 3100/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:27:08] epoch: 3100/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:27:13] epoch: 3101/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:27:13] epoch: 3101/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:27:13] epoch: 3101/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:27:19] epoch: 3102/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:27:19] epoch: 3102/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:27:19] epoch: 3102/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:27:24] epoch: 3103/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-23:27:24] epoch: 3103/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:27:24] epoch: 3103/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:27:29] epoch: 3104/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-23:27:29] epoch: 3104/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:27:29] epoch: 3104/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:27:35] epoch: 3105/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:27:35] epoch: 3105/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:27:35] epoch: 3105/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:27:40] epoch: 3106/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:27:40] epoch: 3106/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:27:40] epoch: 3106/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:27:45] epoch: 3107/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:27:45] epoch: 3107/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:27:45] epoch: 3107/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:27:50] epoch: 3108/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:27:50] epoch: 3108/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:27:50] epoch: 3108/5000, generator loss: 0.6949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:27:56] epoch: 3109/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:27:56] epoch: 3109/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:27:56] epoch: 3109/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:28:01] epoch: 3110/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:28:01] epoch: 3110/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:28:01] epoch: 3110/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:28:06] epoch: 3111/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:28:06] epoch: 3111/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:28:06] epoch: 3111/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:28:11] epoch: 3112/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:28:11] epoch: 3112/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:28:11] epoch: 3112/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:28:17] epoch: 3113/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:28:17] epoch: 3113/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:28:17] epoch: 3113/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:28:22] epoch: 3114/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:28:22] epoch: 3114/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:28:22] epoch: 3114/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:28:27] epoch: 3115/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:28:27] epoch: 3115/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:28:27] epoch: 3115/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:28:33] epoch: 3116/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:28:33] epoch: 3116/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:28:33] epoch: 3116/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:28:38] epoch: 3117/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:28:38] epoch: 3117/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:28:38] epoch: 3117/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:28:43] epoch: 3118/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-23:28:43] epoch: 3118/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:28:43] epoch: 3118/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:28:49] epoch: 3119/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-23:28:49] epoch: 3119/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:28:49] epoch: 3119/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:28:54] epoch: 3120/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-23:28:54] epoch: 3120/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:28:54] epoch: 3120/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:28:59] epoch: 3121/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:28:59] epoch: 3121/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:28:59] epoch: 3121/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:29:05] epoch: 3122/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:29:05] epoch: 3122/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:29:05] epoch: 3122/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:29:10] epoch: 3123/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:29:10] epoch: 3123/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:29:10] epoch: 3123/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:29:15] epoch: 3124/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:29:15] epoch: 3124/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:29:15] epoch: 3124/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:29:20] epoch: 3125/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:29:20] epoch: 3125/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:29:20] epoch: 3125/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:29:26] epoch: 3126/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:29:26] epoch: 3126/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:29:26] epoch: 3126/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:29:31] epoch: 3127/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:29:31] epoch: 3127/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:29:31] epoch: 3127/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200404-23:29:36] epoch: 3128/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:29:36] epoch: 3128/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:29:36] epoch: 3128/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200404-23:29:42] epoch: 3129/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:29:42] epoch: 3129/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:29:42] epoch: 3129/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200404-23:29:47] epoch: 3130/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:29:47] epoch: 3130/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:29:47] epoch: 3130/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:29:52] epoch: 3131/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:29:52] epoch: 3131/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:29:52] epoch: 3131/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:29:58] epoch: 3132/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:29:58] epoch: 3132/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:29:58] epoch: 3132/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:30:03] epoch: 3133/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:30:03] epoch: 3133/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:30:03] epoch: 3133/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:30:09] epoch: 3134/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:30:09] epoch: 3134/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:30:09] epoch: 3134/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:30:14] epoch: 3135/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:30:14] epoch: 3135/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:30:14] epoch: 3135/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:30:19] epoch: 3136/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:30:19] epoch: 3136/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:30:19] epoch: 3136/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:30:24] epoch: 3137/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:30:24] epoch: 3137/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:30:24] epoch: 3137/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:30:30] epoch: 3138/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:30:30] epoch: 3138/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:30:30] epoch: 3138/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:30:35] epoch: 3139/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:30:35] epoch: 3139/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:30:35] epoch: 3139/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:30:40] epoch: 3140/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:30:40] epoch: 3140/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:30:40] epoch: 3140/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:30:46] epoch: 3141/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:30:46] epoch: 3141/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200404-23:30:46] epoch: 3141/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:30:51] epoch: 3142/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:30:51] epoch: 3142/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:30:51] epoch: 3142/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:30:56] epoch: 3143/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:30:56] epoch: 3143/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:30:56] epoch: 3143/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:31:02] epoch: 3144/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:31:02] epoch: 3144/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:02] epoch: 3144/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:31:07] epoch: 3145/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:31:07] epoch: 3145/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:07] epoch: 3145/5000, generator loss: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:31:12] epoch: 3146/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:31:12] epoch: 3146/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:12] epoch: 3146/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:31:18] epoch: 3147/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:31:18] epoch: 3147/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:18] epoch: 3147/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:31:23] epoch: 3148/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:31:23] epoch: 3148/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:23] epoch: 3148/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:31:28] epoch: 3149/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:31:28] epoch: 3149/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:28] epoch: 3149/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:31:33] epoch: 3150/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:31:33] epoch: 3150/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:33] epoch: 3150/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:31:39] epoch: 3151/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:31:39] epoch: 3151/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:39] epoch: 3151/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:31:44] epoch: 3152/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:31:44] epoch: 3152/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:44] epoch: 3152/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:31:49] epoch: 3153/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:31:49] epoch: 3153/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:49] epoch: 3153/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:31:55] epoch: 3154/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:31:55] epoch: 3154/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:31:55] epoch: 3154/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:32:00] epoch: 3155/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:32:00] epoch: 3155/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:00] epoch: 3155/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:32:05] epoch: 3156/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:32:05] epoch: 3156/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:05] epoch: 3156/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:32:11] epoch: 3157/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:32:11] epoch: 3157/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:11] epoch: 3157/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:32:16] epoch: 3158/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:32:16] epoch: 3158/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:16] epoch: 3158/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:32:21] epoch: 3159/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:32:21] epoch: 3159/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:21] epoch: 3159/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:32:26] epoch: 3160/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:32:26] epoch: 3160/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:26] epoch: 3160/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:32:31] epoch: 3161/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:32:31] epoch: 3161/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:31] epoch: 3161/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:32:37] epoch: 3162/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:32:37] epoch: 3162/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:37] epoch: 3162/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:32:42] epoch: 3163/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:32:42] epoch: 3163/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:42] epoch: 3163/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:32:47] epoch: 3164/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:32:47] epoch: 3164/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:47] epoch: 3164/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:32:53] epoch: 3165/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:32:53] epoch: 3165/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:53] epoch: 3165/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:32:58] epoch: 3166/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:32:58] epoch: 3166/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:32:58] epoch: 3166/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:33:04] epoch: 3167/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:33:04] epoch: 3167/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:33:04] epoch: 3167/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:33:09] epoch: 3168/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:33:09] epoch: 3168/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:33:09] epoch: 3168/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:33:15] epoch: 3169/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:33:15] epoch: 3169/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:33:15] epoch: 3169/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:33:20] epoch: 3170/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:33:20] epoch: 3170/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:33:20] epoch: 3170/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:33:25] epoch: 3171/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:33:25] epoch: 3171/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:33:25] epoch: 3171/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:33:30] epoch: 3172/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:33:30] epoch: 3172/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:33:30] epoch: 3172/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:33:36] epoch: 3173/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:33:36] epoch: 3173/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:33:36] epoch: 3173/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:33:41] epoch: 3174/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-23:33:41] epoch: 3174/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:33:41] epoch: 3174/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:33:46] epoch: 3175/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:33:46] epoch: 3175/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:33:46] epoch: 3175/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:33:52] epoch: 3176/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:33:52] epoch: 3176/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:33:52] epoch: 3176/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:33:57] epoch: 3177/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:33:57] epoch: 3177/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:33:57] epoch: 3177/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:34:02] epoch: 3178/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:34:02] epoch: 3178/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:34:02] epoch: 3178/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:34:07] epoch: 3179/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:34:07] epoch: 3179/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:34:07] epoch: 3179/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:34:13] epoch: 3180/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:34:13] epoch: 3180/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:34:13] epoch: 3180/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:34:18] epoch: 3181/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:34:18] epoch: 3181/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:34:18] epoch: 3181/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:34:23] epoch: 3182/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-23:34:23] epoch: 3182/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:34:23] epoch: 3182/5000, generator loss: 0.6950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:34:29] epoch: 3183/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200404-23:34:29] epoch: 3183/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:34:29] epoch: 3183/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:34:34] epoch: 3184/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-23:34:34] epoch: 3184/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:34:34] epoch: 3184/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:34:39] epoch: 3185/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200404-23:34:39] epoch: 3185/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:34:39] epoch: 3185/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:34:45] epoch: 3186/5000, reconstruction loss: 0.0213\n",
      "[LOG TRAIN 20200404-23:34:45] epoch: 3186/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:34:45] epoch: 3186/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:34:50] epoch: 3187/5000, reconstruction loss: 0.0268\n",
      "[LOG TRAIN 20200404-23:34:50] epoch: 3187/5000, discriminator loss: 1.3818\n",
      "[LOG TRAIN 20200404-23:34:50] epoch: 3187/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:34:55] epoch: 3188/5000, reconstruction loss: 0.0255\n",
      "[LOG TRAIN 20200404-23:34:55] epoch: 3188/5000, discriminator loss: 1.3810\n",
      "[LOG TRAIN 20200404-23:34:55] epoch: 3188/5000, generator loss: 0.6968\n",
      "[LOG TRAIN 20200404-23:35:00] epoch: 3189/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200404-23:35:00] epoch: 3189/5000, discriminator loss: 1.3816\n",
      "[LOG TRAIN 20200404-23:35:00] epoch: 3189/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200404-23:35:06] epoch: 3190/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200404-23:35:06] epoch: 3190/5000, discriminator loss: 1.3818\n",
      "[LOG TRAIN 20200404-23:35:06] epoch: 3190/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:35:11] epoch: 3191/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200404-23:35:11] epoch: 3191/5000, discriminator loss: 1.3819\n",
      "[LOG TRAIN 20200404-23:35:11] epoch: 3191/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200404-23:35:16] epoch: 3192/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-23:35:16] epoch: 3192/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:35:16] epoch: 3192/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200404-23:35:22] epoch: 3193/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:35:22] epoch: 3193/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:35:22] epoch: 3193/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200404-23:35:27] epoch: 3194/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:35:27] epoch: 3194/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:35:27] epoch: 3194/5000, generator loss: 0.6974\n",
      "[LOG TRAIN 20200404-23:35:32] epoch: 3195/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:35:32] epoch: 3195/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:35:32] epoch: 3195/5000, generator loss: 0.6971\n",
      "[LOG TRAIN 20200404-23:35:38] epoch: 3196/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:35:38] epoch: 3196/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:35:38] epoch: 3196/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200404-23:35:43] epoch: 3197/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:35:43] epoch: 3197/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:35:43] epoch: 3197/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:35:48] epoch: 3198/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:35:48] epoch: 3198/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:35:48] epoch: 3198/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:35:54] epoch: 3199/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:35:54] epoch: 3199/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:35:54] epoch: 3199/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:35:59] epoch: 3200/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:35:59] epoch: 3200/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:35:59] epoch: 3200/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200404-23:36:05] epoch: 3201/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:36:05] epoch: 3201/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:36:05] epoch: 3201/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200404-23:36:10] epoch: 3202/5000, reconstruction loss: 0.0156\n",
      "[LOG TRAIN 20200404-23:36:10] epoch: 3202/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:36:10] epoch: 3202/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:36:15] epoch: 3203/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:36:15] epoch: 3203/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:36:15] epoch: 3203/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200404-23:36:20] epoch: 3204/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:36:20] epoch: 3204/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:36:20] epoch: 3204/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-23:36:26] epoch: 3205/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:36:26] epoch: 3205/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:36:26] epoch: 3205/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:36:31] epoch: 3206/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:36:31] epoch: 3206/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:36:31] epoch: 3206/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:36:36] epoch: 3207/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:36:36] epoch: 3207/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:36:36] epoch: 3207/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:36:42] epoch: 3208/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:36:42] epoch: 3208/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:36:42] epoch: 3208/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:36:47] epoch: 3209/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:36:47] epoch: 3209/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:36:47] epoch: 3209/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200404-23:36:52] epoch: 3210/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:36:52] epoch: 3210/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:36:52] epoch: 3210/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200404-23:36:57] epoch: 3211/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:36:57] epoch: 3211/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:36:57] epoch: 3211/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:37:03] epoch: 3212/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:37:03] epoch: 3212/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:37:03] epoch: 3212/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:37:08] epoch: 3213/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:37:08] epoch: 3213/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:37:08] epoch: 3213/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:37:13] epoch: 3214/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:37:13] epoch: 3214/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:37:13] epoch: 3214/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:37:19] epoch: 3215/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:37:19] epoch: 3215/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:37:19] epoch: 3215/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:37:24] epoch: 3216/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:37:24] epoch: 3216/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:37:24] epoch: 3216/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:37:29] epoch: 3217/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:37:29] epoch: 3217/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:37:29] epoch: 3217/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:37:35] epoch: 3218/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:37:35] epoch: 3218/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:37:35] epoch: 3218/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:37:40] epoch: 3219/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:37:40] epoch: 3219/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:37:40] epoch: 3219/5000, generator loss: 0.6949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:37:45] epoch: 3220/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:37:45] epoch: 3220/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:37:45] epoch: 3220/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:37:51] epoch: 3221/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:37:51] epoch: 3221/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:37:51] epoch: 3221/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:37:56] epoch: 3222/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:37:56] epoch: 3222/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:37:56] epoch: 3222/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:38:01] epoch: 3223/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:38:01] epoch: 3223/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:38:01] epoch: 3223/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:38:07] epoch: 3224/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:38:07] epoch: 3224/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:38:07] epoch: 3224/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:38:12] epoch: 3225/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:38:12] epoch: 3225/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:38:12] epoch: 3225/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:38:17] epoch: 3226/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:38:17] epoch: 3226/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:38:17] epoch: 3226/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:38:22] epoch: 3227/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:38:22] epoch: 3227/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:38:22] epoch: 3227/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:38:28] epoch: 3228/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:38:28] epoch: 3228/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:38:28] epoch: 3228/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:38:33] epoch: 3229/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:38:33] epoch: 3229/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:38:33] epoch: 3229/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:38:38] epoch: 3230/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:38:38] epoch: 3230/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:38:38] epoch: 3230/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:38:44] epoch: 3231/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:38:44] epoch: 3231/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:38:44] epoch: 3231/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:38:49] epoch: 3232/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:38:49] epoch: 3232/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:38:49] epoch: 3232/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:38:54] epoch: 3233/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:38:54] epoch: 3233/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:38:54] epoch: 3233/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:39:00] epoch: 3234/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:39:00] epoch: 3234/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:39:00] epoch: 3234/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:39:05] epoch: 3235/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:39:05] epoch: 3235/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:39:05] epoch: 3235/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:39:11] epoch: 3236/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:39:11] epoch: 3236/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:39:11] epoch: 3236/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:39:16] epoch: 3237/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:39:16] epoch: 3237/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:39:16] epoch: 3237/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:39:21] epoch: 3238/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:39:21] epoch: 3238/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:39:21] epoch: 3238/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:39:26] epoch: 3239/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:39:26] epoch: 3239/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:39:26] epoch: 3239/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:39:32] epoch: 3240/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-23:39:32] epoch: 3240/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:39:32] epoch: 3240/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:39:37] epoch: 3241/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200404-23:39:37] epoch: 3241/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:39:37] epoch: 3241/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:39:42] epoch: 3242/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-23:39:42] epoch: 3242/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:39:42] epoch: 3242/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:39:48] epoch: 3243/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:39:48] epoch: 3243/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:39:48] epoch: 3243/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:39:53] epoch: 3244/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:39:53] epoch: 3244/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:39:53] epoch: 3244/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:39:58] epoch: 3245/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:39:58] epoch: 3245/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:39:58] epoch: 3245/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:40:04] epoch: 3246/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:40:04] epoch: 3246/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:40:04] epoch: 3246/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:40:09] epoch: 3247/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:40:09] epoch: 3247/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:40:09] epoch: 3247/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:40:14] epoch: 3248/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:40:14] epoch: 3248/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:40:14] epoch: 3248/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:40:19] epoch: 3249/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:40:19] epoch: 3249/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:40:19] epoch: 3249/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:40:25] epoch: 3250/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:40:25] epoch: 3250/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:40:25] epoch: 3250/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:40:30] epoch: 3251/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:40:30] epoch: 3251/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:40:30] epoch: 3251/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:40:35] epoch: 3252/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:40:35] epoch: 3252/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:40:35] epoch: 3252/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:40:41] epoch: 3253/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:40:41] epoch: 3253/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:40:41] epoch: 3253/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:40:46] epoch: 3254/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:40:46] epoch: 3254/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:40:46] epoch: 3254/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:40:51] epoch: 3255/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:40:51] epoch: 3255/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:40:51] epoch: 3255/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:40:56] epoch: 3256/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:40:56] epoch: 3256/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:40:56] epoch: 3256/5000, generator loss: 0.6950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:41:02] epoch: 3257/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:41:02] epoch: 3257/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:02] epoch: 3257/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:41:07] epoch: 3258/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:41:07] epoch: 3258/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:07] epoch: 3258/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:41:13] epoch: 3259/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:41:13] epoch: 3259/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:13] epoch: 3259/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:41:18] epoch: 3260/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:41:18] epoch: 3260/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:18] epoch: 3260/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:41:23] epoch: 3261/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:41:23] epoch: 3261/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:23] epoch: 3261/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:41:29] epoch: 3262/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:41:29] epoch: 3262/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:29] epoch: 3262/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:41:34] epoch: 3263/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:41:34] epoch: 3263/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:34] epoch: 3263/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:41:39] epoch: 3264/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:41:39] epoch: 3264/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:39] epoch: 3264/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:41:44] epoch: 3265/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:41:44] epoch: 3265/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:44] epoch: 3265/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:41:50] epoch: 3266/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:41:50] epoch: 3266/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:50] epoch: 3266/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:41:55] epoch: 3267/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:41:55] epoch: 3267/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:41:55] epoch: 3267/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:42:01] epoch: 3268/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:42:01] epoch: 3268/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:42:01] epoch: 3268/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:42:06] epoch: 3269/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:42:06] epoch: 3269/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:42:06] epoch: 3269/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:42:11] epoch: 3270/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-23:42:11] epoch: 3270/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:42:11] epoch: 3270/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:42:17] epoch: 3271/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:42:17] epoch: 3271/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:42:17] epoch: 3271/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:42:22] epoch: 3272/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:42:22] epoch: 3272/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:42:22] epoch: 3272/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:42:27] epoch: 3273/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:42:27] epoch: 3273/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:42:27] epoch: 3273/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:42:33] epoch: 3274/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:42:33] epoch: 3274/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:42:33] epoch: 3274/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:42:38] epoch: 3275/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:42:38] epoch: 3275/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:42:38] epoch: 3275/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:42:43] epoch: 3276/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:42:43] epoch: 3276/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:42:43] epoch: 3276/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:42:49] epoch: 3277/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:42:49] epoch: 3277/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:42:49] epoch: 3277/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:42:54] epoch: 3278/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:42:54] epoch: 3278/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:42:54] epoch: 3278/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:42:59] epoch: 3279/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:42:59] epoch: 3279/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:42:59] epoch: 3279/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200404-23:43:05] epoch: 3280/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:43:05] epoch: 3280/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:43:05] epoch: 3280/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:43:10] epoch: 3281/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:43:10] epoch: 3281/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:43:10] epoch: 3281/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:43:15] epoch: 3282/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:43:15] epoch: 3282/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:43:15] epoch: 3282/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:43:20] epoch: 3283/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-23:43:20] epoch: 3283/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:43:20] epoch: 3283/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:43:26] epoch: 3284/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-23:43:26] epoch: 3284/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:43:26] epoch: 3284/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:43:31] epoch: 3285/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:43:31] epoch: 3285/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:43:31] epoch: 3285/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:43:36] epoch: 3286/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:43:36] epoch: 3286/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:43:36] epoch: 3286/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:43:42] epoch: 3287/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:43:42] epoch: 3287/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:43:42] epoch: 3287/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:43:47] epoch: 3288/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:43:47] epoch: 3288/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:43:47] epoch: 3288/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:43:52] epoch: 3289/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:43:52] epoch: 3289/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:43:52] epoch: 3289/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:43:58] epoch: 3290/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:43:58] epoch: 3290/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:43:58] epoch: 3290/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200404-23:44:03] epoch: 3291/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:44:03] epoch: 3291/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:44:03] epoch: 3291/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200404-23:44:08] epoch: 3292/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:44:08] epoch: 3292/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:44:08] epoch: 3292/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:44:14] epoch: 3293/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:44:14] epoch: 3293/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:44:14] epoch: 3293/5000, generator loss: 0.6954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:44:19] epoch: 3294/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:44:19] epoch: 3294/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:44:19] epoch: 3294/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:44:24] epoch: 3295/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:44:24] epoch: 3295/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:44:24] epoch: 3295/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:44:29] epoch: 3296/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:44:29] epoch: 3296/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:44:29] epoch: 3296/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:44:35] epoch: 3297/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:44:35] epoch: 3297/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:44:35] epoch: 3297/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:44:40] epoch: 3298/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:44:40] epoch: 3298/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:44:40] epoch: 3298/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:44:45] epoch: 3299/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:44:45] epoch: 3299/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:44:45] epoch: 3299/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:44:51] epoch: 3300/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:44:51] epoch: 3300/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:44:51] epoch: 3300/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:44:56] epoch: 3301/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:44:56] epoch: 3301/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:44:56] epoch: 3301/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:45:02] epoch: 3302/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:45:02] epoch: 3302/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:45:02] epoch: 3302/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:45:07] epoch: 3303/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:45:07] epoch: 3303/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:45:07] epoch: 3303/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:45:12] epoch: 3304/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200404-23:45:12] epoch: 3304/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:45:12] epoch: 3304/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:45:18] epoch: 3305/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-23:45:18] epoch: 3305/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:45:18] epoch: 3305/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:45:23] epoch: 3306/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-23:45:23] epoch: 3306/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:45:23] epoch: 3306/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:45:28] epoch: 3307/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:45:28] epoch: 3307/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:45:28] epoch: 3307/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:45:34] epoch: 3308/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:45:34] epoch: 3308/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:45:34] epoch: 3308/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:45:39] epoch: 3309/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:45:39] epoch: 3309/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:45:39] epoch: 3309/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:45:44] epoch: 3310/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:45:44] epoch: 3310/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:45:44] epoch: 3310/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200404-23:45:50] epoch: 3311/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:45:50] epoch: 3311/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:45:50] epoch: 3311/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200404-23:45:55] epoch: 3312/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:45:55] epoch: 3312/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:45:55] epoch: 3312/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200404-23:46:00] epoch: 3313/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:46:00] epoch: 3313/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:46:00] epoch: 3313/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:46:05] epoch: 3314/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:46:05] epoch: 3314/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:46:05] epoch: 3314/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:46:11] epoch: 3315/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:46:11] epoch: 3315/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:46:11] epoch: 3315/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:46:16] epoch: 3316/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:46:16] epoch: 3316/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:46:16] epoch: 3316/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:46:21] epoch: 3317/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:46:21] epoch: 3317/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:46:21] epoch: 3317/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:46:27] epoch: 3318/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:46:27] epoch: 3318/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:46:27] epoch: 3318/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:46:32] epoch: 3319/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:46:32] epoch: 3319/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:46:32] epoch: 3319/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:46:37] epoch: 3320/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:46:37] epoch: 3320/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:46:37] epoch: 3320/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:46:42] epoch: 3321/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200404-23:46:42] epoch: 3321/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:46:42] epoch: 3321/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:46:48] epoch: 3322/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200404-23:46:48] epoch: 3322/5000, discriminator loss: 1.3821\n",
      "[LOG TRAIN 20200404-23:46:48] epoch: 3322/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200404-23:46:53] epoch: 3323/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200404-23:46:53] epoch: 3323/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:46:53] epoch: 3323/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:46:58] epoch: 3324/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200404-23:46:58] epoch: 3324/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:46:58] epoch: 3324/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:47:04] epoch: 3325/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-23:47:04] epoch: 3325/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:47:04] epoch: 3325/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:47:09] epoch: 3326/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:47:09] epoch: 3326/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:47:09] epoch: 3326/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:47:14] epoch: 3327/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:47:14] epoch: 3327/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:47:14] epoch: 3327/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200404-23:47:20] epoch: 3328/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:47:20] epoch: 3328/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:47:20] epoch: 3328/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200404-23:47:25] epoch: 3329/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:47:25] epoch: 3329/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:47:25] epoch: 3329/5000, generator loss: 0.6964\n",
      "[LOG TRAIN 20200404-23:47:30] epoch: 3330/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:47:30] epoch: 3330/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:47:30] epoch: 3330/5000, generator loss: 0.6966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:47:35] epoch: 3331/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:47:35] epoch: 3331/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:47:35] epoch: 3331/5000, generator loss: 0.6965\n",
      "[LOG TRAIN 20200404-23:47:41] epoch: 3332/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:47:41] epoch: 3332/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:47:41] epoch: 3332/5000, generator loss: 0.6962\n",
      "[LOG TRAIN 20200404-23:47:46] epoch: 3333/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:47:46] epoch: 3333/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:47:46] epoch: 3333/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200404-23:47:51] epoch: 3334/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:47:51] epoch: 3334/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:47:51] epoch: 3334/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200404-23:47:57] epoch: 3335/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:47:57] epoch: 3335/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:47:57] epoch: 3335/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:48:02] epoch: 3336/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:48:02] epoch: 3336/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:48:02] epoch: 3336/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:48:08] epoch: 3337/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:48:08] epoch: 3337/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:48:08] epoch: 3337/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:48:13] epoch: 3338/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:48:13] epoch: 3338/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:48:13] epoch: 3338/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:48:18] epoch: 3339/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:48:18] epoch: 3339/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:48:18] epoch: 3339/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:48:24] epoch: 3340/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:48:24] epoch: 3340/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:48:24] epoch: 3340/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:48:29] epoch: 3341/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:48:29] epoch: 3341/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:48:29] epoch: 3341/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:48:34] epoch: 3342/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-23:48:34] epoch: 3342/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:48:34] epoch: 3342/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:48:40] epoch: 3343/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:48:40] epoch: 3343/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:48:40] epoch: 3343/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:48:45] epoch: 3344/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:48:45] epoch: 3344/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:48:45] epoch: 3344/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:48:50] epoch: 3345/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:48:50] epoch: 3345/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:48:50] epoch: 3345/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:48:55] epoch: 3346/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:48:55] epoch: 3346/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:48:55] epoch: 3346/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:49:01] epoch: 3347/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:49:01] epoch: 3347/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:49:01] epoch: 3347/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:49:06] epoch: 3348/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:49:06] epoch: 3348/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:49:06] epoch: 3348/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:49:11] epoch: 3349/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:49:11] epoch: 3349/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:49:11] epoch: 3349/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:49:17] epoch: 3350/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:49:17] epoch: 3350/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:49:17] epoch: 3350/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:49:22] epoch: 3351/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:49:22] epoch: 3351/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:49:22] epoch: 3351/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:49:27] epoch: 3352/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:49:27] epoch: 3352/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:49:27] epoch: 3352/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:49:33] epoch: 3353/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:49:33] epoch: 3353/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:49:33] epoch: 3353/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:49:38] epoch: 3354/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:49:38] epoch: 3354/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:49:38] epoch: 3354/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:49:43] epoch: 3355/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:49:43] epoch: 3355/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:49:43] epoch: 3355/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:49:49] epoch: 3356/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:49:49] epoch: 3356/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:49:49] epoch: 3356/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:49:54] epoch: 3357/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-23:49:54] epoch: 3357/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:49:54] epoch: 3357/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:49:59] epoch: 3358/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:49:59] epoch: 3358/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:49:59] epoch: 3358/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:50:05] epoch: 3359/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:50:05] epoch: 3359/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:50:05] epoch: 3359/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:50:10] epoch: 3360/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:50:10] epoch: 3360/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:50:10] epoch: 3360/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:50:15] epoch: 3361/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:50:15] epoch: 3361/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:50:15] epoch: 3361/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:50:20] epoch: 3362/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:50:20] epoch: 3362/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:50:20] epoch: 3362/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:50:26] epoch: 3363/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:50:26] epoch: 3363/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:50:26] epoch: 3363/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:50:31] epoch: 3364/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:50:31] epoch: 3364/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:50:31] epoch: 3364/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:50:36] epoch: 3365/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:50:36] epoch: 3365/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:50:36] epoch: 3365/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:50:42] epoch: 3366/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:50:42] epoch: 3366/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:50:42] epoch: 3366/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:50:47] epoch: 3367/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:50:47] epoch: 3367/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:50:47] epoch: 3367/5000, generator loss: 0.6953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:50:52] epoch: 3368/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:50:52] epoch: 3368/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:50:52] epoch: 3368/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:50:58] epoch: 3369/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:50:58] epoch: 3369/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:50:58] epoch: 3369/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:51:03] epoch: 3370/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200404-23:51:03] epoch: 3370/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:51:03] epoch: 3370/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:51:08] epoch: 3371/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200404-23:51:08] epoch: 3371/5000, discriminator loss: 1.3821\n",
      "[LOG TRAIN 20200404-23:51:08] epoch: 3371/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:51:14] epoch: 3372/5000, reconstruction loss: 0.0229\n",
      "[LOG TRAIN 20200404-23:51:14] epoch: 3372/5000, discriminator loss: 1.3819\n",
      "[LOG TRAIN 20200404-23:51:14] epoch: 3372/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:51:19] epoch: 3373/5000, reconstruction loss: 0.0246\n",
      "[LOG TRAIN 20200404-23:51:19] epoch: 3373/5000, discriminator loss: 1.3811\n",
      "[LOG TRAIN 20200404-23:51:19] epoch: 3373/5000, generator loss: 0.6962\n",
      "[LOG TRAIN 20200404-23:51:24] epoch: 3374/5000, reconstruction loss: 0.0218\n",
      "[LOG TRAIN 20200404-23:51:24] epoch: 3374/5000, discriminator loss: 1.3815\n",
      "[LOG TRAIN 20200404-23:51:24] epoch: 3374/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:51:30] epoch: 3375/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-23:51:30] epoch: 3375/5000, discriminator loss: 1.3817\n",
      "[LOG TRAIN 20200404-23:51:30] epoch: 3375/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:51:35] epoch: 3376/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-23:51:35] epoch: 3376/5000, discriminator loss: 1.3819\n",
      "[LOG TRAIN 20200404-23:51:35] epoch: 3376/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200404-23:51:40] epoch: 3377/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:51:40] epoch: 3377/5000, discriminator loss: 1.3821\n",
      "[LOG TRAIN 20200404-23:51:40] epoch: 3377/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:51:45] epoch: 3378/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:51:45] epoch: 3378/5000, discriminator loss: 1.3821\n",
      "[LOG TRAIN 20200404-23:51:45] epoch: 3378/5000, generator loss: 0.6964\n",
      "[LOG TRAIN 20200404-23:51:51] epoch: 3379/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:51:51] epoch: 3379/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200404-23:51:51] epoch: 3379/5000, generator loss: 0.6970\n",
      "[LOG TRAIN 20200404-23:51:56] epoch: 3380/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:51:56] epoch: 3380/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:51:56] epoch: 3380/5000, generator loss: 0.6964\n",
      "[LOG TRAIN 20200404-23:52:01] epoch: 3381/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:52:01] epoch: 3381/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:52:01] epoch: 3381/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200404-23:52:07] epoch: 3382/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:52:07] epoch: 3382/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:52:07] epoch: 3382/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:52:12] epoch: 3383/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:52:12] epoch: 3383/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:52:12] epoch: 3383/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200404-23:52:17] epoch: 3384/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:52:17] epoch: 3384/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:52:17] epoch: 3384/5000, generator loss: 0.6964\n",
      "[LOG TRAIN 20200404-23:52:23] epoch: 3385/5000, reconstruction loss: 0.0157\n",
      "[LOG TRAIN 20200404-23:52:23] epoch: 3385/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:52:23] epoch: 3385/5000, generator loss: 0.6962\n",
      "[LOG TRAIN 20200404-23:52:28] epoch: 3386/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:52:28] epoch: 3386/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:52:28] epoch: 3386/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:52:33] epoch: 3387/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:52:33] epoch: 3387/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:52:33] epoch: 3387/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:52:39] epoch: 3388/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:52:39] epoch: 3388/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:52:39] epoch: 3388/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:52:44] epoch: 3389/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:52:44] epoch: 3389/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:52:44] epoch: 3389/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:52:49] epoch: 3390/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:52:49] epoch: 3390/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:52:49] epoch: 3390/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:52:55] epoch: 3391/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200404-23:52:55] epoch: 3391/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:52:55] epoch: 3391/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:53:00] epoch: 3392/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:53:00] epoch: 3392/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:53:00] epoch: 3392/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:53:05] epoch: 3393/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:53:05] epoch: 3393/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:53:05] epoch: 3393/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:53:11] epoch: 3394/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:53:11] epoch: 3394/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:53:11] epoch: 3394/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:53:16] epoch: 3395/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:53:16] epoch: 3395/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:53:16] epoch: 3395/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:53:21] epoch: 3396/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:53:21] epoch: 3396/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:53:21] epoch: 3396/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:53:27] epoch: 3397/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:53:27] epoch: 3397/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:53:27] epoch: 3397/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:53:32] epoch: 3398/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:53:32] epoch: 3398/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:53:32] epoch: 3398/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:53:37] epoch: 3399/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:53:37] epoch: 3399/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:53:37] epoch: 3399/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:53:43] epoch: 3400/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:53:43] epoch: 3400/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:53:43] epoch: 3400/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:53:48] epoch: 3401/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:53:48] epoch: 3401/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:53:48] epoch: 3401/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:53:53] epoch: 3402/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:53:53] epoch: 3402/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:53:53] epoch: 3402/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:53:59] epoch: 3403/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:53:59] epoch: 3403/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:53:59] epoch: 3403/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:54:04] epoch: 3404/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:54:04] epoch: 3404/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:54:04] epoch: 3404/5000, generator loss: 0.6948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:54:09] epoch: 3405/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:54:09] epoch: 3405/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:54:09] epoch: 3405/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:54:15] epoch: 3406/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:54:15] epoch: 3406/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:54:15] epoch: 3406/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:54:20] epoch: 3407/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-23:54:20] epoch: 3407/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:54:20] epoch: 3407/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:54:25] epoch: 3408/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:54:25] epoch: 3408/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:54:25] epoch: 3408/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:54:31] epoch: 3409/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:54:31] epoch: 3409/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:54:31] epoch: 3409/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:54:36] epoch: 3410/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:54:36] epoch: 3410/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:54:36] epoch: 3410/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:54:41] epoch: 3411/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:54:41] epoch: 3411/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:54:41] epoch: 3411/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:54:47] epoch: 3412/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:54:47] epoch: 3412/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:54:47] epoch: 3412/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:54:52] epoch: 3413/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:54:52] epoch: 3413/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:54:52] epoch: 3413/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:54:57] epoch: 3414/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-23:54:57] epoch: 3414/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:54:57] epoch: 3414/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:55:03] epoch: 3415/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:55:03] epoch: 3415/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:55:03] epoch: 3415/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:55:08] epoch: 3416/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200404-23:55:08] epoch: 3416/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:55:08] epoch: 3416/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:55:13] epoch: 3417/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200404-23:55:13] epoch: 3417/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:55:13] epoch: 3417/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:55:19] epoch: 3418/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200404-23:55:19] epoch: 3418/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:55:19] epoch: 3418/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:55:24] epoch: 3419/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-23:55:24] epoch: 3419/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:55:24] epoch: 3419/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:55:29] epoch: 3420/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-23:55:29] epoch: 3420/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:55:29] epoch: 3420/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:55:35] epoch: 3421/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:55:35] epoch: 3421/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:55:35] epoch: 3421/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:55:40] epoch: 3422/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:55:40] epoch: 3422/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:55:40] epoch: 3422/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:55:45] epoch: 3423/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:55:45] epoch: 3423/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:55:45] epoch: 3423/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:55:51] epoch: 3424/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:55:51] epoch: 3424/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:55:51] epoch: 3424/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:55:56] epoch: 3425/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:55:56] epoch: 3425/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:55:56] epoch: 3425/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:56:01] epoch: 3426/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:56:01] epoch: 3426/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:56:01] epoch: 3426/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:56:06] epoch: 3427/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:56:06] epoch: 3427/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:56:06] epoch: 3427/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200404-23:56:12] epoch: 3428/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:56:12] epoch: 3428/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:56:12] epoch: 3428/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:56:17] epoch: 3429/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:56:17] epoch: 3429/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:56:17] epoch: 3429/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:56:22] epoch: 3430/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:56:22] epoch: 3430/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:56:22] epoch: 3430/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:56:27] epoch: 3431/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:56:27] epoch: 3431/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:56:27] epoch: 3431/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:56:33] epoch: 3432/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:56:33] epoch: 3432/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:56:33] epoch: 3432/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:56:38] epoch: 3433/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:56:38] epoch: 3433/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:56:38] epoch: 3433/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200404-23:56:43] epoch: 3434/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:56:43] epoch: 3434/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:56:43] epoch: 3434/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:56:49] epoch: 3435/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:56:49] epoch: 3435/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:56:49] epoch: 3435/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:56:54] epoch: 3436/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:56:54] epoch: 3436/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:56:54] epoch: 3436/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:57:00] epoch: 3437/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-23:57:00] epoch: 3437/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:57:00] epoch: 3437/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:57:05] epoch: 3438/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:57:05] epoch: 3438/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:57:05] epoch: 3438/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:57:10] epoch: 3439/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:57:10] epoch: 3439/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:57:10] epoch: 3439/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:57:16] epoch: 3440/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200404-23:57:16] epoch: 3440/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:57:16] epoch: 3440/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:57:21] epoch: 3441/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-23:57:21] epoch: 3441/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:57:21] epoch: 3441/5000, generator loss: 0.6948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200404-23:57:26] epoch: 3442/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-23:57:26] epoch: 3442/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:57:26] epoch: 3442/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:57:31] epoch: 3443/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200404-23:57:31] epoch: 3443/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:57:31] epoch: 3443/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:57:37] epoch: 3444/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200404-23:57:37] epoch: 3444/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:57:37] epoch: 3444/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:57:42] epoch: 3445/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200404-23:57:42] epoch: 3445/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:57:42] epoch: 3445/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:57:47] epoch: 3446/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200404-23:57:47] epoch: 3446/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:57:47] epoch: 3446/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:57:52] epoch: 3447/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:57:52] epoch: 3447/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200404-23:57:52] epoch: 3447/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:57:58] epoch: 3448/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:57:58] epoch: 3448/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:57:58] epoch: 3448/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:58:03] epoch: 3449/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:58:03] epoch: 3449/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:58:03] epoch: 3449/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:58:08] epoch: 3450/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:58:08] epoch: 3450/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200404-23:58:08] epoch: 3450/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:58:14] epoch: 3451/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:58:14] epoch: 3451/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:58:14] epoch: 3451/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:58:19] epoch: 3452/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:58:19] epoch: 3452/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:58:19] epoch: 3452/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200404-23:58:24] epoch: 3453/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:58:24] epoch: 3453/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:58:24] epoch: 3453/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200404-23:58:30] epoch: 3454/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:58:30] epoch: 3454/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:58:30] epoch: 3454/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:58:35] epoch: 3455/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200404-23:58:35] epoch: 3455/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:58:35] epoch: 3455/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200404-23:58:40] epoch: 3456/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200404-23:58:40] epoch: 3456/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:58:40] epoch: 3456/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:58:45] epoch: 3457/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200404-23:58:45] epoch: 3457/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:58:45] epoch: 3457/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:58:51] epoch: 3458/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:58:51] epoch: 3458/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:58:51] epoch: 3458/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:58:56] epoch: 3459/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:58:56] epoch: 3459/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:58:56] epoch: 3459/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200404-23:59:01] epoch: 3460/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:59:01] epoch: 3460/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:01] epoch: 3460/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:59:07] epoch: 3461/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:59:07] epoch: 3461/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:07] epoch: 3461/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:59:12] epoch: 3462/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200404-23:59:12] epoch: 3462/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:12] epoch: 3462/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:59:17] epoch: 3463/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:59:17] epoch: 3463/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:17] epoch: 3463/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:59:23] epoch: 3464/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:59:23] epoch: 3464/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:23] epoch: 3464/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200404-23:59:28] epoch: 3465/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200404-23:59:28] epoch: 3465/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:28] epoch: 3465/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:59:33] epoch: 3466/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200404-23:59:33] epoch: 3466/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:33] epoch: 3466/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200404-23:59:38] epoch: 3467/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200404-23:59:38] epoch: 3467/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:38] epoch: 3467/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200404-23:59:44] epoch: 3468/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200404-23:59:44] epoch: 3468/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:44] epoch: 3468/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:59:49] epoch: 3469/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-23:59:49] epoch: 3469/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:49] epoch: 3469/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200404-23:59:54] epoch: 3470/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200404-23:59:54] epoch: 3470/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200404-23:59:54] epoch: 3470/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:00:00] epoch: 3471/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:00:00] epoch: 3471/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:00] epoch: 3471/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:00:06] epoch: 3472/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:00:06] epoch: 3472/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:06] epoch: 3472/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:00:11] epoch: 3473/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:00:11] epoch: 3473/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:11] epoch: 3473/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:00:16] epoch: 3474/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:00:16] epoch: 3474/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:16] epoch: 3474/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:00:21] epoch: 3475/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:00:21] epoch: 3475/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:21] epoch: 3475/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:00:27] epoch: 3476/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:00:27] epoch: 3476/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:27] epoch: 3476/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:00:32] epoch: 3477/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:00:32] epoch: 3477/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:32] epoch: 3477/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:00:37] epoch: 3478/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:00:37] epoch: 3478/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:00:37] epoch: 3478/5000, generator loss: 0.6951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:00:43] epoch: 3479/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:00:43] epoch: 3479/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:43] epoch: 3479/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:00:48] epoch: 3480/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:00:48] epoch: 3480/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:48] epoch: 3480/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:00:53] epoch: 3481/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200405-00:00:53] epoch: 3481/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:53] epoch: 3481/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:00:59] epoch: 3482/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:00:59] epoch: 3482/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:00:59] epoch: 3482/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:01:04] epoch: 3483/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:01:04] epoch: 3483/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:01:04] epoch: 3483/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:01:09] epoch: 3484/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:01:09] epoch: 3484/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:01:09] epoch: 3484/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:01:14] epoch: 3485/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200405-00:01:14] epoch: 3485/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200405-00:01:14] epoch: 3485/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:01:20] epoch: 3486/5000, reconstruction loss: 0.0205\n",
      "[LOG TRAIN 20200405-00:01:20] epoch: 3486/5000, discriminator loss: 1.3821\n",
      "[LOG TRAIN 20200405-00:01:20] epoch: 3486/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:01:25] epoch: 3487/5000, reconstruction loss: 0.0257\n",
      "[LOG TRAIN 20200405-00:01:25] epoch: 3487/5000, discriminator loss: 1.3818\n",
      "[LOG TRAIN 20200405-00:01:25] epoch: 3487/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:01:30] epoch: 3488/5000, reconstruction loss: 0.0263\n",
      "[LOG TRAIN 20200405-00:01:30] epoch: 3488/5000, discriminator loss: 1.3816\n",
      "[LOG TRAIN 20200405-00:01:30] epoch: 3488/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:01:35] epoch: 3489/5000, reconstruction loss: 0.0221\n",
      "[LOG TRAIN 20200405-00:01:35] epoch: 3489/5000, discriminator loss: 1.3817\n",
      "[LOG TRAIN 20200405-00:01:35] epoch: 3489/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:01:41] epoch: 3490/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200405-00:01:41] epoch: 3490/5000, discriminator loss: 1.3817\n",
      "[LOG TRAIN 20200405-00:01:41] epoch: 3490/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:01:46] epoch: 3491/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-00:01:46] epoch: 3491/5000, discriminator loss: 1.3820\n",
      "[LOG TRAIN 20200405-00:01:46] epoch: 3491/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:01:51] epoch: 3492/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:01:51] epoch: 3492/5000, discriminator loss: 1.3821\n",
      "[LOG TRAIN 20200405-00:01:51] epoch: 3492/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:01:57] epoch: 3493/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:01:57] epoch: 3493/5000, discriminator loss: 1.3821\n",
      "[LOG TRAIN 20200405-00:01:57] epoch: 3493/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:02:02] epoch: 3494/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:02:02] epoch: 3494/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200405-00:02:02] epoch: 3494/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200405-00:02:07] epoch: 3495/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200405-00:02:07] epoch: 3495/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200405-00:02:07] epoch: 3495/5000, generator loss: 0.6964\n",
      "[LOG TRAIN 20200405-00:02:13] epoch: 3496/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200405-00:02:13] epoch: 3496/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200405-00:02:13] epoch: 3496/5000, generator loss: 0.6962\n",
      "[LOG TRAIN 20200405-00:02:18] epoch: 3497/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200405-00:02:18] epoch: 3497/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200405-00:02:18] epoch: 3497/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:02:23] epoch: 3498/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200405-00:02:23] epoch: 3498/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:02:23] epoch: 3498/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:02:28] epoch: 3499/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200405-00:02:28] epoch: 3499/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:02:28] epoch: 3499/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200405-00:02:34] epoch: 3500/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200405-00:02:34] epoch: 3500/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:02:34] epoch: 3500/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:02:39] epoch: 3501/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200405-00:02:39] epoch: 3501/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:02:39] epoch: 3501/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:02:44] epoch: 3502/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200405-00:02:44] epoch: 3502/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:02:44] epoch: 3502/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:02:50] epoch: 3503/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200405-00:02:50] epoch: 3503/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:02:50] epoch: 3503/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:02:55] epoch: 3504/5000, reconstruction loss: 0.0158\n",
      "[LOG TRAIN 20200405-00:02:55] epoch: 3504/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:02:55] epoch: 3504/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:03:01] epoch: 3505/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200405-00:03:01] epoch: 3505/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:01] epoch: 3505/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:03:06] epoch: 3506/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:03:06] epoch: 3506/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:06] epoch: 3506/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:03:12] epoch: 3507/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200405-00:03:12] epoch: 3507/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:12] epoch: 3507/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:03:17] epoch: 3508/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200405-00:03:17] epoch: 3508/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:17] epoch: 3508/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:03:22] epoch: 3509/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200405-00:03:22] epoch: 3509/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:22] epoch: 3509/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:03:28] epoch: 3510/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:03:28] epoch: 3510/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:28] epoch: 3510/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:03:33] epoch: 3511/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:03:33] epoch: 3511/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:33] epoch: 3511/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:03:38] epoch: 3512/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:03:38] epoch: 3512/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:38] epoch: 3512/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:03:43] epoch: 3513/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:03:43] epoch: 3513/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:43] epoch: 3513/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:03:49] epoch: 3514/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:03:49] epoch: 3514/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:49] epoch: 3514/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:03:54] epoch: 3515/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:03:54] epoch: 3515/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:54] epoch: 3515/5000, generator loss: 0.6947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:03:59] epoch: 3516/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:03:59] epoch: 3516/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:03:59] epoch: 3516/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:04:05] epoch: 3517/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:04:05] epoch: 3517/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:05] epoch: 3517/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:04:10] epoch: 3518/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:04:10] epoch: 3518/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:10] epoch: 3518/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:04:15] epoch: 3519/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:04:15] epoch: 3519/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:15] epoch: 3519/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:04:20] epoch: 3520/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:04:20] epoch: 3520/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:20] epoch: 3520/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:04:26] epoch: 3521/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:04:26] epoch: 3521/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:26] epoch: 3521/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:04:31] epoch: 3522/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:04:31] epoch: 3522/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:31] epoch: 3522/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:04:36] epoch: 3523/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:04:36] epoch: 3523/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:36] epoch: 3523/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:04:42] epoch: 3524/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:04:42] epoch: 3524/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:42] epoch: 3524/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:04:47] epoch: 3525/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:04:47] epoch: 3525/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:47] epoch: 3525/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:04:52] epoch: 3526/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:04:52] epoch: 3526/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:52] epoch: 3526/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:04:57] epoch: 3527/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:04:57] epoch: 3527/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:04:57] epoch: 3527/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:05:03] epoch: 3528/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:05:03] epoch: 3528/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:05:03] epoch: 3528/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:05:08] epoch: 3529/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:05:08] epoch: 3529/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:05:08] epoch: 3529/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:05:13] epoch: 3530/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:05:13] epoch: 3530/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:05:13] epoch: 3530/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:05:19] epoch: 3531/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200405-00:05:19] epoch: 3531/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:05:19] epoch: 3531/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:05:24] epoch: 3532/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200405-00:05:24] epoch: 3532/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200405-00:05:24] epoch: 3532/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:05:29] epoch: 3533/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:05:29] epoch: 3533/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:05:29] epoch: 3533/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:05:34] epoch: 3534/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:05:34] epoch: 3534/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:05:34] epoch: 3534/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:05:40] epoch: 3535/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:05:40] epoch: 3535/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:05:40] epoch: 3535/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:05:45] epoch: 3536/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:05:45] epoch: 3536/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:05:45] epoch: 3536/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:05:50] epoch: 3537/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:05:50] epoch: 3537/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:05:50] epoch: 3537/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:05:56] epoch: 3538/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:05:56] epoch: 3538/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:05:56] epoch: 3538/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:06:01] epoch: 3539/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:06:01] epoch: 3539/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:06:01] epoch: 3539/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:06:07] epoch: 3540/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:06:07] epoch: 3540/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:06:07] epoch: 3540/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:06:12] epoch: 3541/5000, reconstruction loss: 0.0159\n",
      "[LOG TRAIN 20200405-00:06:12] epoch: 3541/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:06:12] epoch: 3541/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:06:17] epoch: 3542/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:06:17] epoch: 3542/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:06:17] epoch: 3542/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:06:23] epoch: 3543/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:06:23] epoch: 3543/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:06:23] epoch: 3543/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:06:28] epoch: 3544/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:06:28] epoch: 3544/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:06:28] epoch: 3544/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:06:33] epoch: 3545/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:06:33] epoch: 3545/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:06:33] epoch: 3545/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:06:39] epoch: 3546/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:06:39] epoch: 3546/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:06:39] epoch: 3546/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:06:44] epoch: 3547/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:06:44] epoch: 3547/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:06:44] epoch: 3547/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:06:49] epoch: 3548/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:06:49] epoch: 3548/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:06:49] epoch: 3548/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:06:55] epoch: 3549/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:06:55] epoch: 3549/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:06:55] epoch: 3549/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:07:00] epoch: 3550/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:07:00] epoch: 3550/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:07:00] epoch: 3550/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:07:05] epoch: 3551/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:07:05] epoch: 3551/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:07:05] epoch: 3551/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:07:11] epoch: 3552/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:07:11] epoch: 3552/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:07:11] epoch: 3552/5000, generator loss: 0.6950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:07:16] epoch: 3553/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:07:16] epoch: 3553/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:07:16] epoch: 3553/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:07:22] epoch: 3554/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:07:22] epoch: 3554/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:07:22] epoch: 3554/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:07:27] epoch: 3555/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:07:27] epoch: 3555/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:07:27] epoch: 3555/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:07:32] epoch: 3556/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:07:32] epoch: 3556/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:07:32] epoch: 3556/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:07:37] epoch: 3557/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:07:37] epoch: 3557/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:07:37] epoch: 3557/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:07:43] epoch: 3558/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:07:43] epoch: 3558/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:07:43] epoch: 3558/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:07:48] epoch: 3559/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:07:48] epoch: 3559/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:07:48] epoch: 3559/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:07:53] epoch: 3560/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:07:53] epoch: 3560/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:07:53] epoch: 3560/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:07:59] epoch: 3561/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:07:59] epoch: 3561/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:07:59] epoch: 3561/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:08:04] epoch: 3562/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:08:04] epoch: 3562/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:08:04] epoch: 3562/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:08:09] epoch: 3563/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:08:09] epoch: 3563/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:08:09] epoch: 3563/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:08:15] epoch: 3564/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:08:15] epoch: 3564/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:08:15] epoch: 3564/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:08:20] epoch: 3565/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200405-00:08:20] epoch: 3565/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:08:20] epoch: 3565/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:08:25] epoch: 3566/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200405-00:08:25] epoch: 3566/5000, discriminator loss: 1.3822\n",
      "[LOG TRAIN 20200405-00:08:25] epoch: 3566/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:08:31] epoch: 3567/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:08:31] epoch: 3567/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:08:31] epoch: 3567/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:08:36] epoch: 3568/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:08:36] epoch: 3568/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:08:36] epoch: 3568/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:08:41] epoch: 3569/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:08:41] epoch: 3569/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:08:41] epoch: 3569/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:08:47] epoch: 3570/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:08:47] epoch: 3570/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:08:47] epoch: 3570/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:08:52] epoch: 3571/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:08:52] epoch: 3571/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:08:52] epoch: 3571/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200405-00:08:57] epoch: 3572/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:08:57] epoch: 3572/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:08:57] epoch: 3572/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:09:03] epoch: 3573/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:09:03] epoch: 3573/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:09:03] epoch: 3573/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:09:08] epoch: 3574/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:09:08] epoch: 3574/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:09:08] epoch: 3574/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200405-00:09:13] epoch: 3575/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:09:13] epoch: 3575/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:09:13] epoch: 3575/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200405-00:09:19] epoch: 3576/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:09:19] epoch: 3576/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:09:19] epoch: 3576/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:09:24] epoch: 3577/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:09:24] epoch: 3577/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:09:24] epoch: 3577/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:09:29] epoch: 3578/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:09:29] epoch: 3578/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:09:29] epoch: 3578/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:09:34] epoch: 3579/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:09:34] epoch: 3579/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:09:34] epoch: 3579/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:09:40] epoch: 3580/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:09:40] epoch: 3580/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:09:40] epoch: 3580/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:09:45] epoch: 3581/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-00:09:45] epoch: 3581/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:09:45] epoch: 3581/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:09:50] epoch: 3582/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:09:50] epoch: 3582/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:09:50] epoch: 3582/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:09:56] epoch: 3583/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-00:09:56] epoch: 3583/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:09:56] epoch: 3583/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:10:01] epoch: 3584/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-00:10:01] epoch: 3584/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:10:01] epoch: 3584/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:10:06] epoch: 3585/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200405-00:10:06] epoch: 3585/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:10:06] epoch: 3585/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:10:12] epoch: 3586/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-00:10:12] epoch: 3586/5000, discriminator loss: 1.3823\n",
      "[LOG TRAIN 20200405-00:10:12] epoch: 3586/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:10:17] epoch: 3587/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:10:17] epoch: 3587/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:10:17] epoch: 3587/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:10:22] epoch: 3588/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:10:22] epoch: 3588/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:10:22] epoch: 3588/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:10:28] epoch: 3589/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:10:28] epoch: 3589/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:10:28] epoch: 3589/5000, generator loss: 0.6948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:10:33] epoch: 3590/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:10:33] epoch: 3590/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:10:33] epoch: 3590/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:10:38] epoch: 3591/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:10:38] epoch: 3591/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:10:38] epoch: 3591/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:10:44] epoch: 3592/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:10:44] epoch: 3592/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:10:44] epoch: 3592/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:10:49] epoch: 3593/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:10:49] epoch: 3593/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:10:49] epoch: 3593/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:10:54] epoch: 3594/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:10:54] epoch: 3594/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:10:54] epoch: 3594/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:10:59] epoch: 3595/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:10:59] epoch: 3595/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:10:59] epoch: 3595/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:11:05] epoch: 3596/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:11:05] epoch: 3596/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:11:05] epoch: 3596/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:11:10] epoch: 3597/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:11:10] epoch: 3597/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:11:10] epoch: 3597/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:11:15] epoch: 3598/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200405-00:11:15] epoch: 3598/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:11:15] epoch: 3598/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:11:21] epoch: 3599/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-00:11:21] epoch: 3599/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:11:21] epoch: 3599/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:11:26] epoch: 3600/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:11:26] epoch: 3600/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:11:26] epoch: 3600/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:11:31] epoch: 3601/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:11:31] epoch: 3601/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:11:31] epoch: 3601/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:11:37] epoch: 3602/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:11:37] epoch: 3602/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:11:37] epoch: 3602/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:11:42] epoch: 3603/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:11:42] epoch: 3603/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:11:42] epoch: 3603/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:11:47] epoch: 3604/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:11:47] epoch: 3604/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:11:47] epoch: 3604/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:11:52] epoch: 3605/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:11:52] epoch: 3605/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:11:52] epoch: 3605/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:11:58] epoch: 3606/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:11:58] epoch: 3606/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:11:58] epoch: 3606/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:12:04] epoch: 3607/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:12:04] epoch: 3607/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:04] epoch: 3607/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:12:09] epoch: 3608/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:12:09] epoch: 3608/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:09] epoch: 3608/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:12:14] epoch: 3609/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:12:14] epoch: 3609/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:14] epoch: 3609/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:12:20] epoch: 3610/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:12:20] epoch: 3610/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:20] epoch: 3610/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:12:25] epoch: 3611/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:12:25] epoch: 3611/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:25] epoch: 3611/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:12:30] epoch: 3612/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:12:30] epoch: 3612/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:30] epoch: 3612/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:12:35] epoch: 3613/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:12:35] epoch: 3613/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:35] epoch: 3613/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:12:41] epoch: 3614/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:12:41] epoch: 3614/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:41] epoch: 3614/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:12:46] epoch: 3615/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:12:46] epoch: 3615/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:46] epoch: 3615/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:12:51] epoch: 3616/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:12:51] epoch: 3616/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:51] epoch: 3616/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:12:57] epoch: 3617/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:12:57] epoch: 3617/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:12:57] epoch: 3617/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:13:02] epoch: 3618/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:13:02] epoch: 3618/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:13:02] epoch: 3618/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:13:07] epoch: 3619/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200405-00:13:07] epoch: 3619/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:13:07] epoch: 3619/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:13:13] epoch: 3620/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-00:13:13] epoch: 3620/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:13:13] epoch: 3620/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:13:18] epoch: 3621/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:13:18] epoch: 3621/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:13:18] epoch: 3621/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:13:23] epoch: 3622/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:13:23] epoch: 3622/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:13:23] epoch: 3622/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:13:28] epoch: 3623/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:13:28] epoch: 3623/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:13:28] epoch: 3623/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:13:34] epoch: 3624/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:13:34] epoch: 3624/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:13:34] epoch: 3624/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:13:39] epoch: 3625/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:13:39] epoch: 3625/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:13:39] epoch: 3625/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:13:44] epoch: 3626/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:13:44] epoch: 3626/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:13:44] epoch: 3626/5000, generator loss: 0.6952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:13:50] epoch: 3627/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:13:50] epoch: 3627/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:13:50] epoch: 3627/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:13:55] epoch: 3628/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:13:55] epoch: 3628/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:13:55] epoch: 3628/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:14:00] epoch: 3629/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:14:00] epoch: 3629/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:14:00] epoch: 3629/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:14:06] epoch: 3630/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:14:06] epoch: 3630/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:14:06] epoch: 3630/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:14:11] epoch: 3631/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:14:11] epoch: 3631/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:14:11] epoch: 3631/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:14:16] epoch: 3632/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:14:16] epoch: 3632/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:14:16] epoch: 3632/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:14:21] epoch: 3633/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:14:21] epoch: 3633/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:14:21] epoch: 3633/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:14:27] epoch: 3634/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-00:14:27] epoch: 3634/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:14:27] epoch: 3634/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:14:32] epoch: 3635/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200405-00:14:32] epoch: 3635/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:14:32] epoch: 3635/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:14:37] epoch: 3636/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-00:14:37] epoch: 3636/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:14:37] epoch: 3636/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:14:43] epoch: 3637/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200405-00:14:43] epoch: 3637/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:14:43] epoch: 3637/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:14:48] epoch: 3638/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-00:14:48] epoch: 3638/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:14:48] epoch: 3638/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:14:53] epoch: 3639/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:14:53] epoch: 3639/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:14:53] epoch: 3639/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:14:59] epoch: 3640/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:14:59] epoch: 3640/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:14:59] epoch: 3640/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:15:04] epoch: 3641/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:15:04] epoch: 3641/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:15:04] epoch: 3641/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:15:10] epoch: 3642/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:15:10] epoch: 3642/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:15:10] epoch: 3642/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:15:15] epoch: 3643/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:15:15] epoch: 3643/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:15:15] epoch: 3643/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:15:20] epoch: 3644/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:15:20] epoch: 3644/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:15:20] epoch: 3644/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:15:26] epoch: 3645/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:15:26] epoch: 3645/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:15:26] epoch: 3645/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:15:31] epoch: 3646/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:15:31] epoch: 3646/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:15:31] epoch: 3646/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:15:36] epoch: 3647/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:15:36] epoch: 3647/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:15:36] epoch: 3647/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:15:42] epoch: 3648/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:15:42] epoch: 3648/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:15:42] epoch: 3648/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:15:47] epoch: 3649/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:15:47] epoch: 3649/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:15:47] epoch: 3649/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:15:52] epoch: 3650/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:15:52] epoch: 3650/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:15:52] epoch: 3650/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:15:58] epoch: 3651/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:15:58] epoch: 3651/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:15:58] epoch: 3651/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:16:03] epoch: 3652/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:16:03] epoch: 3652/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:16:03] epoch: 3652/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:16:08] epoch: 3653/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:16:08] epoch: 3653/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:16:08] epoch: 3653/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:16:14] epoch: 3654/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200405-00:16:14] epoch: 3654/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:16:14] epoch: 3654/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:16:19] epoch: 3655/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:16:19] epoch: 3655/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:16:19] epoch: 3655/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:16:24] epoch: 3656/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:16:24] epoch: 3656/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:16:24] epoch: 3656/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:16:29] epoch: 3657/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:16:29] epoch: 3657/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:16:29] epoch: 3657/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:16:35] epoch: 3658/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:16:35] epoch: 3658/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:16:35] epoch: 3658/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:16:40] epoch: 3659/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:16:40] epoch: 3659/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:16:40] epoch: 3659/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:16:45] epoch: 3660/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:16:45] epoch: 3660/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:16:45] epoch: 3660/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:16:51] epoch: 3661/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:16:51] epoch: 3661/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:16:51] epoch: 3661/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:16:56] epoch: 3662/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200405-00:16:56] epoch: 3662/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:16:56] epoch: 3662/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:17:01] epoch: 3663/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-00:17:01] epoch: 3663/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:17:01] epoch: 3663/5000, generator loss: 0.6952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:17:07] epoch: 3664/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-00:17:07] epoch: 3664/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:17:07] epoch: 3664/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:17:12] epoch: 3665/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200405-00:17:12] epoch: 3665/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:17:12] epoch: 3665/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:17:17] epoch: 3666/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-00:17:17] epoch: 3666/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:17:17] epoch: 3666/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:17:22] epoch: 3667/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:17:22] epoch: 3667/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:17:22] epoch: 3667/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:17:28] epoch: 3668/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:17:28] epoch: 3668/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:17:28] epoch: 3668/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:17:33] epoch: 3669/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:17:33] epoch: 3669/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:17:33] epoch: 3669/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:17:38] epoch: 3670/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:17:38] epoch: 3670/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:17:38] epoch: 3670/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:17:44] epoch: 3671/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:17:44] epoch: 3671/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:17:44] epoch: 3671/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:17:49] epoch: 3672/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:17:49] epoch: 3672/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:17:49] epoch: 3672/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:17:54] epoch: 3673/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:17:54] epoch: 3673/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:17:54] epoch: 3673/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200405-00:18:00] epoch: 3674/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:18:00] epoch: 3674/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:00] epoch: 3674/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:18:05] epoch: 3675/5000, reconstruction loss: 0.0160\n",
      "[LOG TRAIN 20200405-00:18:05] epoch: 3675/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:05] epoch: 3675/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:18:10] epoch: 3676/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:18:10] epoch: 3676/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:10] epoch: 3676/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:18:16] epoch: 3677/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:18:16] epoch: 3677/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:16] epoch: 3677/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:18:21] epoch: 3678/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:18:21] epoch: 3678/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:21] epoch: 3678/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:18:26] epoch: 3679/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:18:26] epoch: 3679/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:26] epoch: 3679/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:18:31] epoch: 3680/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:18:31] epoch: 3680/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:31] epoch: 3680/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:18:37] epoch: 3681/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:18:37] epoch: 3681/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:37] epoch: 3681/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:18:42] epoch: 3682/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:18:42] epoch: 3682/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:42] epoch: 3682/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:18:47] epoch: 3683/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:18:47] epoch: 3683/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:47] epoch: 3683/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:18:52] epoch: 3684/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:18:52] epoch: 3684/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:52] epoch: 3684/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:18:58] epoch: 3685/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:18:58] epoch: 3685/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:18:58] epoch: 3685/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:19:03] epoch: 3686/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200405-00:19:03] epoch: 3686/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:19:03] epoch: 3686/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:19:09] epoch: 3687/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200405-00:19:09] epoch: 3687/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:19:09] epoch: 3687/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:19:14] epoch: 3688/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200405-00:19:14] epoch: 3688/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:19:14] epoch: 3688/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:19:19] epoch: 3689/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200405-00:19:19] epoch: 3689/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:19:19] epoch: 3689/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:19:24] epoch: 3690/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:19:24] epoch: 3690/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:19:24] epoch: 3690/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:19:30] epoch: 3691/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:19:30] epoch: 3691/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:19:30] epoch: 3691/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:19:35] epoch: 3692/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:19:35] epoch: 3692/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:19:35] epoch: 3692/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:19:40] epoch: 3693/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:19:40] epoch: 3693/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:19:40] epoch: 3693/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:19:46] epoch: 3694/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:19:46] epoch: 3694/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:19:46] epoch: 3694/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:19:51] epoch: 3695/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:19:51] epoch: 3695/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:19:51] epoch: 3695/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:19:56] epoch: 3696/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:19:56] epoch: 3696/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:19:56] epoch: 3696/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:20:01] epoch: 3697/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:20:01] epoch: 3697/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:20:01] epoch: 3697/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:20:07] epoch: 3698/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:20:07] epoch: 3698/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:20:07] epoch: 3698/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:20:12] epoch: 3699/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:20:12] epoch: 3699/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:20:12] epoch: 3699/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:20:17] epoch: 3700/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:20:17] epoch: 3700/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:20:17] epoch: 3700/5000, generator loss: 0.6948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:20:23] epoch: 3701/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:20:23] epoch: 3701/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:20:23] epoch: 3701/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:20:28] epoch: 3702/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:20:28] epoch: 3702/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:20:28] epoch: 3702/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:20:33] epoch: 3703/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:20:33] epoch: 3703/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:20:33] epoch: 3703/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:20:39] epoch: 3704/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:20:39] epoch: 3704/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:20:39] epoch: 3704/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:20:44] epoch: 3705/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:20:44] epoch: 3705/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:20:44] epoch: 3705/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:20:49] epoch: 3706/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-00:20:49] epoch: 3706/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:20:49] epoch: 3706/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:20:55] epoch: 3707/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200405-00:20:55] epoch: 3707/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:20:55] epoch: 3707/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:21:00] epoch: 3708/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:21:00] epoch: 3708/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:21:00] epoch: 3708/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:21:06] epoch: 3709/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:21:06] epoch: 3709/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:21:06] epoch: 3709/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:21:11] epoch: 3710/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:21:11] epoch: 3710/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:21:11] epoch: 3710/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:21:16] epoch: 3711/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:21:16] epoch: 3711/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:21:16] epoch: 3711/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:21:22] epoch: 3712/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:21:22] epoch: 3712/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:21:22] epoch: 3712/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:21:27] epoch: 3713/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:21:27] epoch: 3713/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:21:27] epoch: 3713/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:21:32] epoch: 3714/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:21:32] epoch: 3714/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:21:32] epoch: 3714/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:21:37] epoch: 3715/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:21:37] epoch: 3715/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:21:37] epoch: 3715/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:21:43] epoch: 3716/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:21:43] epoch: 3716/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:21:43] epoch: 3716/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:21:48] epoch: 3717/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:21:48] epoch: 3717/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:21:48] epoch: 3717/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:21:53] epoch: 3718/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:21:53] epoch: 3718/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:21:53] epoch: 3718/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:21:59] epoch: 3719/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:21:59] epoch: 3719/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:21:59] epoch: 3719/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:22:04] epoch: 3720/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:22:04] epoch: 3720/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:22:04] epoch: 3720/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:22:09] epoch: 3721/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:22:09] epoch: 3721/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:22:09] epoch: 3721/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:22:15] epoch: 3722/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:22:15] epoch: 3722/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:22:15] epoch: 3722/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:22:20] epoch: 3723/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:22:20] epoch: 3723/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:22:20] epoch: 3723/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:22:25] epoch: 3724/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:22:25] epoch: 3724/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:22:25] epoch: 3724/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:22:30] epoch: 3725/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-00:22:30] epoch: 3725/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:22:30] epoch: 3725/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:22:36] epoch: 3726/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:22:36] epoch: 3726/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:22:36] epoch: 3726/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:22:41] epoch: 3727/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:22:41] epoch: 3727/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:22:41] epoch: 3727/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:22:46] epoch: 3728/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200405-00:22:46] epoch: 3728/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:22:46] epoch: 3728/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:22:52] epoch: 3729/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-00:22:52] epoch: 3729/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:22:52] epoch: 3729/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:22:57] epoch: 3730/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-00:22:57] epoch: 3730/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:22:57] epoch: 3730/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:23:02] epoch: 3731/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:23:02] epoch: 3731/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:23:02] epoch: 3731/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:23:08] epoch: 3732/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:23:08] epoch: 3732/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:23:08] epoch: 3732/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:23:13] epoch: 3733/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:23:13] epoch: 3733/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:23:13] epoch: 3733/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:23:18] epoch: 3734/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:23:18] epoch: 3734/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:23:18] epoch: 3734/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:23:23] epoch: 3735/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:23:23] epoch: 3735/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:23:23] epoch: 3735/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:23:29] epoch: 3736/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:23:29] epoch: 3736/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:23:29] epoch: 3736/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:23:34] epoch: 3737/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:23:34] epoch: 3737/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:23:34] epoch: 3737/5000, generator loss: 0.6954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:23:39] epoch: 3738/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200405-00:23:39] epoch: 3738/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:23:39] epoch: 3738/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:23:45] epoch: 3739/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:23:45] epoch: 3739/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:23:45] epoch: 3739/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:23:50] epoch: 3740/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:23:50] epoch: 3740/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:23:50] epoch: 3740/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:23:55] epoch: 3741/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:23:55] epoch: 3741/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:23:55] epoch: 3741/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:24:01] epoch: 3742/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:24:01] epoch: 3742/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:24:01] epoch: 3742/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:24:06] epoch: 3743/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:24:06] epoch: 3743/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:24:06] epoch: 3743/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:24:11] epoch: 3744/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:24:11] epoch: 3744/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:24:11] epoch: 3744/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:24:17] epoch: 3745/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:24:17] epoch: 3745/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:24:17] epoch: 3745/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:24:22] epoch: 3746/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:24:22] epoch: 3746/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:24:22] epoch: 3746/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:24:27] epoch: 3747/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:24:27] epoch: 3747/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:24:27] epoch: 3747/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:24:33] epoch: 3748/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:24:33] epoch: 3748/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:24:33] epoch: 3748/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:24:38] epoch: 3749/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:24:38] epoch: 3749/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:24:38] epoch: 3749/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:24:43] epoch: 3750/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:24:43] epoch: 3750/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:24:43] epoch: 3750/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:24:49] epoch: 3751/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:24:49] epoch: 3751/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:24:49] epoch: 3751/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:24:54] epoch: 3752/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:24:54] epoch: 3752/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:24:54] epoch: 3752/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:24:59] epoch: 3753/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:24:59] epoch: 3753/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:24:59] epoch: 3753/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:25:05] epoch: 3754/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:25:05] epoch: 3754/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:25:05] epoch: 3754/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:25:10] epoch: 3755/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:25:10] epoch: 3755/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:25:10] epoch: 3755/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:25:15] epoch: 3756/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:25:15] epoch: 3756/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:25:15] epoch: 3756/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:25:21] epoch: 3757/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:25:21] epoch: 3757/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:25:21] epoch: 3757/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:25:26] epoch: 3758/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:25:26] epoch: 3758/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:25:26] epoch: 3758/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:25:31] epoch: 3759/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:25:31] epoch: 3759/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:25:31] epoch: 3759/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:25:37] epoch: 3760/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:25:37] epoch: 3760/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:25:37] epoch: 3760/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:25:42] epoch: 3761/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200405-00:25:42] epoch: 3761/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:25:42] epoch: 3761/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:25:47] epoch: 3762/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200405-00:25:47] epoch: 3762/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:25:47] epoch: 3762/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:25:52] epoch: 3763/5000, reconstruction loss: 0.0210\n",
      "[LOG TRAIN 20200405-00:25:52] epoch: 3763/5000, discriminator loss: 1.3824\n",
      "[LOG TRAIN 20200405-00:25:52] epoch: 3763/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:25:58] epoch: 3764/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200405-00:25:58] epoch: 3764/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:25:58] epoch: 3764/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:26:03] epoch: 3765/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200405-00:26:03] epoch: 3765/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:26:03] epoch: 3765/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:26:08] epoch: 3766/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:26:08] epoch: 3766/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:26:08] epoch: 3766/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:26:14] epoch: 3767/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:26:14] epoch: 3767/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:26:14] epoch: 3767/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:26:19] epoch: 3768/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:26:19] epoch: 3768/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:26:19] epoch: 3768/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:26:24] epoch: 3769/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:26:24] epoch: 3769/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:26:24] epoch: 3769/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:26:30] epoch: 3770/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:26:30] epoch: 3770/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:26:30] epoch: 3770/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:26:35] epoch: 3771/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:26:35] epoch: 3771/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:26:35] epoch: 3771/5000, generator loss: 0.6964\n",
      "[LOG TRAIN 20200405-00:26:40] epoch: 3772/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:26:40] epoch: 3772/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:26:40] epoch: 3772/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200405-00:26:46] epoch: 3773/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:26:46] epoch: 3773/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:26:46] epoch: 3773/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:26:51] epoch: 3774/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:26:51] epoch: 3774/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:26:51] epoch: 3774/5000, generator loss: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:26:56] epoch: 3775/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:26:56] epoch: 3775/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:26:56] epoch: 3775/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:27:02] epoch: 3776/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:27:02] epoch: 3776/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:27:02] epoch: 3776/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:27:07] epoch: 3777/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:27:07] epoch: 3777/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:27:07] epoch: 3777/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:27:13] epoch: 3778/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:27:13] epoch: 3778/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:27:13] epoch: 3778/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:27:18] epoch: 3779/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:27:18] epoch: 3779/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:27:18] epoch: 3779/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-00:27:23] epoch: 3780/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:27:23] epoch: 3780/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:27:23] epoch: 3780/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:27:29] epoch: 3781/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:27:29] epoch: 3781/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:27:29] epoch: 3781/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:27:34] epoch: 3782/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:27:34] epoch: 3782/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:27:34] epoch: 3782/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:27:39] epoch: 3783/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:27:39] epoch: 3783/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:27:39] epoch: 3783/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:27:44] epoch: 3784/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:27:44] epoch: 3784/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:27:44] epoch: 3784/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:27:50] epoch: 3785/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:27:50] epoch: 3785/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:27:50] epoch: 3785/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:27:55] epoch: 3786/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:27:55] epoch: 3786/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:27:55] epoch: 3786/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:28:00] epoch: 3787/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:28:00] epoch: 3787/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:28:00] epoch: 3787/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:28:06] epoch: 3788/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:28:06] epoch: 3788/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:28:06] epoch: 3788/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:28:11] epoch: 3789/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:28:11] epoch: 3789/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:28:11] epoch: 3789/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:28:16] epoch: 3790/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:28:16] epoch: 3790/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:28:16] epoch: 3790/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:28:22] epoch: 3791/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:28:22] epoch: 3791/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:28:22] epoch: 3791/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:28:27] epoch: 3792/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:28:27] epoch: 3792/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:28:27] epoch: 3792/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:28:32] epoch: 3793/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:28:32] epoch: 3793/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:28:32] epoch: 3793/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:28:38] epoch: 3794/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:28:38] epoch: 3794/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:28:38] epoch: 3794/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:28:43] epoch: 3795/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:28:43] epoch: 3795/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:28:43] epoch: 3795/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:28:48] epoch: 3796/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:28:48] epoch: 3796/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:28:48] epoch: 3796/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:28:54] epoch: 3797/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:28:54] epoch: 3797/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:28:54] epoch: 3797/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:28:59] epoch: 3798/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:28:59] epoch: 3798/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:28:59] epoch: 3798/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:29:04] epoch: 3799/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:29:04] epoch: 3799/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:29:04] epoch: 3799/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:29:09] epoch: 3800/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:29:09] epoch: 3800/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:29:09] epoch: 3800/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:29:15] epoch: 3801/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:29:15] epoch: 3801/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:29:15] epoch: 3801/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:29:20] epoch: 3802/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:29:20] epoch: 3802/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:29:20] epoch: 3802/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:29:25] epoch: 3803/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:29:25] epoch: 3803/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:29:25] epoch: 3803/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:29:30] epoch: 3804/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:29:30] epoch: 3804/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:29:30] epoch: 3804/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:29:36] epoch: 3805/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:29:36] epoch: 3805/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:29:36] epoch: 3805/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:29:41] epoch: 3806/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:29:41] epoch: 3806/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:29:41] epoch: 3806/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:29:46] epoch: 3807/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:29:46] epoch: 3807/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:29:46] epoch: 3807/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:29:52] epoch: 3808/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:29:52] epoch: 3808/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:29:52] epoch: 3808/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:29:57] epoch: 3809/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:29:57] epoch: 3809/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:29:57] epoch: 3809/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:30:03] epoch: 3810/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-00:30:03] epoch: 3810/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:30:03] epoch: 3810/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:30:08] epoch: 3811/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200405-00:30:08] epoch: 3811/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:30:08] epoch: 3811/5000, generator loss: 0.6949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:30:13] epoch: 3812/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200405-00:30:13] epoch: 3812/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:30:13] epoch: 3812/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:30:18] epoch: 3813/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200405-00:30:18] epoch: 3813/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:30:18] epoch: 3813/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:30:24] epoch: 3814/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-00:30:24] epoch: 3814/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:30:24] epoch: 3814/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:30:29] epoch: 3815/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:30:29] epoch: 3815/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:30:29] epoch: 3815/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:30:34] epoch: 3816/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:30:34] epoch: 3816/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:30:34] epoch: 3816/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:30:40] epoch: 3817/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:30:40] epoch: 3817/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:30:40] epoch: 3817/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:30:45] epoch: 3818/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:30:45] epoch: 3818/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:30:45] epoch: 3818/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:30:50] epoch: 3819/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:30:50] epoch: 3819/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:30:50] epoch: 3819/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:30:55] epoch: 3820/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:30:55] epoch: 3820/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:30:55] epoch: 3820/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:31:01] epoch: 3821/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-00:31:01] epoch: 3821/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:31:01] epoch: 3821/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:31:06] epoch: 3822/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:31:06] epoch: 3822/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:31:06] epoch: 3822/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:31:11] epoch: 3823/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:31:11] epoch: 3823/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:31:11] epoch: 3823/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:31:16] epoch: 3824/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:31:16] epoch: 3824/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:31:16] epoch: 3824/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:31:22] epoch: 3825/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:31:22] epoch: 3825/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:31:22] epoch: 3825/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:31:27] epoch: 3826/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:31:27] epoch: 3826/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:31:27] epoch: 3826/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:31:32] epoch: 3827/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:31:32] epoch: 3827/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:31:32] epoch: 3827/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:31:38] epoch: 3828/5000, reconstruction loss: 0.0214\n",
      "[LOG TRAIN 20200405-00:31:38] epoch: 3828/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:31:38] epoch: 3828/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:31:43] epoch: 3829/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200405-00:31:43] epoch: 3829/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:31:43] epoch: 3829/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:31:48] epoch: 3830/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200405-00:31:48] epoch: 3830/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:31:48] epoch: 3830/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:31:53] epoch: 3831/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-00:31:53] epoch: 3831/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:31:53] epoch: 3831/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:31:59] epoch: 3832/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:31:59] epoch: 3832/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:31:59] epoch: 3832/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:32:04] epoch: 3833/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:32:04] epoch: 3833/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:32:04] epoch: 3833/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:32:09] epoch: 3834/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:32:09] epoch: 3834/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:32:09] epoch: 3834/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:32:14] epoch: 3835/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:32:14] epoch: 3835/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:32:14] epoch: 3835/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:32:20] epoch: 3836/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:32:20] epoch: 3836/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:32:20] epoch: 3836/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:32:25] epoch: 3837/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:32:25] epoch: 3837/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:32:25] epoch: 3837/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200405-00:32:30] epoch: 3838/5000, reconstruction loss: 0.0161\n",
      "[LOG TRAIN 20200405-00:32:30] epoch: 3838/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:32:30] epoch: 3838/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200405-00:32:36] epoch: 3839/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:32:36] epoch: 3839/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:32:36] epoch: 3839/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:32:41] epoch: 3840/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:32:41] epoch: 3840/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:32:41] epoch: 3840/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:32:46] epoch: 3841/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:32:46] epoch: 3841/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:32:46] epoch: 3841/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:32:52] epoch: 3842/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:32:52] epoch: 3842/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:32:52] epoch: 3842/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:32:57] epoch: 3843/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:32:57] epoch: 3843/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:32:57] epoch: 3843/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:33:03] epoch: 3844/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:33:03] epoch: 3844/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:33:03] epoch: 3844/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:33:08] epoch: 3845/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:33:08] epoch: 3845/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:33:08] epoch: 3845/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-00:33:14] epoch: 3846/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:33:14] epoch: 3846/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:33:14] epoch: 3846/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:33:19] epoch: 3847/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:33:19] epoch: 3847/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:33:19] epoch: 3847/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:33:24] epoch: 3848/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:33:24] epoch: 3848/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:33:24] epoch: 3848/5000, generator loss: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:33:29] epoch: 3849/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:33:29] epoch: 3849/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:33:29] epoch: 3849/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:33:35] epoch: 3850/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:33:35] epoch: 3850/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:33:35] epoch: 3850/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:33:40] epoch: 3851/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:33:40] epoch: 3851/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:33:40] epoch: 3851/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:33:45] epoch: 3852/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:33:45] epoch: 3852/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:33:45] epoch: 3852/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:33:51] epoch: 3853/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:33:51] epoch: 3853/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:33:51] epoch: 3853/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:33:56] epoch: 3854/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200405-00:33:56] epoch: 3854/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:33:56] epoch: 3854/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:34:01] epoch: 3855/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200405-00:34:01] epoch: 3855/5000, discriminator loss: 1.3825\n",
      "[LOG TRAIN 20200405-00:34:01] epoch: 3855/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:34:07] epoch: 3856/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200405-00:34:07] epoch: 3856/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:34:07] epoch: 3856/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:34:12] epoch: 3857/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-00:34:12] epoch: 3857/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:34:12] epoch: 3857/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:34:17] epoch: 3858/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:34:17] epoch: 3858/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:34:17] epoch: 3858/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:34:23] epoch: 3859/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:34:23] epoch: 3859/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:34:23] epoch: 3859/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:34:28] epoch: 3860/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:34:28] epoch: 3860/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:34:28] epoch: 3860/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:34:33] epoch: 3861/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:34:33] epoch: 3861/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:34:33] epoch: 3861/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:34:38] epoch: 3862/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:34:38] epoch: 3862/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:34:38] epoch: 3862/5000, generator loss: 0.6959\n",
      "[LOG TRAIN 20200405-00:34:44] epoch: 3863/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:34:44] epoch: 3863/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:34:44] epoch: 3863/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200405-00:34:49] epoch: 3864/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:34:49] epoch: 3864/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:34:49] epoch: 3864/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:34:54] epoch: 3865/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:34:54] epoch: 3865/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:34:54] epoch: 3865/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:35:00] epoch: 3866/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:35:00] epoch: 3866/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:35:00] epoch: 3866/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:35:05] epoch: 3867/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:35:05] epoch: 3867/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:35:05] epoch: 3867/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:35:10] epoch: 3868/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:35:10] epoch: 3868/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:35:10] epoch: 3868/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:35:16] epoch: 3869/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:35:16] epoch: 3869/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:35:16] epoch: 3869/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:35:21] epoch: 3870/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:35:21] epoch: 3870/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:35:21] epoch: 3870/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:35:26] epoch: 3871/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:35:26] epoch: 3871/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:35:26] epoch: 3871/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:35:32] epoch: 3872/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:35:32] epoch: 3872/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:35:32] epoch: 3872/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:35:37] epoch: 3873/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:35:37] epoch: 3873/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:35:37] epoch: 3873/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:35:42] epoch: 3874/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:35:42] epoch: 3874/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:35:42] epoch: 3874/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:35:47] epoch: 3875/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:35:47] epoch: 3875/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:35:47] epoch: 3875/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:35:53] epoch: 3876/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:35:53] epoch: 3876/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:35:53] epoch: 3876/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:35:58] epoch: 3877/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:35:58] epoch: 3877/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:35:58] epoch: 3877/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:36:04] epoch: 3878/5000, reconstruction loss: 0.0222\n",
      "[LOG TRAIN 20200405-00:36:04] epoch: 3878/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:36:04] epoch: 3878/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:36:09] epoch: 3879/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200405-00:36:09] epoch: 3879/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:36:09] epoch: 3879/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:36:14] epoch: 3880/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200405-00:36:14] epoch: 3880/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:36:14] epoch: 3880/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:36:20] epoch: 3881/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-00:36:20] epoch: 3881/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:36:20] epoch: 3881/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:36:25] epoch: 3882/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:36:25] epoch: 3882/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:36:25] epoch: 3882/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:36:30] epoch: 3883/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:36:30] epoch: 3883/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:36:30] epoch: 3883/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:36:36] epoch: 3884/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:36:36] epoch: 3884/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:36:36] epoch: 3884/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:36:41] epoch: 3885/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:36:41] epoch: 3885/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:36:41] epoch: 3885/5000, generator loss: 0.6953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:36:46] epoch: 3886/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:36:46] epoch: 3886/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:36:46] epoch: 3886/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:36:51] epoch: 3887/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:36:51] epoch: 3887/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:36:51] epoch: 3887/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200405-00:36:57] epoch: 3888/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:36:57] epoch: 3888/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:36:57] epoch: 3888/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:37:02] epoch: 3889/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:37:02] epoch: 3889/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:37:02] epoch: 3889/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:37:07] epoch: 3890/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:37:07] epoch: 3890/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:37:07] epoch: 3890/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:37:13] epoch: 3891/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:37:13] epoch: 3891/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:37:13] epoch: 3891/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:37:18] epoch: 3892/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:37:18] epoch: 3892/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:37:18] epoch: 3892/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:37:23] epoch: 3893/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:37:23] epoch: 3893/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:37:23] epoch: 3893/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:37:29] epoch: 3894/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:37:29] epoch: 3894/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:37:29] epoch: 3894/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:37:34] epoch: 3895/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:37:34] epoch: 3895/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:37:34] epoch: 3895/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:37:39] epoch: 3896/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:37:39] epoch: 3896/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:37:39] epoch: 3896/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:37:45] epoch: 3897/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:37:45] epoch: 3897/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:37:45] epoch: 3897/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:37:50] epoch: 3898/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:37:50] epoch: 3898/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:37:50] epoch: 3898/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:37:55] epoch: 3899/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:37:55] epoch: 3899/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:37:55] epoch: 3899/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:38:00] epoch: 3900/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-00:38:00] epoch: 3900/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:38:00] epoch: 3900/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:38:06] epoch: 3901/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:38:06] epoch: 3901/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:38:06] epoch: 3901/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:38:11] epoch: 3902/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:38:11] epoch: 3902/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:38:11] epoch: 3902/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:38:16] epoch: 3903/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:38:16] epoch: 3903/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:38:16] epoch: 3903/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:38:22] epoch: 3904/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:38:22] epoch: 3904/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:38:22] epoch: 3904/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:38:27] epoch: 3905/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200405-00:38:27] epoch: 3905/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:38:27] epoch: 3905/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:38:32] epoch: 3906/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200405-00:38:32] epoch: 3906/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:38:32] epoch: 3906/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:38:38] epoch: 3907/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200405-00:38:38] epoch: 3907/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:38:38] epoch: 3907/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:38:43] epoch: 3908/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200405-00:38:43] epoch: 3908/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:38:43] epoch: 3908/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:38:48] epoch: 3909/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200405-00:38:48] epoch: 3909/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:38:48] epoch: 3909/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:38:53] epoch: 3910/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:38:53] epoch: 3910/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:38:53] epoch: 3910/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:38:59] epoch: 3911/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:38:59] epoch: 3911/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:38:59] epoch: 3911/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:39:04] epoch: 3912/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:39:04] epoch: 3912/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:39:04] epoch: 3912/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:39:10] epoch: 3913/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:39:10] epoch: 3913/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:39:10] epoch: 3913/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200405-00:39:15] epoch: 3914/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:39:15] epoch: 3914/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:39:15] epoch: 3914/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200405-00:39:20] epoch: 3915/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:39:20] epoch: 3915/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:39:20] epoch: 3915/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:39:25] epoch: 3916/5000, reconstruction loss: 0.0162\n",
      "[LOG TRAIN 20200405-00:39:25] epoch: 3916/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:39:25] epoch: 3916/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:39:31] epoch: 3917/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:39:31] epoch: 3917/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:39:31] epoch: 3917/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:39:36] epoch: 3918/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:39:36] epoch: 3918/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:39:36] epoch: 3918/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:39:41] epoch: 3919/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:39:41] epoch: 3919/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:39:41] epoch: 3919/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:39:47] epoch: 3920/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:39:47] epoch: 3920/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:39:47] epoch: 3920/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:39:52] epoch: 3921/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:39:52] epoch: 3921/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:39:52] epoch: 3921/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:39:57] epoch: 3922/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:39:57] epoch: 3922/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:39:57] epoch: 3922/5000, generator loss: 0.6941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:40:02] epoch: 3923/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:40:02] epoch: 3923/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:40:02] epoch: 3923/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:40:08] epoch: 3924/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:40:08] epoch: 3924/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:40:08] epoch: 3924/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:40:13] epoch: 3925/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:40:13] epoch: 3925/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:40:13] epoch: 3925/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:40:18] epoch: 3926/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:40:18] epoch: 3926/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:40:18] epoch: 3926/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:40:24] epoch: 3927/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:40:24] epoch: 3927/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:40:24] epoch: 3927/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:40:29] epoch: 3928/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:40:29] epoch: 3928/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:40:29] epoch: 3928/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:40:34] epoch: 3929/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:40:34] epoch: 3929/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:40:34] epoch: 3929/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:40:40] epoch: 3930/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:40:40] epoch: 3930/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:40:40] epoch: 3930/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:40:45] epoch: 3931/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:40:45] epoch: 3931/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:40:45] epoch: 3931/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:40:50] epoch: 3932/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:40:50] epoch: 3932/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:40:50] epoch: 3932/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:40:56] epoch: 3933/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:40:56] epoch: 3933/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:40:56] epoch: 3933/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:41:01] epoch: 3934/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:41:01] epoch: 3934/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:41:01] epoch: 3934/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:41:06] epoch: 3935/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:41:06] epoch: 3935/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:41:06] epoch: 3935/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:41:11] epoch: 3936/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:41:11] epoch: 3936/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:41:11] epoch: 3936/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:41:16] epoch: 3937/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:41:16] epoch: 3937/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:41:16] epoch: 3937/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:41:22] epoch: 3938/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:41:22] epoch: 3938/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:41:22] epoch: 3938/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:41:27] epoch: 3939/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:41:27] epoch: 3939/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:41:27] epoch: 3939/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:41:32] epoch: 3940/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:41:32] epoch: 3940/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:41:32] epoch: 3940/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:41:38] epoch: 3941/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:41:38] epoch: 3941/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:41:38] epoch: 3941/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:41:43] epoch: 3942/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-00:41:43] epoch: 3942/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:41:43] epoch: 3942/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:41:48] epoch: 3943/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:41:48] epoch: 3943/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:41:48] epoch: 3943/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:41:54] epoch: 3944/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:41:54] epoch: 3944/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:41:54] epoch: 3944/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:41:59] epoch: 3945/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:41:59] epoch: 3945/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:41:59] epoch: 3945/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:42:05] epoch: 3946/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:42:05] epoch: 3946/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:42:05] epoch: 3946/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:42:10] epoch: 3947/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:42:10] epoch: 3947/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:42:10] epoch: 3947/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:42:15] epoch: 3948/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:42:15] epoch: 3948/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:42:15] epoch: 3948/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:42:21] epoch: 3949/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:42:21] epoch: 3949/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:42:21] epoch: 3949/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:42:26] epoch: 3950/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:42:26] epoch: 3950/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:42:26] epoch: 3950/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:42:31] epoch: 3951/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200405-00:42:31] epoch: 3951/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:42:31] epoch: 3951/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:42:36] epoch: 3952/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200405-00:42:36] epoch: 3952/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:42:36] epoch: 3952/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:42:42] epoch: 3953/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-00:42:42] epoch: 3953/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:42:42] epoch: 3953/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:42:47] epoch: 3954/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-00:42:47] epoch: 3954/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:42:47] epoch: 3954/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:42:52] epoch: 3955/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:42:52] epoch: 3955/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:42:52] epoch: 3955/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:42:58] epoch: 3956/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:42:58] epoch: 3956/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:42:58] epoch: 3956/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:43:03] epoch: 3957/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:43:03] epoch: 3957/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:43:03] epoch: 3957/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:43:08] epoch: 3958/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:43:08] epoch: 3958/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:43:08] epoch: 3958/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:43:14] epoch: 3959/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:43:14] epoch: 3959/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:43:14] epoch: 3959/5000, generator loss: 0.6953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:43:19] epoch: 3960/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:43:19] epoch: 3960/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:43:19] epoch: 3960/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:43:24] epoch: 3961/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:43:24] epoch: 3961/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:43:24] epoch: 3961/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:43:30] epoch: 3962/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:43:30] epoch: 3962/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:43:30] epoch: 3962/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:43:35] epoch: 3963/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:43:35] epoch: 3963/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:43:35] epoch: 3963/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:43:40] epoch: 3964/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:43:40] epoch: 3964/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:43:40] epoch: 3964/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:43:45] epoch: 3965/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:43:45] epoch: 3965/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:43:45] epoch: 3965/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:43:51] epoch: 3966/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200405-00:43:51] epoch: 3966/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:43:51] epoch: 3966/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:43:56] epoch: 3967/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200405-00:43:56] epoch: 3967/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:43:56] epoch: 3967/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:44:01] epoch: 3968/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-00:44:01] epoch: 3968/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:44:01] epoch: 3968/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:44:06] epoch: 3969/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200405-00:44:06] epoch: 3969/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:44:06] epoch: 3969/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:44:12] epoch: 3970/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200405-00:44:12] epoch: 3970/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:44:12] epoch: 3970/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:44:17] epoch: 3971/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-00:44:17] epoch: 3971/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:44:17] epoch: 3971/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:44:22] epoch: 3972/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:44:22] epoch: 3972/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:44:22] epoch: 3972/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:44:28] epoch: 3973/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:44:28] epoch: 3973/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:44:28] epoch: 3973/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:44:33] epoch: 3974/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:44:33] epoch: 3974/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:44:33] epoch: 3974/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:44:38] epoch: 3975/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:44:38] epoch: 3975/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:44:38] epoch: 3975/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:44:44] epoch: 3976/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:44:44] epoch: 3976/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:44:44] epoch: 3976/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:44:49] epoch: 3977/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:44:49] epoch: 3977/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:44:49] epoch: 3977/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:44:54] epoch: 3978/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:44:54] epoch: 3978/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:44:54] epoch: 3978/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:45:00] epoch: 3979/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-00:45:00] epoch: 3979/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:45:00] epoch: 3979/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:45:05] epoch: 3980/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:45:05] epoch: 3980/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:45:05] epoch: 3980/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:45:11] epoch: 3981/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:45:11] epoch: 3981/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:45:11] epoch: 3981/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:45:16] epoch: 3982/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:45:16] epoch: 3982/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:45:16] epoch: 3982/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:45:21] epoch: 3983/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:45:21] epoch: 3983/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:45:21] epoch: 3983/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:45:26] epoch: 3984/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:45:26] epoch: 3984/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:45:26] epoch: 3984/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:45:32] epoch: 3985/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:45:32] epoch: 3985/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:45:32] epoch: 3985/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:45:37] epoch: 3986/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:45:37] epoch: 3986/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:45:37] epoch: 3986/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:45:42] epoch: 3987/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:45:42] epoch: 3987/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:45:42] epoch: 3987/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:45:48] epoch: 3988/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:45:48] epoch: 3988/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:45:48] epoch: 3988/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:45:53] epoch: 3989/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200405-00:45:53] epoch: 3989/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:45:53] epoch: 3989/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:45:58] epoch: 3990/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:45:58] epoch: 3990/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:45:58] epoch: 3990/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:46:03] epoch: 3991/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200405-00:46:03] epoch: 3991/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:46:03] epoch: 3991/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:46:09] epoch: 3992/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200405-00:46:09] epoch: 3992/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:46:09] epoch: 3992/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:46:14] epoch: 3993/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200405-00:46:14] epoch: 3993/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:46:14] epoch: 3993/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:46:19] epoch: 3994/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:46:19] epoch: 3994/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:46:19] epoch: 3994/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:46:25] epoch: 3995/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:46:25] epoch: 3995/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:46:25] epoch: 3995/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:46:30] epoch: 3996/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:46:30] epoch: 3996/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:46:30] epoch: 3996/5000, generator loss: 0.6951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:46:35] epoch: 3997/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:46:35] epoch: 3997/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:46:35] epoch: 3997/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:46:41] epoch: 3998/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:46:41] epoch: 3998/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:46:41] epoch: 3998/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:46:46] epoch: 3999/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:46:46] epoch: 3999/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:46:46] epoch: 3999/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:46:51] epoch: 4000/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:46:51] epoch: 4000/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:46:51] epoch: 4000/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:46:56] epoch: 4001/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:46:56] epoch: 4001/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:46:56] epoch: 4001/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:47:02] epoch: 4002/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:47:02] epoch: 4002/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:47:02] epoch: 4002/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:47:07] epoch: 4003/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:47:07] epoch: 4003/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:47:07] epoch: 4003/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:47:12] epoch: 4004/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:47:12] epoch: 4004/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:47:12] epoch: 4004/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:47:18] epoch: 4005/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:47:18] epoch: 4005/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:47:18] epoch: 4005/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:47:23] epoch: 4006/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:47:23] epoch: 4006/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:47:23] epoch: 4006/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:47:28] epoch: 4007/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:47:28] epoch: 4007/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:47:28] epoch: 4007/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:47:33] epoch: 4008/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200405-00:47:33] epoch: 4008/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:47:33] epoch: 4008/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:47:39] epoch: 4009/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200405-00:47:39] epoch: 4009/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:47:39] epoch: 4009/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:47:44] epoch: 4010/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200405-00:47:44] epoch: 4010/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:47:44] epoch: 4010/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:47:49] epoch: 4011/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-00:47:49] epoch: 4011/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:47:49] epoch: 4011/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:47:55] epoch: 4012/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-00:47:55] epoch: 4012/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:47:55] epoch: 4012/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:48:00] epoch: 4013/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-00:48:00] epoch: 4013/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:48:00] epoch: 4013/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:48:06] epoch: 4014/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-00:48:06] epoch: 4014/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:48:06] epoch: 4014/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:48:11] epoch: 4015/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:48:11] epoch: 4015/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:48:11] epoch: 4015/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:48:16] epoch: 4016/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:48:16] epoch: 4016/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:48:16] epoch: 4016/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:48:21] epoch: 4017/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:48:21] epoch: 4017/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:48:21] epoch: 4017/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:48:27] epoch: 4018/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:48:27] epoch: 4018/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:48:27] epoch: 4018/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:48:32] epoch: 4019/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:48:32] epoch: 4019/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:48:32] epoch: 4019/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:48:37] epoch: 4020/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:48:37] epoch: 4020/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:48:37] epoch: 4020/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:48:43] epoch: 4021/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:48:43] epoch: 4021/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:48:43] epoch: 4021/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:48:48] epoch: 4022/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:48:48] epoch: 4022/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:48:48] epoch: 4022/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:48:53] epoch: 4023/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:48:53] epoch: 4023/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:48:53] epoch: 4023/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:48:58] epoch: 4024/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:48:58] epoch: 4024/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:48:58] epoch: 4024/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:49:04] epoch: 4025/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:49:04] epoch: 4025/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:49:04] epoch: 4025/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:49:09] epoch: 4026/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:49:09] epoch: 4026/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:49:09] epoch: 4026/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:49:14] epoch: 4027/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:49:14] epoch: 4027/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:49:14] epoch: 4027/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:49:20] epoch: 4028/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:49:20] epoch: 4028/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:49:20] epoch: 4028/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:49:25] epoch: 4029/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-00:49:25] epoch: 4029/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:49:25] epoch: 4029/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:49:30] epoch: 4030/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:49:30] epoch: 4030/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:49:30] epoch: 4030/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:49:35] epoch: 4031/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200405-00:49:35] epoch: 4031/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:49:35] epoch: 4031/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:49:41] epoch: 4032/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-00:49:41] epoch: 4032/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:49:41] epoch: 4032/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:49:46] epoch: 4033/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200405-00:49:46] epoch: 4033/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:49:46] epoch: 4033/5000, generator loss: 0.6951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:49:51] epoch: 4034/5000, reconstruction loss: 0.0232\n",
      "[LOG TRAIN 20200405-00:49:51] epoch: 4034/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:49:51] epoch: 4034/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:49:57] epoch: 4035/5000, reconstruction loss: 0.0240\n",
      "[LOG TRAIN 20200405-00:49:57] epoch: 4035/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:49:57] epoch: 4035/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:50:02] epoch: 4036/5000, reconstruction loss: 0.0221\n",
      "[LOG TRAIN 20200405-00:50:02] epoch: 4036/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:50:02] epoch: 4036/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:50:07] epoch: 4037/5000, reconstruction loss: 0.0215\n",
      "[LOG TRAIN 20200405-00:50:07] epoch: 4037/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:50:07] epoch: 4037/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:50:12] epoch: 4038/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200405-00:50:12] epoch: 4038/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:50:12] epoch: 4038/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:50:18] epoch: 4039/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-00:50:18] epoch: 4039/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:50:18] epoch: 4039/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:50:23] epoch: 4040/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:50:23] epoch: 4040/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:50:23] epoch: 4040/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:50:29] epoch: 4041/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:50:29] epoch: 4041/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:50:29] epoch: 4041/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:50:34] epoch: 4042/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:50:34] epoch: 4042/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:50:34] epoch: 4042/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:50:39] epoch: 4043/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:50:39] epoch: 4043/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:50:39] epoch: 4043/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:50:44] epoch: 4044/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:50:44] epoch: 4044/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:50:44] epoch: 4044/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:50:50] epoch: 4045/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:50:50] epoch: 4045/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:50:50] epoch: 4045/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:50:55] epoch: 4046/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:50:55] epoch: 4046/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:50:55] epoch: 4046/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:51:01] epoch: 4047/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:51:01] epoch: 4047/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:51:01] epoch: 4047/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:51:06] epoch: 4048/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:51:06] epoch: 4048/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:51:06] epoch: 4048/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:51:12] epoch: 4049/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:51:12] epoch: 4049/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:51:12] epoch: 4049/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:51:17] epoch: 4050/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:51:17] epoch: 4050/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:51:17] epoch: 4050/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:51:22] epoch: 4051/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:51:22] epoch: 4051/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:51:22] epoch: 4051/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-00:51:27] epoch: 4052/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:51:27] epoch: 4052/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:51:27] epoch: 4052/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-00:51:33] epoch: 4053/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:51:33] epoch: 4053/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:51:33] epoch: 4053/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:51:38] epoch: 4054/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:51:38] epoch: 4054/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:51:38] epoch: 4054/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:51:43] epoch: 4055/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:51:43] epoch: 4055/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:51:43] epoch: 4055/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:51:49] epoch: 4056/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:51:49] epoch: 4056/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:51:49] epoch: 4056/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:51:54] epoch: 4057/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:51:54] epoch: 4057/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:51:54] epoch: 4057/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:51:59] epoch: 4058/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:51:59] epoch: 4058/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:51:59] epoch: 4058/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:52:04] epoch: 4059/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:52:04] epoch: 4059/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:52:04] epoch: 4059/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:52:10] epoch: 4060/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:52:10] epoch: 4060/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:52:10] epoch: 4060/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:52:15] epoch: 4061/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:52:15] epoch: 4061/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:52:15] epoch: 4061/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:52:20] epoch: 4062/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-00:52:20] epoch: 4062/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:52:20] epoch: 4062/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:52:26] epoch: 4063/5000, reconstruction loss: 0.0216\n",
      "[LOG TRAIN 20200405-00:52:26] epoch: 4063/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:52:26] epoch: 4063/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-00:52:31] epoch: 4064/5000, reconstruction loss: 0.0193\n",
      "[LOG TRAIN 20200405-00:52:31] epoch: 4064/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:52:31] epoch: 4064/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:52:36] epoch: 4065/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-00:52:36] epoch: 4065/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:52:36] epoch: 4065/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:52:42] epoch: 4066/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:52:42] epoch: 4066/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:52:42] epoch: 4066/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:52:47] epoch: 4067/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:52:47] epoch: 4067/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:52:47] epoch: 4067/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:52:52] epoch: 4068/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:52:52] epoch: 4068/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:52:52] epoch: 4068/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:52:58] epoch: 4069/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:52:58] epoch: 4069/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:52:58] epoch: 4069/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-00:53:03] epoch: 4070/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:53:03] epoch: 4070/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:53:03] epoch: 4070/5000, generator loss: 0.6951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:53:08] epoch: 4071/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:53:08] epoch: 4071/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:53:08] epoch: 4071/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:53:13] epoch: 4072/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:53:13] epoch: 4072/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:53:13] epoch: 4072/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:53:19] epoch: 4073/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:53:19] epoch: 4073/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:53:19] epoch: 4073/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-00:53:24] epoch: 4074/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:53:24] epoch: 4074/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:53:24] epoch: 4074/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:53:29] epoch: 4075/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:53:29] epoch: 4075/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:53:29] epoch: 4075/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:53:35] epoch: 4076/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:53:35] epoch: 4076/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:53:35] epoch: 4076/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:53:40] epoch: 4077/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:53:40] epoch: 4077/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:53:40] epoch: 4077/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:53:45] epoch: 4078/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:53:45] epoch: 4078/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:53:45] epoch: 4078/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:53:51] epoch: 4079/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:53:51] epoch: 4079/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:53:51] epoch: 4079/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:53:56] epoch: 4080/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:53:56] epoch: 4080/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:53:56] epoch: 4080/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:54:02] epoch: 4081/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200405-00:54:02] epoch: 4081/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:54:02] epoch: 4081/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:54:07] epoch: 4082/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200405-00:54:07] epoch: 4082/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:54:07] epoch: 4082/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:54:12] epoch: 4083/5000, reconstruction loss: 0.0224\n",
      "[LOG TRAIN 20200405-00:54:12] epoch: 4083/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:54:12] epoch: 4083/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:54:18] epoch: 4084/5000, reconstruction loss: 0.0230\n",
      "[LOG TRAIN 20200405-00:54:18] epoch: 4084/5000, discriminator loss: 1.3826\n",
      "[LOG TRAIN 20200405-00:54:18] epoch: 4084/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:54:23] epoch: 4085/5000, reconstruction loss: 0.0239\n",
      "[LOG TRAIN 20200405-00:54:23] epoch: 4085/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:54:23] epoch: 4085/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:54:28] epoch: 4086/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200405-00:54:28] epoch: 4086/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-00:54:28] epoch: 4086/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-00:54:34] epoch: 4087/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200405-00:54:34] epoch: 4087/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:54:34] epoch: 4087/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-00:54:39] epoch: 4088/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200405-00:54:39] epoch: 4088/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:54:39] epoch: 4088/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-00:54:44] epoch: 4089/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200405-00:54:44] epoch: 4089/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-00:54:44] epoch: 4089/5000, generator loss: 0.6972\n",
      "[LOG TRAIN 20200405-00:54:50] epoch: 4090/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:54:50] epoch: 4090/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-00:54:50] epoch: 4090/5000, generator loss: 0.6967\n",
      "[LOG TRAIN 20200405-00:54:55] epoch: 4091/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:54:55] epoch: 4091/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:54:55] epoch: 4091/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:55:00] epoch: 4092/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:55:00] epoch: 4092/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:55:00] epoch: 4092/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-00:55:06] epoch: 4093/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:55:06] epoch: 4093/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:55:06] epoch: 4093/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:55:11] epoch: 4094/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:55:11] epoch: 4094/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:55:11] epoch: 4094/5000, generator loss: 0.6962\n",
      "[LOG TRAIN 20200405-00:55:16] epoch: 4095/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:55:16] epoch: 4095/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:55:16] epoch: 4095/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-00:55:22] epoch: 4096/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:55:22] epoch: 4096/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:55:22] epoch: 4096/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:55:27] epoch: 4097/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:55:27] epoch: 4097/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:55:27] epoch: 4097/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-00:55:32] epoch: 4098/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:55:32] epoch: 4098/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:55:32] epoch: 4098/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:55:38] epoch: 4099/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:55:38] epoch: 4099/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:55:38] epoch: 4099/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:55:43] epoch: 4100/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:55:43] epoch: 4100/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:55:43] epoch: 4100/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:55:48] epoch: 4101/5000, reconstruction loss: 0.0163\n",
      "[LOG TRAIN 20200405-00:55:48] epoch: 4101/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:55:48] epoch: 4101/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:55:53] epoch: 4102/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:55:53] epoch: 4102/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:55:53] epoch: 4102/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-00:55:59] epoch: 4103/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:55:59] epoch: 4103/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:55:59] epoch: 4103/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:56:04] epoch: 4104/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-00:56:04] epoch: 4104/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:04] epoch: 4104/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:56:09] epoch: 4105/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:56:09] epoch: 4105/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:09] epoch: 4105/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:56:15] epoch: 4106/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:56:15] epoch: 4106/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:15] epoch: 4106/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:56:20] epoch: 4107/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:56:20] epoch: 4107/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:20] epoch: 4107/5000, generator loss: 0.6943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:56:25] epoch: 4108/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:56:25] epoch: 4108/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:25] epoch: 4108/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:56:31] epoch: 4109/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:56:31] epoch: 4109/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:31] epoch: 4109/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:56:36] epoch: 4110/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:56:36] epoch: 4110/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:36] epoch: 4110/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:56:41] epoch: 4111/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:56:41] epoch: 4111/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:41] epoch: 4111/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:56:47] epoch: 4112/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:56:47] epoch: 4112/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:47] epoch: 4112/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:56:52] epoch: 4113/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:56:52] epoch: 4113/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:52] epoch: 4113/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:56:57] epoch: 4114/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:56:57] epoch: 4114/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:56:57] epoch: 4114/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:57:03] epoch: 4115/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:57:03] epoch: 4115/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:57:03] epoch: 4115/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:57:08] epoch: 4116/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:57:08] epoch: 4116/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:57:08] epoch: 4116/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:57:14] epoch: 4117/5000, reconstruction loss: 0.0220\n",
      "[LOG TRAIN 20200405-00:57:14] epoch: 4117/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:57:14] epoch: 4117/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:57:19] epoch: 4118/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200405-00:57:19] epoch: 4118/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-00:57:19] epoch: 4118/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-00:57:24] epoch: 4119/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-00:57:24] epoch: 4119/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-00:57:24] epoch: 4119/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:57:29] epoch: 4120/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-00:57:29] epoch: 4120/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:57:29] epoch: 4120/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-00:57:35] epoch: 4121/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:57:35] epoch: 4121/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:57:35] epoch: 4121/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:57:40] epoch: 4122/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:57:40] epoch: 4122/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:57:40] epoch: 4122/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:57:45] epoch: 4123/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:57:45] epoch: 4123/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:57:45] epoch: 4123/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:57:50] epoch: 4124/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:57:50] epoch: 4124/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:57:50] epoch: 4124/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-00:57:56] epoch: 4125/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:57:56] epoch: 4125/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:57:56] epoch: 4125/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-00:58:01] epoch: 4126/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:58:01] epoch: 4126/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:58:01] epoch: 4126/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:58:06] epoch: 4127/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:58:06] epoch: 4127/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:58:06] epoch: 4127/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-00:58:12] epoch: 4128/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:58:12] epoch: 4128/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:58:12] epoch: 4128/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-00:58:17] epoch: 4129/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:58:17] epoch: 4129/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:58:17] epoch: 4129/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:58:22] epoch: 4130/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:58:22] epoch: 4130/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:58:22] epoch: 4130/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:58:28] epoch: 4131/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:58:28] epoch: 4131/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:58:28] epoch: 4131/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:58:33] epoch: 4132/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:58:33] epoch: 4132/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:58:33] epoch: 4132/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:58:38] epoch: 4133/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:58:38] epoch: 4133/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:58:38] epoch: 4133/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:58:44] epoch: 4134/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:58:44] epoch: 4134/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:58:44] epoch: 4134/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:58:49] epoch: 4135/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:58:49] epoch: 4135/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:58:49] epoch: 4135/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-00:58:54] epoch: 4136/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-00:58:54] epoch: 4136/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-00:58:54] epoch: 4136/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:58:59] epoch: 4137/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-00:58:59] epoch: 4137/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:58:59] epoch: 4137/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-00:59:05] epoch: 4138/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:59:05] epoch: 4138/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-00:59:05] epoch: 4138/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-00:59:10] epoch: 4139/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-00:59:10] epoch: 4139/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:59:10] epoch: 4139/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:59:15] epoch: 4140/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200405-00:59:15] epoch: 4140/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:59:15] epoch: 4140/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:59:21] epoch: 4141/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200405-00:59:21] epoch: 4141/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-00:59:21] epoch: 4141/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-00:59:26] epoch: 4142/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-00:59:26] epoch: 4142/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-00:59:26] epoch: 4142/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-00:59:31] epoch: 4143/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-00:59:31] epoch: 4143/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:59:31] epoch: 4143/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-00:59:37] epoch: 4144/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:59:37] epoch: 4144/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:59:37] epoch: 4144/5000, generator loss: 0.6945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-00:59:42] epoch: 4145/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-00:59:42] epoch: 4145/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:59:42] epoch: 4145/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:59:47] epoch: 4146/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-00:59:47] epoch: 4146/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:59:47] epoch: 4146/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-00:59:53] epoch: 4147/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-00:59:53] epoch: 4147/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:59:53] epoch: 4147/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-00:59:58] epoch: 4148/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-00:59:58] epoch: 4148/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-00:59:58] epoch: 4148/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-01:00:04] epoch: 4149/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:00:04] epoch: 4149/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:00:04] epoch: 4149/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-01:00:09] epoch: 4150/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:00:09] epoch: 4150/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:00:09] epoch: 4150/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-01:00:14] epoch: 4151/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:00:14] epoch: 4151/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:00:14] epoch: 4151/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:00:20] epoch: 4152/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:00:20] epoch: 4152/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:00:20] epoch: 4152/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:00:25] epoch: 4153/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:00:25] epoch: 4153/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:00:25] epoch: 4153/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:00:30] epoch: 4154/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-01:00:30] epoch: 4154/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:00:30] epoch: 4154/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:00:35] epoch: 4155/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200405-01:00:35] epoch: 4155/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:00:35] epoch: 4155/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:00:41] epoch: 4156/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200405-01:00:41] epoch: 4156/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:00:41] epoch: 4156/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:00:46] epoch: 4157/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200405-01:00:46] epoch: 4157/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:00:46] epoch: 4157/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:00:51] epoch: 4158/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-01:00:51] epoch: 4158/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:00:51] epoch: 4158/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:00:57] epoch: 4159/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200405-01:00:57] epoch: 4159/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:00:57] epoch: 4159/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:01:02] epoch: 4160/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200405-01:01:02] epoch: 4160/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:01:02] epoch: 4160/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:01:07] epoch: 4161/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:01:07] epoch: 4161/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:01:07] epoch: 4161/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:01:12] epoch: 4162/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:01:12] epoch: 4162/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:01:12] epoch: 4162/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-01:01:18] epoch: 4163/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:01:18] epoch: 4163/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:01:18] epoch: 4163/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-01:01:23] epoch: 4164/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:01:23] epoch: 4164/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:01:23] epoch: 4164/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-01:01:28] epoch: 4165/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:01:28] epoch: 4165/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:01:28] epoch: 4165/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-01:01:34] epoch: 4166/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:01:34] epoch: 4166/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:01:34] epoch: 4166/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:01:39] epoch: 4167/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:01:39] epoch: 4167/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:01:39] epoch: 4167/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:01:44] epoch: 4168/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:01:44] epoch: 4168/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:01:44] epoch: 4168/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:01:49] epoch: 4169/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:01:49] epoch: 4169/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:01:49] epoch: 4169/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:01:55] epoch: 4170/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:01:55] epoch: 4170/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:01:55] epoch: 4170/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:02:00] epoch: 4171/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:02:00] epoch: 4171/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:02:00] epoch: 4171/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:02:05] epoch: 4172/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:02:05] epoch: 4172/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:02:05] epoch: 4172/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:02:11] epoch: 4173/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:02:11] epoch: 4173/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:02:11] epoch: 4173/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:02:16] epoch: 4174/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:02:16] epoch: 4174/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:02:16] epoch: 4174/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:02:21] epoch: 4175/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-01:02:21] epoch: 4175/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:02:21] epoch: 4175/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:02:27] epoch: 4176/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:02:27] epoch: 4176/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:02:27] epoch: 4176/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:02:32] epoch: 4177/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200405-01:02:32] epoch: 4177/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:02:32] epoch: 4177/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:02:37] epoch: 4178/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200405-01:02:37] epoch: 4178/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:02:37] epoch: 4178/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:02:42] epoch: 4179/5000, reconstruction loss: 0.0219\n",
      "[LOG TRAIN 20200405-01:02:42] epoch: 4179/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:02:42] epoch: 4179/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:02:48] epoch: 4180/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200405-01:02:48] epoch: 4180/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:02:48] epoch: 4180/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:02:53] epoch: 4181/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200405-01:02:53] epoch: 4181/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:02:53] epoch: 4181/5000, generator loss: 0.6950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:02:58] epoch: 4182/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200405-01:02:58] epoch: 4182/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:02:58] epoch: 4182/5000, generator loss: 0.6958\n",
      "[LOG TRAIN 20200405-01:03:04] epoch: 4183/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-01:03:04] epoch: 4183/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:03:04] epoch: 4183/5000, generator loss: 0.6961\n",
      "[LOG TRAIN 20200405-01:03:09] epoch: 4184/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:03:09] epoch: 4184/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:03:09] epoch: 4184/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-01:03:14] epoch: 4185/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:03:14] epoch: 4185/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:03:14] epoch: 4185/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-01:03:20] epoch: 4186/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:03:20] epoch: 4186/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:03:20] epoch: 4186/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200405-01:03:25] epoch: 4187/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:03:25] epoch: 4187/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:03:25] epoch: 4187/5000, generator loss: 0.6962\n",
      "[LOG TRAIN 20200405-01:03:30] epoch: 4188/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-01:03:30] epoch: 4188/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:03:30] epoch: 4188/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200405-01:03:36] epoch: 4189/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:03:36] epoch: 4189/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:03:36] epoch: 4189/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-01:03:41] epoch: 4190/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:03:41] epoch: 4190/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:03:41] epoch: 4190/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:03:46] epoch: 4191/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:03:46] epoch: 4191/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:03:46] epoch: 4191/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:03:51] epoch: 4192/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:03:51] epoch: 4192/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:03:51] epoch: 4192/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:03:57] epoch: 4193/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:03:57] epoch: 4193/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:03:57] epoch: 4193/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:04:02] epoch: 4194/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:04:02] epoch: 4194/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:04:02] epoch: 4194/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:04:07] epoch: 4195/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:04:07] epoch: 4195/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:04:07] epoch: 4195/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200405-01:04:13] epoch: 4196/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:04:13] epoch: 4196/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:04:13] epoch: 4196/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200405-01:04:18] epoch: 4197/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:04:18] epoch: 4197/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:04:18] epoch: 4197/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:04:23] epoch: 4198/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:04:23] epoch: 4198/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:04:23] epoch: 4198/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:04:29] epoch: 4199/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:04:29] epoch: 4199/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:04:29] epoch: 4199/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:04:34] epoch: 4200/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:04:34] epoch: 4200/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:04:34] epoch: 4200/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:04:39] epoch: 4201/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:04:39] epoch: 4201/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:04:39] epoch: 4201/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:04:45] epoch: 4202/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:04:45] epoch: 4202/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:04:45] epoch: 4202/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:04:50] epoch: 4203/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:04:50] epoch: 4203/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:04:50] epoch: 4203/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:04:55] epoch: 4204/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:04:55] epoch: 4204/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:04:55] epoch: 4204/5000, generator loss: 0.6955\n",
      "[LOG TRAIN 20200405-01:05:01] epoch: 4205/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:05:01] epoch: 4205/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:05:01] epoch: 4205/5000, generator loss: 0.6960\n",
      "[LOG TRAIN 20200405-01:05:06] epoch: 4206/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:05:06] epoch: 4206/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:05:06] epoch: 4206/5000, generator loss: 0.6966\n",
      "[LOG TRAIN 20200405-01:05:11] epoch: 4207/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200405-01:05:11] epoch: 4207/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:05:11] epoch: 4207/5000, generator loss: 0.6975\n",
      "[LOG TRAIN 20200405-01:05:17] epoch: 4208/5000, reconstruction loss: 0.0235\n",
      "[LOG TRAIN 20200405-01:05:17] epoch: 4208/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:05:17] epoch: 4208/5000, generator loss: 0.6987\n",
      "[LOG TRAIN 20200405-01:05:22] epoch: 4209/5000, reconstruction loss: 0.0221\n",
      "[LOG TRAIN 20200405-01:05:22] epoch: 4209/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-01:05:22] epoch: 4209/5000, generator loss: 0.6979\n",
      "[LOG TRAIN 20200405-01:05:27] epoch: 4210/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200405-01:05:27] epoch: 4210/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-01:05:27] epoch: 4210/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-01:05:33] epoch: 4211/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200405-01:05:33] epoch: 4211/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-01:05:33] epoch: 4211/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:05:38] epoch: 4212/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200405-01:05:38] epoch: 4212/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-01:05:38] epoch: 4212/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:05:43] epoch: 4213/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-01:05:43] epoch: 4213/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:05:43] epoch: 4213/5000, generator loss: 0.6957\n",
      "[LOG TRAIN 20200405-01:05:49] epoch: 4214/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:05:49] epoch: 4214/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:05:49] epoch: 4214/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:05:54] epoch: 4215/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:05:54] epoch: 4215/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:05:54] epoch: 4215/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:06:00] epoch: 4216/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:06:00] epoch: 4216/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:06:00] epoch: 4216/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:06:05] epoch: 4217/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-01:06:05] epoch: 4217/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:06:05] epoch: 4217/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:06:10] epoch: 4218/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-01:06:10] epoch: 4218/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:06:10] epoch: 4218/5000, generator loss: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:06:16] epoch: 4219/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:06:16] epoch: 4219/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:06:16] epoch: 4219/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-01:06:21] epoch: 4220/5000, reconstruction loss: 0.0164\n",
      "[LOG TRAIN 20200405-01:06:21] epoch: 4220/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:06:21] epoch: 4220/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200405-01:06:26] epoch: 4221/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:06:26] epoch: 4221/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:06:26] epoch: 4221/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:06:32] epoch: 4222/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:06:32] epoch: 4222/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:06:32] epoch: 4222/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:06:37] epoch: 4223/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:06:37] epoch: 4223/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:06:37] epoch: 4223/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:06:42] epoch: 4224/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:06:42] epoch: 4224/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:06:42] epoch: 4224/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200405-01:06:48] epoch: 4225/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:06:48] epoch: 4225/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:06:48] epoch: 4225/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:06:53] epoch: 4226/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:06:53] epoch: 4226/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:06:53] epoch: 4226/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:06:58] epoch: 4227/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:06:58] epoch: 4227/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:06:58] epoch: 4227/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200405-01:07:03] epoch: 4228/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:07:03] epoch: 4228/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:07:03] epoch: 4228/5000, generator loss: 0.6929\n",
      "[LOG TRAIN 20200405-01:07:09] epoch: 4229/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:07:09] epoch: 4229/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:07:09] epoch: 4229/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200405-01:07:14] epoch: 4230/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:07:14] epoch: 4230/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:07:14] epoch: 4230/5000, generator loss: 0.6930\n",
      "[LOG TRAIN 20200405-01:07:19] epoch: 4231/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200405-01:07:19] epoch: 4231/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:07:19] epoch: 4231/5000, generator loss: 0.6931\n",
      "[LOG TRAIN 20200405-01:07:25] epoch: 4232/5000, reconstruction loss: 0.0203\n",
      "[LOG TRAIN 20200405-01:07:25] epoch: 4232/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:07:25] epoch: 4232/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200405-01:07:30] epoch: 4233/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200405-01:07:30] epoch: 4233/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:07:30] epoch: 4233/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:07:35] epoch: 4234/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200405-01:07:35] epoch: 4234/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-01:07:35] epoch: 4234/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:07:40] epoch: 4235/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200405-01:07:40] epoch: 4235/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:07:40] epoch: 4235/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:07:46] epoch: 4236/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:07:46] epoch: 4236/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:07:46] epoch: 4236/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200405-01:07:51] epoch: 4237/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:07:51] epoch: 4237/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:07:51] epoch: 4237/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-01:07:56] epoch: 4238/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:07:56] epoch: 4238/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:07:56] epoch: 4238/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:08:02] epoch: 4239/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:08:02] epoch: 4239/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:08:02] epoch: 4239/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:08:07] epoch: 4240/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:08:07] epoch: 4240/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:08:07] epoch: 4240/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:08:12] epoch: 4241/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:08:12] epoch: 4241/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:08:12] epoch: 4241/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:08:18] epoch: 4242/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:08:18] epoch: 4242/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:08:18] epoch: 4242/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:08:23] epoch: 4243/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:08:23] epoch: 4243/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:08:23] epoch: 4243/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:08:28] epoch: 4244/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:08:28] epoch: 4244/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:08:28] epoch: 4244/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200405-01:08:34] epoch: 4245/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200405-01:08:34] epoch: 4245/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:08:34] epoch: 4245/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200405-01:08:39] epoch: 4246/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200405-01:08:39] epoch: 4246/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:08:39] epoch: 4246/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:08:44] epoch: 4247/5000, reconstruction loss: 0.0216\n",
      "[LOG TRAIN 20200405-01:08:44] epoch: 4247/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:08:44] epoch: 4247/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200405-01:08:50] epoch: 4248/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200405-01:08:50] epoch: 4248/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:08:50] epoch: 4248/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200405-01:08:55] epoch: 4249/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200405-01:08:55] epoch: 4249/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:08:55] epoch: 4249/5000, generator loss: 0.6928\n",
      "[LOG TRAIN 20200405-01:09:01] epoch: 4250/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:09:01] epoch: 4250/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:09:01] epoch: 4250/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200405-01:09:06] epoch: 4251/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:09:06] epoch: 4251/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:09:06] epoch: 4251/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200405-01:09:11] epoch: 4252/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:09:11] epoch: 4252/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:09:11] epoch: 4252/5000, generator loss: 0.6932\n",
      "[LOG TRAIN 20200405-01:09:17] epoch: 4253/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:09:17] epoch: 4253/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:09:17] epoch: 4253/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200405-01:09:22] epoch: 4254/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:09:22] epoch: 4254/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:09:22] epoch: 4254/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:09:27] epoch: 4255/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:09:27] epoch: 4255/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:09:27] epoch: 4255/5000, generator loss: 0.6938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:09:33] epoch: 4256/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:09:33] epoch: 4256/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:09:33] epoch: 4256/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-01:09:38] epoch: 4257/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:09:38] epoch: 4257/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:09:38] epoch: 4257/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:09:43] epoch: 4258/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:09:43] epoch: 4258/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:09:43] epoch: 4258/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:09:48] epoch: 4259/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:09:48] epoch: 4259/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:09:48] epoch: 4259/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:09:54] epoch: 4260/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:09:54] epoch: 4260/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:09:54] epoch: 4260/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-01:09:59] epoch: 4261/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:09:59] epoch: 4261/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:09:59] epoch: 4261/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-01:10:05] epoch: 4262/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:10:05] epoch: 4262/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:10:05] epoch: 4262/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:10:10] epoch: 4263/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:10:10] epoch: 4263/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:10:10] epoch: 4263/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200405-01:10:15] epoch: 4264/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:10:15] epoch: 4264/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:10:15] epoch: 4264/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200405-01:10:20] epoch: 4265/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200405-01:10:20] epoch: 4265/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:10:20] epoch: 4265/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-01:10:26] epoch: 4266/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200405-01:10:26] epoch: 4266/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:10:26] epoch: 4266/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-01:10:31] epoch: 4267/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-01:10:31] epoch: 4267/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:10:31] epoch: 4267/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:10:36] epoch: 4268/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:10:36] epoch: 4268/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:10:36] epoch: 4268/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:10:42] epoch: 4269/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:10:42] epoch: 4269/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:10:42] epoch: 4269/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:10:47] epoch: 4270/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:10:47] epoch: 4270/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:10:47] epoch: 4270/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:10:52] epoch: 4271/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:10:52] epoch: 4271/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:10:52] epoch: 4271/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:10:58] epoch: 4272/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:10:58] epoch: 4272/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:10:58] epoch: 4272/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:11:03] epoch: 4273/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:11:03] epoch: 4273/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:11:03] epoch: 4273/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:11:08] epoch: 4274/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:11:08] epoch: 4274/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:11:08] epoch: 4274/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:11:13] epoch: 4275/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:11:13] epoch: 4275/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:11:13] epoch: 4275/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:11:19] epoch: 4276/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:11:19] epoch: 4276/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:11:19] epoch: 4276/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:11:24] epoch: 4277/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:11:24] epoch: 4277/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:11:24] epoch: 4277/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:11:29] epoch: 4278/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:11:29] epoch: 4278/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:11:29] epoch: 4278/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:11:35] epoch: 4279/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:11:35] epoch: 4279/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:11:35] epoch: 4279/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:11:40] epoch: 4280/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:11:40] epoch: 4280/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:11:40] epoch: 4280/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-01:11:45] epoch: 4281/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:11:45] epoch: 4281/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:11:45] epoch: 4281/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:11:51] epoch: 4282/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:11:51] epoch: 4282/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:11:51] epoch: 4282/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:11:56] epoch: 4283/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:11:56] epoch: 4283/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:11:56] epoch: 4283/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:12:02] epoch: 4284/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200405-01:12:02] epoch: 4284/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:12:02] epoch: 4284/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:12:07] epoch: 4285/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200405-01:12:07] epoch: 4285/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:12:07] epoch: 4285/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:12:12] epoch: 4286/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:12:12] epoch: 4286/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:12:12] epoch: 4286/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-01:12:18] epoch: 4287/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:12:18] epoch: 4287/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:12:18] epoch: 4287/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:12:23] epoch: 4288/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:12:23] epoch: 4288/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:12:23] epoch: 4288/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:12:28] epoch: 4289/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:12:28] epoch: 4289/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:12:28] epoch: 4289/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:12:34] epoch: 4290/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:12:34] epoch: 4290/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:12:34] epoch: 4290/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:12:39] epoch: 4291/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200405-01:12:39] epoch: 4291/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:12:39] epoch: 4291/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:12:44] epoch: 4292/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200405-01:12:44] epoch: 4292/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:12:44] epoch: 4292/5000, generator loss: 0.6947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:12:49] epoch: 4293/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200405-01:12:49] epoch: 4293/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:12:49] epoch: 4293/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:12:55] epoch: 4294/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200405-01:12:55] epoch: 4294/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:12:55] epoch: 4294/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:13:00] epoch: 4295/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200405-01:13:00] epoch: 4295/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:13:00] epoch: 4295/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:13:05] epoch: 4296/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200405-01:13:05] epoch: 4296/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:13:05] epoch: 4296/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:13:10] epoch: 4297/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200405-01:13:10] epoch: 4297/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:13:10] epoch: 4297/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:13:16] epoch: 4298/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200405-01:13:16] epoch: 4298/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:13:16] epoch: 4298/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:13:21] epoch: 4299/5000, reconstruction loss: 0.0204\n",
      "[LOG TRAIN 20200405-01:13:21] epoch: 4299/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-01:13:21] epoch: 4299/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:13:26] epoch: 4300/5000, reconstruction loss: 0.0195\n",
      "[LOG TRAIN 20200405-01:13:26] epoch: 4300/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:13:26] epoch: 4300/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:13:32] epoch: 4301/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-01:13:32] epoch: 4301/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:13:32] epoch: 4301/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:13:37] epoch: 4302/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:13:37] epoch: 4302/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:13:37] epoch: 4302/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:13:42] epoch: 4303/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:13:42] epoch: 4303/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:13:42] epoch: 4303/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:13:48] epoch: 4304/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:13:48] epoch: 4304/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:13:48] epoch: 4304/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:13:53] epoch: 4305/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:13:53] epoch: 4305/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:13:53] epoch: 4305/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:13:58] epoch: 4306/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:13:58] epoch: 4306/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:13:58] epoch: 4306/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:14:03] epoch: 4307/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:14:03] epoch: 4307/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:14:03] epoch: 4307/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:14:09] epoch: 4308/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:14:09] epoch: 4308/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:14:09] epoch: 4308/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:14:14] epoch: 4309/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:14:14] epoch: 4309/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:14:14] epoch: 4309/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:14:19] epoch: 4310/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:14:19] epoch: 4310/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:14:19] epoch: 4310/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:14:25] epoch: 4311/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:14:25] epoch: 4311/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:14:25] epoch: 4311/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:14:30] epoch: 4312/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200405-01:14:30] epoch: 4312/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:14:30] epoch: 4312/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:14:35] epoch: 4313/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200405-01:14:35] epoch: 4313/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:14:35] epoch: 4313/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:14:41] epoch: 4314/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-01:14:41] epoch: 4314/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:14:41] epoch: 4314/5000, generator loss: 0.6933\n",
      "[LOG TRAIN 20200405-01:14:46] epoch: 4315/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:14:46] epoch: 4315/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:14:46] epoch: 4315/5000, generator loss: 0.6936\n",
      "[LOG TRAIN 20200405-01:14:51] epoch: 4316/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:14:51] epoch: 4316/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:14:51] epoch: 4316/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:14:57] epoch: 4317/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:14:57] epoch: 4317/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:14:57] epoch: 4317/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:15:02] epoch: 4318/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:15:02] epoch: 4318/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:15:02] epoch: 4318/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:15:08] epoch: 4319/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:15:08] epoch: 4319/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:15:08] epoch: 4319/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:15:13] epoch: 4320/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:15:13] epoch: 4320/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:15:13] epoch: 4320/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:15:18] epoch: 4321/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:15:18] epoch: 4321/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:15:18] epoch: 4321/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:15:24] epoch: 4322/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:15:24] epoch: 4322/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:15:24] epoch: 4322/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:15:29] epoch: 4323/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:15:29] epoch: 4323/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:15:29] epoch: 4323/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:15:34] epoch: 4324/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:15:34] epoch: 4324/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:15:34] epoch: 4324/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:15:39] epoch: 4325/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:15:39] epoch: 4325/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:15:39] epoch: 4325/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:15:45] epoch: 4326/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200405-01:15:45] epoch: 4326/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:15:45] epoch: 4326/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:15:50] epoch: 4327/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200405-01:15:50] epoch: 4327/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:15:50] epoch: 4327/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:15:55] epoch: 4328/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:15:55] epoch: 4328/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:15:55] epoch: 4328/5000, generator loss: 0.6935\n",
      "[LOG TRAIN 20200405-01:16:01] epoch: 4329/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:16:01] epoch: 4329/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:16:01] epoch: 4329/5000, generator loss: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:16:06] epoch: 4330/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:16:06] epoch: 4330/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:16:06] epoch: 4330/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:16:11] epoch: 4331/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:16:11] epoch: 4331/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:16:11] epoch: 4331/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:16:17] epoch: 4332/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:16:17] epoch: 4332/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:16:17] epoch: 4332/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:16:22] epoch: 4333/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:16:22] epoch: 4333/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:16:22] epoch: 4333/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:16:27] epoch: 4334/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:16:27] epoch: 4334/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:16:27] epoch: 4334/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:16:33] epoch: 4335/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:16:33] epoch: 4335/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:16:33] epoch: 4335/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:16:38] epoch: 4336/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:16:38] epoch: 4336/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:16:38] epoch: 4336/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:16:43] epoch: 4337/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:16:43] epoch: 4337/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:16:43] epoch: 4337/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:16:49] epoch: 4338/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200405-01:16:49] epoch: 4338/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:16:49] epoch: 4338/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:16:54] epoch: 4339/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200405-01:16:54] epoch: 4339/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:16:54] epoch: 4339/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:16:59] epoch: 4340/5000, reconstruction loss: 0.0216\n",
      "[LOG TRAIN 20200405-01:16:59] epoch: 4340/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:16:59] epoch: 4340/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:17:05] epoch: 4341/5000, reconstruction loss: 0.0222\n",
      "[LOG TRAIN 20200405-01:17:05] epoch: 4341/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:17:05] epoch: 4341/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:17:10] epoch: 4342/5000, reconstruction loss: 0.0197\n",
      "[LOG TRAIN 20200405-01:17:10] epoch: 4342/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:17:10] epoch: 4342/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:17:15] epoch: 4343/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200405-01:17:15] epoch: 4343/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:17:15] epoch: 4343/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:17:21] epoch: 4344/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-01:17:21] epoch: 4344/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:17:21] epoch: 4344/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:17:26] epoch: 4345/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:17:26] epoch: 4345/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:17:26] epoch: 4345/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:17:31] epoch: 4346/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:17:31] epoch: 4346/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:17:31] epoch: 4346/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:17:36] epoch: 4347/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:17:36] epoch: 4347/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:17:36] epoch: 4347/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:17:42] epoch: 4348/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:17:42] epoch: 4348/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:17:42] epoch: 4348/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:17:47] epoch: 4349/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:17:47] epoch: 4349/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:17:47] epoch: 4349/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:17:52] epoch: 4350/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:17:52] epoch: 4350/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:17:52] epoch: 4350/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:17:58] epoch: 4351/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:17:58] epoch: 4351/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:17:58] epoch: 4351/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:18:03] epoch: 4352/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:18:03] epoch: 4352/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:18:03] epoch: 4352/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:18:09] epoch: 4353/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:18:09] epoch: 4353/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:18:09] epoch: 4353/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:18:14] epoch: 4354/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:18:14] epoch: 4354/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:18:14] epoch: 4354/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:18:19] epoch: 4355/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:18:19] epoch: 4355/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:18:19] epoch: 4355/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:18:24] epoch: 4356/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-01:18:24] epoch: 4356/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:18:24] epoch: 4356/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:18:30] epoch: 4357/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200405-01:18:30] epoch: 4357/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:18:30] epoch: 4357/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:18:35] epoch: 4358/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200405-01:18:35] epoch: 4358/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:18:35] epoch: 4358/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:18:40] epoch: 4359/5000, reconstruction loss: 0.0189\n",
      "[LOG TRAIN 20200405-01:18:40] epoch: 4359/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:18:40] epoch: 4359/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:18:46] epoch: 4360/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200405-01:18:46] epoch: 4360/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:18:46] epoch: 4360/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:18:51] epoch: 4361/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200405-01:18:51] epoch: 4361/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:18:51] epoch: 4361/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:18:56] epoch: 4362/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:18:56] epoch: 4362/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:18:56] epoch: 4362/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:19:02] epoch: 4363/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:19:02] epoch: 4363/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:19:02] epoch: 4363/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:19:07] epoch: 4364/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:19:07] epoch: 4364/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:19:07] epoch: 4364/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:19:12] epoch: 4365/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:19:12] epoch: 4365/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:19:12] epoch: 4365/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:19:17] epoch: 4366/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:19:17] epoch: 4366/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:19:17] epoch: 4366/5000, generator loss: 0.6946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:19:23] epoch: 4367/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:19:23] epoch: 4367/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:19:23] epoch: 4367/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:19:28] epoch: 4368/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:19:28] epoch: 4368/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:19:28] epoch: 4368/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-01:19:33] epoch: 4369/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:19:33] epoch: 4369/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:19:33] epoch: 4369/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:19:39] epoch: 4370/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:19:39] epoch: 4370/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:19:39] epoch: 4370/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:19:44] epoch: 4371/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:19:44] epoch: 4371/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:19:44] epoch: 4371/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:19:49] epoch: 4372/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:19:49] epoch: 4372/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:19:49] epoch: 4372/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:19:55] epoch: 4373/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:19:55] epoch: 4373/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:19:55] epoch: 4373/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:20:00] epoch: 4374/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:20:00] epoch: 4374/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:20:00] epoch: 4374/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:20:05] epoch: 4375/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:20:05] epoch: 4375/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:20:05] epoch: 4375/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:20:11] epoch: 4376/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:20:11] epoch: 4376/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:20:11] epoch: 4376/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:20:16] epoch: 4377/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200405-01:20:16] epoch: 4377/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:20:16] epoch: 4377/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:20:21] epoch: 4378/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200405-01:20:21] epoch: 4378/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:20:21] epoch: 4378/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:20:26] epoch: 4379/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:20:26] epoch: 4379/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:20:26] epoch: 4379/5000, generator loss: 0.6934\n",
      "[LOG TRAIN 20200405-01:20:32] epoch: 4380/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:20:32] epoch: 4380/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:20:32] epoch: 4380/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:20:37] epoch: 4381/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:20:37] epoch: 4381/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:20:37] epoch: 4381/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:20:42] epoch: 4382/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:20:42] epoch: 4382/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:20:42] epoch: 4382/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:20:48] epoch: 4383/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:20:48] epoch: 4383/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:20:48] epoch: 4383/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:20:53] epoch: 4384/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:20:53] epoch: 4384/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:20:53] epoch: 4384/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:20:59] epoch: 4385/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:20:59] epoch: 4385/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:20:59] epoch: 4385/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:21:04] epoch: 4386/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:21:04] epoch: 4386/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:21:04] epoch: 4386/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:21:09] epoch: 4387/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:21:09] epoch: 4387/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:21:09] epoch: 4387/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:21:15] epoch: 4388/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:21:15] epoch: 4388/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:21:15] epoch: 4388/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:21:20] epoch: 4389/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:21:20] epoch: 4389/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:21:20] epoch: 4389/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:21:25] epoch: 4390/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:21:25] epoch: 4390/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:21:25] epoch: 4390/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:21:31] epoch: 4391/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:21:31] epoch: 4391/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:21:31] epoch: 4391/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:21:36] epoch: 4392/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200405-01:21:36] epoch: 4392/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:21:36] epoch: 4392/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:21:41] epoch: 4393/5000, reconstruction loss: 0.0231\n",
      "[LOG TRAIN 20200405-01:21:41] epoch: 4393/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:21:41] epoch: 4393/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:21:47] epoch: 4394/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-01:21:47] epoch: 4394/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:21:47] epoch: 4394/5000, generator loss: 0.6937\n",
      "[LOG TRAIN 20200405-01:21:52] epoch: 4395/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:21:52] epoch: 4395/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:21:52] epoch: 4395/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:21:57] epoch: 4396/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:21:57] epoch: 4396/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:21:57] epoch: 4396/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:22:02] epoch: 4397/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:22:02] epoch: 4397/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:22:02] epoch: 4397/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:22:08] epoch: 4398/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:22:08] epoch: 4398/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:22:08] epoch: 4398/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:22:13] epoch: 4399/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:22:13] epoch: 4399/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:22:13] epoch: 4399/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:22:18] epoch: 4400/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:22:18] epoch: 4400/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:22:18] epoch: 4400/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-01:22:23] epoch: 4401/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:22:23] epoch: 4401/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:22:23] epoch: 4401/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:22:29] epoch: 4402/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:22:29] epoch: 4402/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:22:29] epoch: 4402/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:22:34] epoch: 4403/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:22:34] epoch: 4403/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:22:34] epoch: 4403/5000, generator loss: 0.6948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:22:40] epoch: 4404/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:22:40] epoch: 4404/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:22:40] epoch: 4404/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:22:45] epoch: 4405/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:22:45] epoch: 4405/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:22:45] epoch: 4405/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:22:50] epoch: 4406/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-01:22:50] epoch: 4406/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:22:50] epoch: 4406/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:22:55] epoch: 4407/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:22:55] epoch: 4407/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:22:55] epoch: 4407/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:23:01] epoch: 4408/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-01:23:01] epoch: 4408/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:23:01] epoch: 4408/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:23:06] epoch: 4409/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200405-01:23:06] epoch: 4409/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:23:06] epoch: 4409/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:23:12] epoch: 4410/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-01:23:12] epoch: 4410/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:23:12] epoch: 4410/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:23:17] epoch: 4411/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:23:17] epoch: 4411/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:23:17] epoch: 4411/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:23:22] epoch: 4412/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:23:22] epoch: 4412/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:23:22] epoch: 4412/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:23:28] epoch: 4413/5000, reconstruction loss: 0.0192\n",
      "[LOG TRAIN 20200405-01:23:28] epoch: 4413/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:23:28] epoch: 4413/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:23:33] epoch: 4414/5000, reconstruction loss: 0.0196\n",
      "[LOG TRAIN 20200405-01:23:33] epoch: 4414/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:23:33] epoch: 4414/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:23:38] epoch: 4415/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-01:23:38] epoch: 4415/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:23:38] epoch: 4415/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:23:43] epoch: 4416/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200405-01:23:43] epoch: 4416/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:23:43] epoch: 4416/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:23:49] epoch: 4417/5000, reconstruction loss: 0.0194\n",
      "[LOG TRAIN 20200405-01:23:49] epoch: 4417/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:23:49] epoch: 4417/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-01:23:54] epoch: 4418/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-01:23:54] epoch: 4418/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:23:54] epoch: 4418/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:24:00] epoch: 4419/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:24:00] epoch: 4419/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:24:00] epoch: 4419/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:24:05] epoch: 4420/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:24:05] epoch: 4420/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:24:05] epoch: 4420/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:24:10] epoch: 4421/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:24:10] epoch: 4421/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:24:10] epoch: 4421/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:24:16] epoch: 4422/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:24:16] epoch: 4422/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:24:16] epoch: 4422/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-01:24:21] epoch: 4423/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:24:21] epoch: 4423/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:24:21] epoch: 4423/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:24:27] epoch: 4424/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:24:27] epoch: 4424/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:24:27] epoch: 4424/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:24:32] epoch: 4425/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:24:32] epoch: 4425/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:24:32] epoch: 4425/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-01:24:37] epoch: 4426/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:24:37] epoch: 4426/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:24:37] epoch: 4426/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:24:42] epoch: 4427/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-01:24:42] epoch: 4427/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:24:42] epoch: 4427/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:24:48] epoch: 4428/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:24:48] epoch: 4428/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:24:48] epoch: 4428/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:24:53] epoch: 4429/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200405-01:24:53] epoch: 4429/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:24:53] epoch: 4429/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:24:58] epoch: 4430/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200405-01:24:58] epoch: 4430/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:24:58] epoch: 4430/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:25:04] epoch: 4431/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-01:25:04] epoch: 4431/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:25:04] epoch: 4431/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:25:09] epoch: 4432/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:25:09] epoch: 4432/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:25:09] epoch: 4432/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:25:14] epoch: 4433/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:25:14] epoch: 4433/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:25:14] epoch: 4433/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:25:20] epoch: 4434/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:25:20] epoch: 4434/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:25:20] epoch: 4434/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:25:25] epoch: 4435/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:25:25] epoch: 4435/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:25:25] epoch: 4435/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:25:30] epoch: 4436/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:25:30] epoch: 4436/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:25:30] epoch: 4436/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:25:35] epoch: 4437/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:25:35] epoch: 4437/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:25:35] epoch: 4437/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:25:41] epoch: 4438/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:25:41] epoch: 4438/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:25:41] epoch: 4438/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:25:46] epoch: 4439/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200405-01:25:46] epoch: 4439/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:25:46] epoch: 4439/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:25:51] epoch: 4440/5000, reconstruction loss: 0.0199\n",
      "[LOG TRAIN 20200405-01:25:51] epoch: 4440/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:25:51] epoch: 4440/5000, generator loss: 0.6947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:25:57] epoch: 4441/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200405-01:25:57] epoch: 4441/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:25:57] epoch: 4441/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:26:02] epoch: 4442/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:26:02] epoch: 4442/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:26:02] epoch: 4442/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:26:07] epoch: 4443/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:26:07] epoch: 4443/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:26:07] epoch: 4443/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:26:13] epoch: 4444/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:26:13] epoch: 4444/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:26:13] epoch: 4444/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:26:18] epoch: 4445/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:26:18] epoch: 4445/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:26:18] epoch: 4445/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:26:23] epoch: 4446/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:26:23] epoch: 4446/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:26:23] epoch: 4446/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:26:29] epoch: 4447/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:26:29] epoch: 4447/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:26:29] epoch: 4447/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:26:34] epoch: 4448/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:26:34] epoch: 4448/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:26:34] epoch: 4448/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:26:39] epoch: 4449/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:26:39] epoch: 4449/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:26:39] epoch: 4449/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:26:45] epoch: 4450/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:26:45] epoch: 4450/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:26:45] epoch: 4450/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:26:50] epoch: 4451/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:26:50] epoch: 4451/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:26:50] epoch: 4451/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:26:55] epoch: 4452/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:26:55] epoch: 4452/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:26:55] epoch: 4452/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:27:01] epoch: 4453/5000, reconstruction loss: 0.0206\n",
      "[LOG TRAIN 20200405-01:27:01] epoch: 4453/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:27:01] epoch: 4453/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:27:06] epoch: 4454/5000, reconstruction loss: 0.0209\n",
      "[LOG TRAIN 20200405-01:27:06] epoch: 4454/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:27:06] epoch: 4454/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:27:12] epoch: 4455/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200405-01:27:12] epoch: 4455/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:27:12] epoch: 4455/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:27:17] epoch: 4456/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200405-01:27:17] epoch: 4456/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:27:17] epoch: 4456/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:27:22] epoch: 4457/5000, reconstruction loss: 0.0227\n",
      "[LOG TRAIN 20200405-01:27:22] epoch: 4457/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-01:27:22] epoch: 4457/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:27:28] epoch: 4458/5000, reconstruction loss: 0.0220\n",
      "[LOG TRAIN 20200405-01:27:28] epoch: 4458/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-01:27:28] epoch: 4458/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:27:33] epoch: 4459/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200405-01:27:33] epoch: 4459/5000, discriminator loss: 1.3827\n",
      "[LOG TRAIN 20200405-01:27:33] epoch: 4459/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:27:38] epoch: 4460/5000, reconstruction loss: 0.0181\n",
      "[LOG TRAIN 20200405-01:27:38] epoch: 4460/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:27:38] epoch: 4460/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:27:44] epoch: 4461/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:27:44] epoch: 4461/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:27:44] epoch: 4461/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:27:49] epoch: 4462/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:27:49] epoch: 4462/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:27:49] epoch: 4462/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:27:54] epoch: 4463/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:27:54] epoch: 4463/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:27:54] epoch: 4463/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-01:28:00] epoch: 4464/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:28:00] epoch: 4464/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:28:00] epoch: 4464/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-01:28:05] epoch: 4465/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:28:05] epoch: 4465/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:28:05] epoch: 4465/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-01:28:10] epoch: 4466/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:28:10] epoch: 4466/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:28:10] epoch: 4466/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:28:16] epoch: 4467/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:28:16] epoch: 4467/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:28:16] epoch: 4467/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:28:21] epoch: 4468/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:28:21] epoch: 4468/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:28:21] epoch: 4468/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:28:26] epoch: 4469/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:28:26] epoch: 4469/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:28:26] epoch: 4469/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:28:32] epoch: 4470/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:28:32] epoch: 4470/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:28:32] epoch: 4470/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:28:37] epoch: 4471/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:28:37] epoch: 4471/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:28:37] epoch: 4471/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:28:42] epoch: 4472/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:28:42] epoch: 4472/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:28:42] epoch: 4472/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:28:48] epoch: 4473/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:28:48] epoch: 4473/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:28:48] epoch: 4473/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:28:53] epoch: 4474/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:28:53] epoch: 4474/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:28:53] epoch: 4474/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:28:58] epoch: 4475/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:28:58] epoch: 4475/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:28:58] epoch: 4475/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:29:04] epoch: 4476/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:29:04] epoch: 4476/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:29:04] epoch: 4476/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:29:09] epoch: 4477/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:29:09] epoch: 4477/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:29:09] epoch: 4477/5000, generator loss: 0.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:29:14] epoch: 4478/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:29:14] epoch: 4478/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:29:14] epoch: 4478/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:29:20] epoch: 4479/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:29:20] epoch: 4479/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:29:20] epoch: 4479/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:29:25] epoch: 4480/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:29:25] epoch: 4480/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:29:25] epoch: 4480/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:29:30] epoch: 4481/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:29:30] epoch: 4481/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:29:30] epoch: 4481/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:29:35] epoch: 4482/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:29:35] epoch: 4482/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:29:35] epoch: 4482/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:29:41] epoch: 4483/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:29:41] epoch: 4483/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:29:41] epoch: 4483/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:29:46] epoch: 4484/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:29:46] epoch: 4484/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:29:46] epoch: 4484/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:29:52] epoch: 4485/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:29:52] epoch: 4485/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:29:52] epoch: 4485/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:29:57] epoch: 4486/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:29:57] epoch: 4486/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:29:57] epoch: 4486/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:30:03] epoch: 4487/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:30:03] epoch: 4487/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:30:03] epoch: 4487/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:30:08] epoch: 4488/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:30:08] epoch: 4488/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:30:08] epoch: 4488/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:30:13] epoch: 4489/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200405-01:30:13] epoch: 4489/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:30:13] epoch: 4489/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:30:19] epoch: 4490/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200405-01:30:19] epoch: 4490/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:30:19] epoch: 4490/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:30:24] epoch: 4491/5000, reconstruction loss: 0.0242\n",
      "[LOG TRAIN 20200405-01:30:24] epoch: 4491/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-01:30:24] epoch: 4491/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:30:29] epoch: 4492/5000, reconstruction loss: 0.0211\n",
      "[LOG TRAIN 20200405-01:30:29] epoch: 4492/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-01:30:29] epoch: 4492/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:30:34] epoch: 4493/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200405-01:30:34] epoch: 4493/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:30:34] epoch: 4493/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:30:40] epoch: 4494/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-01:30:40] epoch: 4494/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:30:40] epoch: 4494/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:30:45] epoch: 4495/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:30:45] epoch: 4495/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:30:45] epoch: 4495/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:30:50] epoch: 4496/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:30:50] epoch: 4496/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:30:50] epoch: 4496/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-01:30:56] epoch: 4497/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:30:56] epoch: 4497/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:30:56] epoch: 4497/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-01:31:01] epoch: 4498/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:31:01] epoch: 4498/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:31:01] epoch: 4498/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:31:06] epoch: 4499/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:31:06] epoch: 4499/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:31:06] epoch: 4499/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-01:31:12] epoch: 4500/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:31:12] epoch: 4500/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:31:12] epoch: 4500/5000, generator loss: 0.6956\n",
      "[LOG TRAIN 20200405-01:31:17] epoch: 4501/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:31:17] epoch: 4501/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:31:17] epoch: 4501/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-01:31:22] epoch: 4502/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:31:22] epoch: 4502/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:31:22] epoch: 4502/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:31:28] epoch: 4503/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:31:28] epoch: 4503/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:31:28] epoch: 4503/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:31:33] epoch: 4504/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:31:33] epoch: 4504/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:31:33] epoch: 4504/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:31:38] epoch: 4505/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:31:38] epoch: 4505/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:31:38] epoch: 4505/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:31:44] epoch: 4506/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:31:44] epoch: 4506/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:31:44] epoch: 4506/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:31:49] epoch: 4507/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:31:49] epoch: 4507/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:31:49] epoch: 4507/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:31:54] epoch: 4508/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:31:54] epoch: 4508/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:31:54] epoch: 4508/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:32:00] epoch: 4509/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:32:00] epoch: 4509/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:32:00] epoch: 4509/5000, generator loss: 0.6939\n",
      "[LOG TRAIN 20200405-01:32:05] epoch: 4510/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:32:05] epoch: 4510/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:32:05] epoch: 4510/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:32:10] epoch: 4511/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-01:32:10] epoch: 4511/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:32:10] epoch: 4511/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:32:15] epoch: 4512/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-01:32:15] epoch: 4512/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:32:15] epoch: 4512/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:32:21] epoch: 4513/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:32:21] epoch: 4513/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:32:21] epoch: 4513/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:32:26] epoch: 4514/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:32:26] epoch: 4514/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:32:26] epoch: 4514/5000, generator loss: 0.6941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:32:31] epoch: 4515/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:32:31] epoch: 4515/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:32:31] epoch: 4515/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:32:37] epoch: 4516/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-01:32:37] epoch: 4516/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:32:37] epoch: 4516/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:32:42] epoch: 4517/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-01:32:42] epoch: 4517/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:32:42] epoch: 4517/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:32:47] epoch: 4518/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-01:32:47] epoch: 4518/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:32:47] epoch: 4518/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:32:53] epoch: 4519/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:32:53] epoch: 4519/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:32:53] epoch: 4519/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:32:58] epoch: 4520/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200405-01:32:58] epoch: 4520/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:32:58] epoch: 4520/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:33:04] epoch: 4521/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200405-01:33:04] epoch: 4521/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:33:04] epoch: 4521/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:33:09] epoch: 4522/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200405-01:33:09] epoch: 4522/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:33:09] epoch: 4522/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:33:14] epoch: 4523/5000, reconstruction loss: 0.0182\n",
      "[LOG TRAIN 20200405-01:33:14] epoch: 4523/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:33:14] epoch: 4523/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:33:20] epoch: 4524/5000, reconstruction loss: 0.0190\n",
      "[LOG TRAIN 20200405-01:33:20] epoch: 4524/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:33:20] epoch: 4524/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:33:25] epoch: 4525/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200405-01:33:25] epoch: 4525/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:33:25] epoch: 4525/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:33:30] epoch: 4526/5000, reconstruction loss: 0.0184\n",
      "[LOG TRAIN 20200405-01:33:30] epoch: 4526/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:33:30] epoch: 4526/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:33:36] epoch: 4527/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200405-01:33:36] epoch: 4527/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:33:36] epoch: 4527/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:33:41] epoch: 4528/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:33:41] epoch: 4528/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:33:41] epoch: 4528/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:33:46] epoch: 4529/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:33:46] epoch: 4529/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:33:46] epoch: 4529/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:33:52] epoch: 4530/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:33:52] epoch: 4530/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:33:52] epoch: 4530/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:33:57] epoch: 4531/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:33:57] epoch: 4531/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:33:57] epoch: 4531/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:34:02] epoch: 4532/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:34:02] epoch: 4532/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:34:02] epoch: 4532/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:34:08] epoch: 4533/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:34:08] epoch: 4533/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:34:08] epoch: 4533/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:34:13] epoch: 4534/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:34:13] epoch: 4534/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:34:13] epoch: 4534/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:34:18] epoch: 4535/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:34:18] epoch: 4535/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:34:18] epoch: 4535/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:34:24] epoch: 4536/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:34:24] epoch: 4536/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:34:24] epoch: 4536/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:34:29] epoch: 4537/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:34:29] epoch: 4537/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:34:29] epoch: 4537/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:34:34] epoch: 4538/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200405-01:34:34] epoch: 4538/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200405-01:34:34] epoch: 4538/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:34:40] epoch: 4539/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200405-01:34:40] epoch: 4539/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:34:40] epoch: 4539/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:34:45] epoch: 4540/5000, reconstruction loss: 0.0179\n",
      "[LOG TRAIN 20200405-01:34:45] epoch: 4540/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:34:45] epoch: 4540/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:34:50] epoch: 4541/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:34:50] epoch: 4541/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:34:50] epoch: 4541/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:34:55] epoch: 4542/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:34:55] epoch: 4542/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:34:55] epoch: 4542/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:35:01] epoch: 4543/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:35:01] epoch: 4543/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:35:01] epoch: 4543/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:35:06] epoch: 4544/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:35:06] epoch: 4544/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:35:06] epoch: 4544/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:35:11] epoch: 4545/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:35:11] epoch: 4545/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:35:11] epoch: 4545/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:35:17] epoch: 4546/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:35:17] epoch: 4546/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:35:17] epoch: 4546/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:35:22] epoch: 4547/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:35:22] epoch: 4547/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:35:22] epoch: 4547/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:35:27] epoch: 4548/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:35:27] epoch: 4548/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:35:27] epoch: 4548/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:35:33] epoch: 4549/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:35:33] epoch: 4549/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:35:33] epoch: 4549/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:35:38] epoch: 4550/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:35:38] epoch: 4550/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:35:38] epoch: 4550/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:35:43] epoch: 4551/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200405-01:35:43] epoch: 4551/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:35:43] epoch: 4551/5000, generator loss: 0.6947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:35:48] epoch: 4552/5000, reconstruction loss: 0.0217\n",
      "[LOG TRAIN 20200405-01:35:48] epoch: 4552/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:35:48] epoch: 4552/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:35:54] epoch: 4553/5000, reconstruction loss: 0.0226\n",
      "[LOG TRAIN 20200405-01:35:54] epoch: 4553/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-01:35:54] epoch: 4553/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:36:00] epoch: 4554/5000, reconstruction loss: 0.0208\n",
      "[LOG TRAIN 20200405-01:36:00] epoch: 4554/5000, discriminator loss: 1.3828\n",
      "[LOG TRAIN 20200405-01:36:00] epoch: 4554/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:36:05] epoch: 4555/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200405-01:36:05] epoch: 4555/5000, discriminator loss: 1.3830\n",
      "[LOG TRAIN 20200405-01:36:05] epoch: 4555/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:36:10] epoch: 4556/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200405-01:36:10] epoch: 4556/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:36:10] epoch: 4556/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:36:16] epoch: 4557/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-01:36:16] epoch: 4557/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:36:16] epoch: 4557/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:36:21] epoch: 4558/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:36:21] epoch: 4558/5000, discriminator loss: 1.3832\n",
      "[LOG TRAIN 20200405-01:36:21] epoch: 4558/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:36:26] epoch: 4559/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:36:26] epoch: 4559/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:36:26] epoch: 4559/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:36:31] epoch: 4560/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:36:31] epoch: 4560/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:36:31] epoch: 4560/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:36:37] epoch: 4561/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:36:37] epoch: 4561/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:36:37] epoch: 4561/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-01:36:42] epoch: 4562/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:36:42] epoch: 4562/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:36:42] epoch: 4562/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-01:36:48] epoch: 4563/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:36:48] epoch: 4563/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:36:48] epoch: 4563/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:36:53] epoch: 4564/5000, reconstruction loss: 0.0165\n",
      "[LOG TRAIN 20200405-01:36:53] epoch: 4564/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:36:53] epoch: 4564/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:36:58] epoch: 4565/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:36:58] epoch: 4565/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:36:58] epoch: 4565/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:37:03] epoch: 4566/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:37:03] epoch: 4566/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:37:03] epoch: 4566/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:37:09] epoch: 4567/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:37:09] epoch: 4567/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:37:09] epoch: 4567/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:37:14] epoch: 4568/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:37:14] epoch: 4568/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:37:14] epoch: 4568/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:37:19] epoch: 4569/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:37:19] epoch: 4569/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:37:19] epoch: 4569/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:37:25] epoch: 4570/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:37:25] epoch: 4570/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:37:25] epoch: 4570/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:37:30] epoch: 4571/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-01:37:30] epoch: 4571/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:37:30] epoch: 4571/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:37:35] epoch: 4572/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200405-01:37:35] epoch: 4572/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:37:35] epoch: 4572/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:37:41] epoch: 4573/5000, reconstruction loss: 0.0187\n",
      "[LOG TRAIN 20200405-01:37:41] epoch: 4573/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:37:41] epoch: 4573/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:37:46] epoch: 4574/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-01:37:46] epoch: 4574/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:37:46] epoch: 4574/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:37:51] epoch: 4575/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:37:51] epoch: 4575/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:37:51] epoch: 4575/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:37:57] epoch: 4576/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:37:57] epoch: 4576/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:37:57] epoch: 4576/5000, generator loss: 0.6941\n",
      "[LOG TRAIN 20200405-01:38:02] epoch: 4577/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:38:02] epoch: 4577/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:38:02] epoch: 4577/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:38:07] epoch: 4578/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-01:38:07] epoch: 4578/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:38:07] epoch: 4578/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:38:13] epoch: 4579/5000, reconstruction loss: 0.0177\n",
      "[LOG TRAIN 20200405-01:38:13] epoch: 4579/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:38:13] epoch: 4579/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:38:18] epoch: 4580/5000, reconstruction loss: 0.0185\n",
      "[LOG TRAIN 20200405-01:38:18] epoch: 4580/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:38:18] epoch: 4580/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:38:23] epoch: 4581/5000, reconstruction loss: 0.0178\n",
      "[LOG TRAIN 20200405-01:38:23] epoch: 4581/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:38:23] epoch: 4581/5000, generator loss: 0.6949\n",
      "[LOG TRAIN 20200405-01:38:28] epoch: 4582/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-01:38:28] epoch: 4582/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:38:28] epoch: 4582/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:38:34] epoch: 4583/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-01:38:34] epoch: 4583/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:38:34] epoch: 4583/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:38:39] epoch: 4584/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:38:39] epoch: 4584/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:38:39] epoch: 4584/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:38:44] epoch: 4585/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:38:44] epoch: 4585/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:38:44] epoch: 4585/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:38:50] epoch: 4586/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:38:50] epoch: 4586/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:38:50] epoch: 4586/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:38:55] epoch: 4587/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:38:55] epoch: 4587/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:38:55] epoch: 4587/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:39:01] epoch: 4588/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:39:01] epoch: 4588/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:39:01] epoch: 4588/5000, generator loss: 0.6947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:39:06] epoch: 4589/5000, reconstruction loss: 0.0201\n",
      "[LOG TRAIN 20200405-01:39:06] epoch: 4589/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:39:06] epoch: 4589/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:39:12] epoch: 4590/5000, reconstruction loss: 0.0191\n",
      "[LOG TRAIN 20200405-01:39:12] epoch: 4590/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:39:12] epoch: 4590/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:39:17] epoch: 4591/5000, reconstruction loss: 0.0183\n",
      "[LOG TRAIN 20200405-01:39:17] epoch: 4591/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:39:17] epoch: 4591/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:39:22] epoch: 4592/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:39:22] epoch: 4592/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:39:22] epoch: 4592/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:39:28] epoch: 4593/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:39:28] epoch: 4593/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:39:28] epoch: 4593/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:39:33] epoch: 4594/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:39:33] epoch: 4594/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:39:33] epoch: 4594/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:39:38] epoch: 4595/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:39:38] epoch: 4595/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:39:38] epoch: 4595/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:39:44] epoch: 4596/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:39:44] epoch: 4596/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:39:44] epoch: 4596/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:39:49] epoch: 4597/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:39:49] epoch: 4597/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:39:49] epoch: 4597/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:39:54] epoch: 4598/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:39:54] epoch: 4598/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:39:54] epoch: 4598/5000, generator loss: 0.6946\n",
      "[LOG TRAIN 20200405-01:40:00] epoch: 4599/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:40:00] epoch: 4599/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:40:00] epoch: 4599/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:40:05] epoch: 4600/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:40:05] epoch: 4600/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:40:05] epoch: 4600/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:40:10] epoch: 4601/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:40:10] epoch: 4601/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:40:10] epoch: 4601/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:40:15] epoch: 4602/5000, reconstruction loss: 0.0170\n",
      "[LOG TRAIN 20200405-01:40:15] epoch: 4602/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:40:15] epoch: 4602/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:40:21] epoch: 4603/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:40:21] epoch: 4603/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:40:21] epoch: 4603/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:40:26] epoch: 4604/5000, reconstruction loss: 0.0175\n",
      "[LOG TRAIN 20200405-01:40:26] epoch: 4604/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:40:26] epoch: 4604/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:40:31] epoch: 4605/5000, reconstruction loss: 0.0172\n",
      "[LOG TRAIN 20200405-01:40:31] epoch: 4605/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:40:31] epoch: 4605/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:40:37] epoch: 4606/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:40:37] epoch: 4606/5000, discriminator loss: 1.3837\n",
      "[LOG TRAIN 20200405-01:40:37] epoch: 4606/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:40:42] epoch: 4607/5000, reconstruction loss: 0.0180\n",
      "[LOG TRAIN 20200405-01:40:42] epoch: 4607/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:40:42] epoch: 4607/5000, generator loss: 0.6944\n",
      "[LOG TRAIN 20200405-01:40:47] epoch: 4608/5000, reconstruction loss: 0.0202\n",
      "[LOG TRAIN 20200405-01:40:47] epoch: 4608/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:40:47] epoch: 4608/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:40:53] epoch: 4609/5000, reconstruction loss: 0.0198\n",
      "[LOG TRAIN 20200405-01:40:53] epoch: 4609/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:40:53] epoch: 4609/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:40:58] epoch: 4610/5000, reconstruction loss: 0.0200\n",
      "[LOG TRAIN 20200405-01:40:58] epoch: 4610/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:40:58] epoch: 4610/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:41:03] epoch: 4611/5000, reconstruction loss: 0.0212\n",
      "[LOG TRAIN 20200405-01:41:03] epoch: 4611/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:41:03] epoch: 4611/5000, generator loss: 0.6952\n",
      "[LOG TRAIN 20200405-01:41:08] epoch: 4612/5000, reconstruction loss: 0.0188\n",
      "[LOG TRAIN 20200405-01:41:08] epoch: 4612/5000, discriminator loss: 1.3829\n",
      "[LOG TRAIN 20200405-01:41:08] epoch: 4612/5000, generator loss: 0.6951\n",
      "[LOG TRAIN 20200405-01:41:14] epoch: 4613/5000, reconstruction loss: 0.0176\n",
      "[LOG TRAIN 20200405-01:41:14] epoch: 4613/5000, discriminator loss: 1.3831\n",
      "[LOG TRAIN 20200405-01:41:14] epoch: 4613/5000, generator loss: 0.6947\n",
      "[LOG TRAIN 20200405-01:41:19] epoch: 4614/5000, reconstruction loss: 0.0173\n",
      "[LOG TRAIN 20200405-01:41:19] epoch: 4614/5000, discriminator loss: 1.3833\n",
      "[LOG TRAIN 20200405-01:41:19] epoch: 4614/5000, generator loss: 0.6938\n",
      "[LOG TRAIN 20200405-01:41:24] epoch: 4615/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:41:24] epoch: 4615/5000, discriminator loss: 1.3834\n",
      "[LOG TRAIN 20200405-01:41:24] epoch: 4615/5000, generator loss: 0.6945\n",
      "[LOG TRAIN 20200405-01:41:30] epoch: 4616/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:41:30] epoch: 4616/5000, discriminator loss: 1.3835\n",
      "[LOG TRAIN 20200405-01:41:30] epoch: 4616/5000, generator loss: 0.6953\n",
      "[LOG TRAIN 20200405-01:41:35] epoch: 4617/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:41:35] epoch: 4617/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:41:35] epoch: 4617/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:41:40] epoch: 4618/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:41:40] epoch: 4618/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:41:40] epoch: 4618/5000, generator loss: 0.6942\n",
      "[LOG TRAIN 20200405-01:41:46] epoch: 4619/5000, reconstruction loss: 0.0167\n",
      "[LOG TRAIN 20200405-01:41:46] epoch: 4619/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:41:46] epoch: 4619/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:41:51] epoch: 4620/5000, reconstruction loss: 0.0174\n",
      "[LOG TRAIN 20200405-01:41:51] epoch: 4620/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:41:51] epoch: 4620/5000, generator loss: 0.6954\n",
      "[LOG TRAIN 20200405-01:41:57] epoch: 4621/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:41:57] epoch: 4621/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:41:57] epoch: 4621/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:42:02] epoch: 4622/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:42:02] epoch: 4622/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:42:02] epoch: 4622/5000, generator loss: 0.6943\n",
      "[LOG TRAIN 20200405-01:42:07] epoch: 4623/5000, reconstruction loss: 0.0168\n",
      "[LOG TRAIN 20200405-01:42:07] epoch: 4623/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:42:07] epoch: 4623/5000, generator loss: 0.6948\n",
      "[LOG TRAIN 20200405-01:42:13] epoch: 4624/5000, reconstruction loss: 0.0166\n",
      "[LOG TRAIN 20200405-01:42:13] epoch: 4624/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:42:13] epoch: 4624/5000, generator loss: 0.6950\n",
      "[LOG TRAIN 20200405-01:42:18] epoch: 4625/5000, reconstruction loss: 0.0171\n",
      "[LOG TRAIN 20200405-01:42:18] epoch: 4625/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:42:18] epoch: 4625/5000, generator loss: 0.6945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG TRAIN 20200405-01:42:23] epoch: 4626/5000, reconstruction loss: 0.0169\n",
      "[LOG TRAIN 20200405-01:42:23] epoch: 4626/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:42:23] epoch: 4626/5000, generator loss: 0.6940\n",
      "[LOG TRAIN 20200405-01:42:29] epoch: 4627/5000, reconstruction loss: 0.0186\n",
      "[LOG TRAIN 20200405-01:42:29] epoch: 4627/5000, discriminator loss: 1.3836\n",
      "[LOG TRAIN 20200405-01:42:29] epoch: 4627/5000, generator loss: 0.6944\n"
     ]
    }
   ],
   "source": [
    "# initialize training adversarial autoencoder model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # init mini batch counter\n",
    "    mini_batch_count = 0\n",
    "    \n",
    "    # init epoch training losses\n",
    "    batch_reconstruction_losses = 0.0\n",
    "    batch_vae_losses = 0.0\n",
    "    batch_discriminator_losses = 0.0\n",
    "    batch_generator_losses = 0.0\n",
    "\n",
    "    # determine if GPU training is enabled\n",
    "    if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "\n",
    "        # set all networks / models in GPU mode\n",
    "        encoder_train.cuda()\n",
    "        decoder_train.cuda()\n",
    "        discriminator_train.cuda()\n",
    "\n",
    "    # set networks in training mode (apply dropout when needed)\n",
    "    encoder_train.train()\n",
    "    decoder_train.train()\n",
    "    discriminator_train.train()\n",
    "    \n",
    "    # start timer\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    # iterate over epoch mini batches\n",
    "    for mini_batch_data in dataloader:\n",
    "\n",
    "        # increase mini batch counter\n",
    "        mini_batch_count += 1\n",
    "\n",
    "        # determine if GPU training is enabled\n",
    "        if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "          \n",
    "            # convert mini batch to torch variable\n",
    "            mini_batch_torch = torch.cuda.FloatTensor(mini_batch_data)\n",
    "\n",
    "        else:\n",
    "          \n",
    "             # convert mini batch to torch variable\n",
    "             mini_batch_torch = torch.FloatTensor(mini_batch_data)\n",
    "        \n",
    "        # reset the networks gradients\n",
    "        encoder_train.zero_grad()\n",
    "        decoder_train.zero_grad()\n",
    "        discriminator_train.zero_grad()\n",
    "\n",
    "        # =================== reconstruction phase =====================\n",
    "        \n",
    "        # run autoencoder encoding - decoding\n",
    "        z_sample, mu, logvar = encoder_train(mini_batch_torch)\n",
    "        mini_batch_reconstruction = decoder_train(z_sample)\n",
    "\n",
    "        # split input date to numerical and categorical part\n",
    "        batch_cat = mini_batch_torch[:, :ori_dataset_categ_transformed.shape[1]]\n",
    "        batch_num = mini_batch_torch[:, ori_dataset_categ_transformed.shape[1]:]\n",
    "        \n",
    "        # split reconstruction to numerical and categorical part\n",
    "        rec_batch_cat = mini_batch_reconstruction[:, :ori_dataset_categ_transformed.shape[1]]\n",
    "        rec_batch_num = mini_batch_reconstruction[:, ori_dataset_categ_transformed.shape[1]:]\n",
    "\n",
    "        # backward pass + gradients update\n",
    "        rec_error_cat = reconstruction_criterion_categorical(input=rec_batch_cat, target=batch_cat)  # one-hot attr error\n",
    "        rec_error_num = reconstruction_criterion_numeric(input=rec_batch_num, target=batch_num)  # numeric attr error\n",
    "\n",
    "        # combine both reconstruction errors\n",
    "        # calculate vae loss\n",
    "        reconstruction_loss = rec_error_cat + rec_error_num\n",
    "        \n",
    "        # run backward pass - determine gradients\n",
    "        reconstruction_loss.backward()\n",
    "        \n",
    "        # collect batch reconstruction loss\n",
    "        batch_reconstruction_losses += reconstruction_loss.item()\n",
    "        \n",
    "        # update network parameter - decoder and encoder\n",
    "        decoder_optimizer.step()\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        # =================== regularization phase =====================\n",
    "        # =================== discriminator training ===================\n",
    "\n",
    "        # set discriminator in evaluation mode\n",
    "        discriminator_train.eval()\n",
    "\n",
    "        # generate target latent space data\n",
    "        z_target_batch = z_continous_samples_all[random.sample(range(0, z_continous_samples_all.shape[0]), mini_batch_size),:]\n",
    "\n",
    "        # convert to torch tensor\n",
    "        z_target_batch = torch.FloatTensor(z_target_batch)\n",
    "\n",
    "        if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "            z_target_batch = z_target_batch.cuda()\n",
    "\n",
    "        # determine mini batch sample generated by the encoder -> fake gaussian sample\n",
    "        z_fake_gauss, _, _ = encoder_train(mini_batch_torch)\n",
    "\n",
    "        # determine discriminator classification of both samples\n",
    "        d_real_gauss = discriminator_train(z_target_batch) # real sampled gaussian \n",
    "        d_fake_gauss = discriminator_train(z_fake_gauss) # fake created gaussian\n",
    "\n",
    "        # determine discriminator classification target variables\n",
    "        d_real_gauss_target = torch.FloatTensor(torch.ones(d_real_gauss.shape)) # real -> 1\n",
    "        d_fake_gauss_target = torch.FloatTensor(torch.zeros(d_fake_gauss.shape)) # fake -> 0\n",
    "\n",
    "        # determine if GPU training is enabled\n",
    "        if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "\n",
    "            # push tensors to CUDA\n",
    "            d_real_gauss_target = d_real_gauss_target.cuda()\n",
    "            d_fake_gauss_target = d_fake_gauss_target.cuda()\n",
    "\n",
    "        # determine individual discrimination losses\n",
    "        discriminator_loss_real = discriminator_criterion(target=d_real_gauss_target, input=d_real_gauss) # real loss\n",
    "        discriminator_loss_fake = discriminator_criterion(target=d_fake_gauss_target, input=d_fake_gauss) # fake loss\n",
    "        \n",
    "        # add real loss and fake loss\n",
    "        discriminator_loss = discriminator_loss_fake + discriminator_loss_real\n",
    "\n",
    "        # run backward through the discriminator network\n",
    "        discriminator_loss.backward()\n",
    "        \n",
    "        # collect discriminator loss\n",
    "        batch_discriminator_losses += discriminator_loss.item()\n",
    "\n",
    "        # update network the discriminator network parameters\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        # reset the networks gradients\n",
    "        encoder_train.zero_grad()\n",
    "        decoder_train.zero_grad()\n",
    "        discriminator_train.zero_grad()\n",
    "\n",
    "        # =================== regularization phase =====================\n",
    "        # =================== generator training =======================\n",
    "\n",
    "        # set encoder / generator in training mode\n",
    "        encoder_train.train()\n",
    "        \n",
    "        # reset the encoder / generator networks gradients\n",
    "        encoder_train.zero_grad()\n",
    "\n",
    "        # determine fake gaussian sample generated by the encoder / generator\n",
    "        z_fake_gauss, _, _ = encoder_train(mini_batch_torch)\n",
    "\n",
    "        # determine discriminator classification of fake gaussian sample\n",
    "        d_fake_gauss = discriminator_train(z_fake_gauss)\n",
    "\n",
    "        # determine discriminator classification target variables\n",
    "        d_fake_gauss_target = torch.FloatTensor(torch.ones(d_fake_gauss.shape)) # fake -> 1\n",
    "\n",
    "        # determine if GPU training is enabled\n",
    "        if (torch.backends.cudnn.version() != None) and (USE_CUDA == True):\n",
    "\n",
    "            # push tensors to CUDA\n",
    "            d_fake_gauss_target = d_fake_gauss_target.cuda()\n",
    "\n",
    "        # determine discrimination loss of fake gaussian sample\n",
    "        generator_loss = discriminator_criterion(target=d_fake_gauss_target, input=d_fake_gauss)\n",
    "        \n",
    "        # collect generator loss\n",
    "        batch_generator_losses += generator_loss.item()\n",
    "\n",
    "        # run backward pass - determine gradients\n",
    "        generator_loss.backward()\n",
    "\n",
    "        # update network paramaters - encoder / generatorc\n",
    "        encoder_optimizer.step()\n",
    "\n",
    "        # reset the networks gradients\n",
    "        encoder_train.zero_grad()\n",
    "        decoder_train.zero_grad()\n",
    "        discriminator_train.zero_grad()\n",
    "\n",
    "    # collect epoch training losses - reconstruction loss\n",
    "    epoch_reconstruction_loss = batch_reconstruction_losses / mini_batch_count\n",
    "    epoch_reconstruction_losses.extend([epoch_reconstruction_loss])\n",
    "    \n",
    "    # collect epoch training losses - discriminator loss\n",
    "    epoch_discriminator_loss = batch_discriminator_losses / mini_batch_count\n",
    "    epoch_discriminator_losses.extend([epoch_discriminator_loss])\n",
    "    \n",
    "    # collect epoch training losses - generator loss\n",
    "    epoch_generator_loss = batch_generator_losses / mini_batch_count\n",
    "    epoch_generator_losses.extend([epoch_generator_loss])\n",
    "    \n",
    "    # print epoch reconstruction loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG TRAIN {}] epoch: {:04}/{:04}, reconstruction loss: {:.4f}'.format(now, epoch + 1, num_epochs, epoch_reconstruction_loss))\n",
    "    print('[LOG TRAIN {}] epoch: {:04}/{:04}, discriminator loss: {:.4f}'.format(now, epoch + 1, num_epochs, epoch_discriminator_loss))\n",
    "    print('[LOG TRAIN {}] epoch: {:04}/{:04}, generator loss: {:.4f}'.format(now, epoch + 1, num_epochs, epoch_generator_loss))\n",
    "    \n",
    "    # =================== save model snapshots to disk ============================\n",
    "    \n",
    "    # save trained encoder model file to disk\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H_%M_%S\")\n",
    "    encoder_model_name = \"{}_ep_{}_encoder_model.pth\".format(now, (epoch+1))\n",
    "    torch.save(encoder_train.state_dict(), os.path.join(\"./models\", encoder_model_name))\n",
    "\n",
    "    # save trained decoder model file to disk\n",
    "    decoder_model_name = \"{}_ep_{}_decoder_model.pth\".format(now, (epoch+1))\n",
    "    torch.save(decoder_train.state_dict(), os.path.join(\"./models\", decoder_model_name))\n",
    "    \n",
    "    # save trained discriminator model file to disk\n",
    "    decoder_model_name = \"{}_ep_{}_discriminator_model.pth\".format(now, (epoch+1))\n",
    "    torch.save(discriminator_train.state_dict(), os.path.join(\"./models\", decoder_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # =================== evaluate model performance =============================\n",
    "    \n",
    "    # set networks in evaluation mode (don't apply dropout)\n",
    "    encoder_train.cpu().eval()\n",
    "    decoder_train.cpu().eval()\n",
    "\n",
    "    # reconstruct encoded transactional data\n",
    "    reconstruction = decoder_train(encoder_train(data))\n",
    "    \n",
    "    # determine reconstruction loss - all transactions\n",
    "    reconstruction_loss_all = loss_function(reconstruction, data)\n",
    "            \n",
    "    # collect reconstruction loss\n",
    "    losses.extend([reconstruction_loss_all.item()])\n",
    "    \n",
    "    # print reconstuction loss results\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] training status, epoch: [{:04}/{:04}], loss: {:.10f}'.format(now, (epoch+1), num_epochs, reconstruction_loss_all.item()))\n",
    "\n",
    "    # =================== save model snapshot to disk ============================\n",
    "    \n",
    "    # save trained encoder model file to disk\n",
    "    encoder_model_name = \"ep_{}_encoder_model.pth\".format((epoch+1))\n",
    "    torch.save(encoder_train.state_dict(), os.path.join(\"./models\", encoder_model_name))\n",
    "\n",
    "    # save trained decoder model file to disk\n",
    "    decoder_model_name = \"ep_{}_decoder_model.pth\".format((epoch+1))\n",
    "    torch.save(decoder_train.state_dict(), os.path.join(\"./models\", decoder_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'reconstruction loss')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAESCAYAAAD9gqKNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU1fnH8U8SlhC2EAir7MvDjgrKrqK4ohUXXFuXVm1dahV3f/qr+nOrC1Zbt9patWrV1iKoiEvVKghaEBEIPCyyhX0xbCHbZH5/3ImESJIBMpks3/frxSszc++Z+9xDMs/cc849JyEcDiMiIpIY7wBERKRqUEIQERFACUFERCKUEEREBFBCEBGRCCUEEREBoE68A5CaxczqAiuBb939pP3YFgbmA6ESbznW3VeU2PcyoJ67P7WfsU0BbnT3jDL2uQdY6u4v7c97x5KZXQLcAyx09xPjHI7UYEoIUtHOAL4FBppZL3dfGOU2gFHuvjmKY4wgSB77xd1PiWKf/93f960EFwG3u/vL8Q5EajYlBKloVwGvAUuB64BfRrktKmZ2BvAT4Hgz2w2kA0OBNgTJ5gbgWaAV0JrgiuQcd99oZiuAs4FGwH3Ad0BfoD5wtbt/YmYvAPPd/REzywEeBI4H2gKPu/vvzSwJeDgSxzbgS6C3ux9TItZLgPMJmmbbAWuAi919rZk1BR4H+gF1gX8DN7l7gZnlApOAAcBa4Aigs5mlA88DTwKHAmHgPYJkUbLchcA04DHgVKAJcBMwLnLMtcBp7r7LzH4e+b+oB6QBD7r705H4zwAKge5AHnCRu883s9bAM0DPyPZn3P2Jss6r/P9diTf1IUiFMbPewBDgDeBF4Gdm1ry8bcV8YmbfFPs3seQx3H0iMBl4zN2fjLzcETjc3X8KnAfMcPehQBcgG/jZPsIdDDzq7ocBfwHu2sc+9YHN7j6cIJE8aGbJwGXAQIJkMhToWka1DCdINr2B2cATkdcfA2a7+0DgMKAFMD6yrR7wtrubu48CZhF8qD4WKb+F4AN3EMGH/437KDcrEv86d+8HPAX8mSAR9waaAqebWSPgcuCUSF2cCzxULP6jgV+7e19gOkFSIfJ+i929Z6QOrjCzbuWcl1RxukKQinQl8K67bwW2mtlygm+e95ezrUi0TUYlzSz6Buruj5vZSDMbT/Ctti/BN/iSVrr7N5HHXwOXlPLek4rtUx9oCJwCvOTuOQBm9ixwbSnlP3D3xZHHzwFFxzwVONLMfhF53qBEuc9Leb+TgeHuHgZyzewZgg/5B0sp92bk5zJgnruvicS8HEhz951mdiowxsy6E1x5NCpWfra7ZxargzMjj0cDNwO4+zaCeibyXmWdl1RhSghSIcysIUFbd06kaQaCZoqrzezJMrY97O75B3n4ncXi+B1wJEHTyicEzRYJ+yizu9jjcCn7/LCfu4fNjMh+BSX2L9kRXlzxppLEYvsmAeOK+lHMLDUSx4/OqYSSV/WJBOdYWrncYo9/VM9mdggwA/gTQRPTPwmSVZHS6qmgeLxm1gXYTPnnJVWYmoykolxI8IHQ1t07uXsngiabRgTfYEvbds4BHKuAvT8EizsR+L27/w3YSND+n3QAxyjLu8BPzay+mdUhuLoo7UPvODNrF3n8K+DtyOP3gevNLMHM6hM0g10TxbHfJ0ikReWuAD48wPOAoNlpE3Cvu79PJBlE+knK8hFwaWTfpgR9Bd058POSKkAJQSrKlcAEd//h27K7ZxG0eY8tY9t1xd6jZB/CN2a2r5FB7wHXmtlt+9h2D/CImc0G/kXwrbfbwZ5cCS8QNEPNAb4g6GzNLmXfTOBvZrYQ6MSe872WoPlpHkFn+Dz2brsvzbVAy8j+8wAn6CA/UB9EYnQzmwN0IEgQ5dXZNUAvM/uWoG/hAXefzYGfl1QBCZr+WmT/mNkJQMuiYaBm9jiQ4+63lNjvEuBsdz/1x+8iUvWoD0Fk/y0AbjKzmwj+huYSXCGJVGu6QhAREUB9CCIiEhGTJiMzSyS4cWUAwbC3y9x96T72eReY5O7PmFkD4GWCDrMdBHd0bopFfCIi8mOx6kMYCyS7+1AzGwI8CpxeYp97gWbFnl9JcOPMXWZ2HnAH8JuyDlJYWBgOhap3k1dSUgLV/Rwqiupib6qPvak+9jiYuqhbN2kzwZQvPxKrhDACmArg7jPNbFDxjWZ2NsH8J1NLlCkanvYecGd5BwmFwmRllTbar3pITU2p9udQUVQXe1N97E31scfB1EV6euOVpW2LVUJoQjDpV5GQmdWJTMDVF7iAYG6Y/y2lzA6CuVbKlJSUQGpqSgWFHB9JSYnV/hwqiupib6qPvak+9ohVXcQqIWwHGhd7nlhstsOLCGZ+/JjgRp28yHQGxcs0BrLKO4iuEGoW1cXeVB97U33scZBXCKVui1VCmA6cBrwR6UOYV7TB3W8uemxmdwHr3X2qmfUhmDTsK4IJvEqb3EtERGIgVglhIsF89V8QTIZ1aWT2yaXuPrmUMk8DL5rZNIKpAC6IUWwiIrIP1frGtPz8ULi6X0LqMngP1cXeVB97U33scZBNRrMJJjX8Ed2YJiIigBKCiIhEaHI7EZEqLhwOs2VXHsu3ZrNi6256tmtKv/SGFX4cJQQRkSqiIFRI5rYcVm7NZvmWbFZ8v5uVW7NZsTWbnbl7FuYb3bMlD4zpWeHHV0IQEalku/IKWLl1NysiH/bLt2SzcutuVmftpqBwz0Cf9Eb16JSWwsm9WtEprQGd0lLolJZC90NS2bZtdxlHODBKCCIiMRAOh9m8Ky/ygb/nm/6Krdls3Jn3w35JiQm0T02mU1oKR3drHvnQb0DHtBQa1d/3R3RCQmlLgB8cJQQRkYNQ1MyzYsueD/wVkW//u/L2NPM0rJdEp7QUjuiQSse0FDpHvu0fkppMnaSqMb5HCUFEJAoFhWEWb9z5QxNP0Yf/6qwcQsWaeVo2qkfHtBTG9G5Fx8i3/c7NU2jRsF7MvtlXFCUEEZEyLN20i3cWbGDqoo1s2RU09RRv5jmmWws6N0+hY1oKHZs1KLWZpzqovpGLiMTIll15vL9oI+8u2MDiTbtISkxgROc0TuiZTo+WjTikadVp5qlISggiIkBuQSGfL9vCuxkbmLF8K6Ew9GrViBtHdeXEni1JTakb7xBjTglBRGqtcDjMt2u3MyVjIx/6JnbkFtCyUT0uHNSeMX1a0qV5xd/8VZUpIYhIrbN2Ww5TMjYwJWMDq7NySK6TyKjuLRjTuxWDOqSSlFi1O39jRQlBRGqFnbkFfLx4M+9mbODrzGBxxkHtm3Lp4A4c26MFDevp41A1ICI1VqgwzH9Xfc+7GRv5ZMlmcgsK6dCsAVcO78TJvVvSpklyvEOsUpQQRKTGWbZ5F1MyNvDewo1s2plH4/p1OLVPK8b0bkXfNo2r/P0A8aKEICI1wvfZeby/aBNTMjawcMNOkhITGNapGTeOasWILs2pV6fmDROtaEoIIlJt5RUUMu27LbybsZHpy7cSKgzTs2Ujxo/qyok900lLqRfvEKsVJQQRqVbC4TAL1u/gnQUb+NA3sT2ngBYN63HB4e04pU8rurWoXUNFK5ISgohUC2uzdvP6l6t4d8EGVn6/m/p1EjmmW3PG9GnFkR2a1dqhohVJCUFEqrQF63fw5OfLmbU6i3AYDj+kKRcd0Z5je7So1vMGVUWqTRGpknbmFvDM9BW8MWctzRvW49pR3RjVpRntmjaId2g1lhKCiFQ5nyzZzCMfL2XTzjzGHdqWK0d04pBWTcjKyo53aDWaEoKIVBnrt+fwyMfL+M+yLXRPb8jvftKbvm2axDusWkMJQUTiLlQY5o1v1vLMtBWEwmGuPaoz5x/erkZOMV2VKSGISFwt2rCD+z9cwsINOxnaqRm3jO6mfoI4UUIQkbjIzgvx7BcreO3rNaQ2qMv9p/ZidI8WmlYijmKSEMwsEXgKGADkApe5+9Ji268GLgHCwCPu/oaZJQCZwJLIbjPc/bZYxCci8fXZsi089O+lbNiRy5n923DNyM40Ttb303iL1f/AWCDZ3Yea2RDgUeB0ADNrAVwJHAYkAxlm9g+gK/C1u58Wo5hEJM427czlkY+X8fGSzXRpnsKfzxvAgHZN4x2WRMSqx2YEMBXA3WcCg4o2uPtm4FB3zwdaAznuHgYGAu3M7BMzm2JmFqPYRKSShQrDvDFnLeP+Oovpy7dy1YhOvPyzw5UMqphYXSE0AbYVex4yszruXgDg7gVmdg1wN/BEZJ91wAPu/g8zGwG8DBxR1kGSkhJITU2p+OgrUVJSYrU/h4qiuthbTamPheu2c+fkBczN3Mbwrs25+yd96Ji2/+dVU+qjIsSqLmKVELYDjYs9TyxKBkXc/Y9m9ifgPTMbBXwJFCWMaWbW1swSIlcP+xQKhav9jSqpqSnV/hwqiupib9W9Pnbnh3jui5W8OjuTJsl1uecU46SeLUlI4IDOq7rXR0U6mLpIT29c6rZYJYTpwGnAG5E+hHlFGyJNQQ8AZwH5BJ3OhcBvgS3AQ2Y2AFhdVjIQkapr+vKtPPTREtZuz+X0fq359cjONG1QN95hSTlilRAmAseb2RdAAnCpmY0Hlrr7ZDObC8wgGGX0nrv/x8y+BV42szEEVwqXxCg2EYmRzbvymPDJMj70TXRKa8Cz5/bn8ENS4x2WRCkhHK6+X8Lz80Ph6n4JqcvgPVQXe6tO9VEYDvPWt+v4w+fLyS0o5OeDO3DREe0rdJWy6lQfsXaQTUazKTbQpzgN/BWRg7J08y4e+HAJ367dzqD2Tbl1dPcD6jSW+FNCEJEDkpMf4vkvV/HSfzNpVC+J357UgzG9W+lO42pMCUFE9tuXK77ngY+WsGZbDmP6tOK6o7qQmqJO4+pOCUFEorY1O4/HPv2OqQs30qFZA54e159BHdRpXFMoIYhIuQrDYd6ev54nPltOdl6Iy4Z04JLBHahfgZ3GEn9KCCJSpuVbsnngw8XMWbOdw9o14bbje9C5uTqNayIlBBHZp4LCMH+duYrnv1xFSr0k7jihO6f1bU2iOo1rLCUEEfmRnbkF3P7OQmas+J4Te6YzflRX0lLqxTssiTElBBHZy6rvd3PDW/NZnZXDbcd358z+beIdklQSJQQR+cGXK7/n9ncWkgA8eXY/BrbXCKLaRAlBRAiHw/zjm3VM+GQpnZqn8OjYPlrXuBZSQhCp5QpChTz88TL+9e06RnZJ4//G9KRhPX001Eb6XxepxbKy87nl7Qy+ztzGxUe258rhnUhK1Cii2koJQaSWWrZ5F+PfWsDmnbncfbJxSu9W8Q5J4kwJQaQW+nzZFu54dxEN6iXx7LkD6NumSbxDkipACUGkFgmHw/ztv5n88fPl9GzViIdP70OrxvXjHZZUEUoIIrVEbkEh93+4mCkZGxndI53fntSD5LpJ8Q5LqhAlBJFaYPOuPG6atID563bwq+Ed+fngDlq3QH5ECUGkhlu0YQc3vLWA7TkF/O4nvTm2e4t4hyRVlBKCSA32kW/irqlOaoO6/Pn8Q7GWjeIdklRhSggiNVBhOMyfZ6zkuRmr6N+2CQ/9pDfNG2pyOimbEoJIDbM7P8Rd7zkfL9nMqX1acdvo7tTTQjYSBSUEkRpk/fYcbnhrAUs37+I3R3fhwoHt1HksUVNCEKkh5q7Zxs2TM8gtKGTCGX0Z3jkt3iFJNaOEIFIDvLNgPfd/uIRWjevzzDkDtMSlHBAlBJFqLFQY5o+fL+flWZkM6pDKA6f2IrVB3XiHJdWUEoJINbUzt4A73l3E9OVbGXdoW8Yf04U6Seo8lgNXbkIws9GR/RKBPwB3uvur5ZRJBJ4CBgC5wGXuvrTY9quBS4Aw8Ii7v2FmDYCXgZbADuBid990ICclUtNlZu1m/MQFrMraza2ju3HWgLbxDklqgGi+TtwHLAGuBYYDv4qizFgg2d2HArcCjxZtMLMWwJXAMOA44FEzS4i8Ns/dRwIvAXfsx3mI1BqzVmVxyStz2Jqdxx/P6qdkIBUmmoSQDWwACtx9PcG3+vKMAKYCuPtMYFDRBnffDBzq7vlAayDH3cPFywDvAaOjPQmR2uKf36zlmjfnkZZSjxcuPIxBHbTmsVScaPoQthN8UP8p0tSzMYoyTYBtxZ6HzKyOuxcAuHuBmV0D3A08sY8yO4Cm5R0kKSmB1NTqPZoiKSmx2p9DRVFd7K14feSHCrlvyiJe+WoVx/RIZ8K4ATROrl1dgPr92CNWdRHNb9Q5QFd3zzCzPsCfoyizHWhc7HliUTIo4u5/NLM/Ae+Z2agSZRoDWeUdJBQKk5WVHUU4VVdqakq1P4eKorrYW1F9bNudz63vLGTWqix+NugQrh7ZmVBOHlk5efEOsVLp92OPg6mL9PTGpW6LpsnIgKZmNpjg2/yIKMpMB04BMLMhwLwf3izwr0i/QT5Bp3Nh8TLAycDnURxHpEZbviWbS16dw9w12/jtST249uguWvNYYiaaK4RngKLmnf8BHgL+XU6ZicDxZvYFkABcambjgaXuPtnM5gIzCPoj3nP3/5jZf4EXzWwakAdccEBnJFJDfLp4E9e9/g316yTyzDkD6N9Wy1xKbEWTEHKABUA9d59pZqHyCrh7IT8ejbSo2Pa7CRJM8TLZwLgo4hGp8V77eg0TPl1G9xYNeXRsH1o3SY53SFILRJMQwgTDQKeY2TkEzTwiEiPvL9zIo58s4/heLbnz+O400DKXUkmi6UM4F3jR3R8nGGF0XmxDEqm95q3dzj3vO4cd0pTfn3OokoFUqmgSQh4wyszeBU6PcTwitda67TncOGkBLRvX56HTemsNA6l00fzGPQ+sIuhQXgG8EMN4RGqlnbkFXD9xPnmhQh4b25fUFE1QJ5Uvmj6E5u7+h8jjb8zs7FgGJFLbhArD3DllESu2ZPP4Wf3opKmrJU6iuUJoYGatAcysFaBGTZEK9MRn3zHtu63cdFw3BndsFu9wpBaL5grhTuALMyu6k/iK2IYkUnv8a+5aXp29hvMOb6dJ6iTuyk0I7v4h0MXMWkQmphORCvDlyu956N9LGd45jeuO7hLvcERKTwhmVnQncfHXAHD3YbENS6RmW7E1m9veXkin5incO6anpqOQKqGsKwTdbyASA1m78xk/cT51EhOYMLYvjerXrllLpeoq9TfR3VdWZiAitUF+qJBbJmewYUcuT43rT9ummpJCqg7d+SJSScLhMA9+tISvM7dx54nGgHblLvkhUqmUEEQqycuzMpk8fwOXDenASb1axjsckR8pt/HSzI4HxgP1i15z92NjGZRITfPpks384bPlHG/pXDGsY7zDEdmnaHqzHgOuA1bHOBaRGsk37OTOKYvo3box/3tiDxISNKJIqqZoEsIqd/8o5pGI1ECbduYy/q35NG1Ql0fG9iFZs5dKFRZNQthoZs8Ac4jcl+Duf4ppVCI1QE5+iBveWsCO3AL+fN6htGhYL94hiZQpmoSwPPKzdSwDEalJCsNh7prqLNqwk0fG9qFHy0bxDkmkXOWOMoosdzkL2A18E3kuImV49ouV/HvxZn5zdBeO6to83uGIRKXchGBmDwCXEiyUc7GZPRLzqESqsSkZG3h+5ipO79eaCwa2i3c4IlGLpsnoKHcfDmBmjwMzYxuSSPU1d8027v1gMYPaN+WW47ppRJFUK9HcmFbXzIr2S6DEhHciEsjM2s2NkzJo0ySZB0/rTd0k3fcp1Us0VwivA9PNbCYwOPJcRIrZmVvA+LcWUBgOM2FsH5o20BKYUv1Esx7Co2b2PtAT+Iu7z499WCLVR0FhmNvfWciq73fzx7P60TFNS2BK9VTqNa2ZXRb5+QBwAXA4cIGZ3V9JsYlUC7//dBkzVnzPrcd1Y1CH1HiHI3LAyrpCKJqqYlGJ19WHIBLxxpy1vD5nLRcOPISx/dvEOxyRg1LWegjvRx4e4e7XFL1uZi8BL8U6MJGqbuaKrUz4ZCkju6Tx66M6xzsckYNW1hKaVwN3AGlmdmbk5URgQXlvGhmV9BQwAMgFLnP3pcW2X8+eFdmmuPvdZpYAZAJLIq/PcPfb9vN8RCrFd1t2cevbC+nSoiH3jumlJTClRijrCuFJ4Ekzu93d97ffYCyQ7O5DzWwI8ChwOoCZdQEuJBixVAhMM7OJQDbwtbufdgDnIVJpvs/O4/qJC6hfJ5EJY/uQUk8T1knNEM1A6flmdjeAmU01sxOiKDMCmArg7jOBQcW2rQZOcveQu4eBukAOMBBoZ2afmNkUM7P9ORGRypBXUMjNkzPYsiuPR8f2oXUTLYEpNUc09yHcBYyKPD4XeA/4oJwyTYBtxZ6HzKyOuxe4ez6wOdJE9DAwx90Xm1lr4AF3/4eZjQBeBo4o6yBJSQmkplbvIX5JSYnV/hwqSlWvi3A4zC3/msc3a7bz+DkDGNErtvM9VvX6qGyqjz1iVRfRJIR8d98G4O7bzCwURZntQONizxPdvaDoiZklA88DO4CrIi/PAgoix5lmZm3NLCFyFbFPoVCYrKzsKMKpulJTU6r9OVSUql4Xf/1yFRO/Wcsvh3VkWPumMY+1qtdHZVN97HEwdZGe3rjUbdEkhK/M7FVgBnAkwboI5ZkOnAa8EelDmFe0IXJlMAn42N1/V6zMb4EtwENmNgBYXVYyEKlMHy/ZzFPTVnBiz3R+MaRDvMMRiYmEcLj8z1wzGwsYsNDdJ0exf9Eoo/4E8x9dCpwCLAWSgL+z9yR5txHc7/Ay0IjgSuFqdy95D8Re8vND4er+jUHfevaoqnWxcMMOLn9tLj3SG/H0Of2pX6dy5iiqqvURL6qPPQ7yCmE2e/fr/qDcKwQzuyjycB2QamYXuXuZ9yG4eyHwqxIvF/9wL60nbkx58YhUpo07crnhrQWkpdTl4dN7V1oyEImHaJqMekV+JgCHAlvRjWlSC+zODzH+rQVk54X48/mH0lxLYEoNF83kdj/cHBZp/38nphGJVAGF4TD/O2URSzbtZMLYvnRr0TDeIYnEXDRNRsW/FrUBdI++1HhPTVvBp0u3cMOorgzvkhbvcEQqRTRNRk4woV0CwbrKD8c0IpE4e3v+el78ajVnDWjDuYe1jXc4IpUmmoRwp7u/HPNIRKqArzOzuP/DJRzZIZUbR3XVEphSq0QzZOLymEchUgVkZu3m5kkZtGsaLIFZR0tgSi0TzRVCfTObQ9B0VAjg7hfENCqRSla0BGYYmHBGXxonR/OnIVKzRPNbf0vMoxCJo1BhmDveXcSq73fzh7P60qFZg3iHJBIXZa2HkERwV/FvCCa1S4g8fxc4tlKiE6kEf/hsOdOXb+XW0d04okOzeIcjEjdlXSH8HLgdaE3QXJRA0GT0eSXEJVIpJs9fzyuzMznn0LacNUAjiqR2K2uBnOeA58zs5+7+fCXGJFIp5mRu44EPlzC4YyrXj+oa73BE4i6aPoRZZjaU4OrgfuB+d/93bMMSia0123Zz8+QM2jZN5v5Te1FHS2CKRDXs9BmCdZHvAP6HYJpqkWprV14BN7y1gFBhmAlj+9AkuW68QxKpEqJJCDnAAqBeZDnMaBbIEamSikYUrdiSzQOn9aJjmlbgEikSTUIIE8xuOsXMzgHyYxuSSOw8+flypn23lRuO7cbgjhpRJFJcNH0I5xKslPYecAxwXiwDEomVt+ev52+zMjl7QBvGHaoRRSIlRXOFkEuwitnPgPbAqTGNSCQG5q7ZxgMfLeGIDqncoBFFIvsUzRXCJGAtsDryXOscS7WydlsON03KoE2TZB48rZfmKBIpRTQJIdHdfxrzSERioGhEUUFhmEc1okikTNEkhG/NbDDwDZGrA3fPi2lUIhUgWPXMWb5lF4+f2Y9OGlEkUqZoEsLRwGnFnoeBLrEJR6TiPPn5Cj5btoWbju3K4E4aUSRSnmjWVB4AYGYtgS3urvsQpMp7d8EGXvpvsOqZRhSJRKfc3jUzO8bMvgPeB5aZ2fGxD0vkwM1ds437PlzMIK16JrJfohlucS8wwt0PA4ZHnotUSeu253Dz5AxaN67Pg6dqRJHI/ojmryXk7msB3H0NwVQWIlVOdl6IG95aQF6okAlj+9K0gUYUieyPaDqVt5vZr4HPgKOArbENSWT/FYbD/Pa9RSzbvIvHz+xLp+YaUSSyv6K5Qvgp0AG4j+BO5Z/HNCKRA/D0tBV8unQL1x/TlSGd0uIdjki1FE1CaAF87e6nEqyJ0DS2IYnsnykZG3jhq9Wc0b815x6mEUUiByqaJqOXgBsij6cAfwGOK6uAmSUCTwEDCOZCuszdlxbbfj17Jsmb4u53m1kD4GWgJbADuNjdN+3HuUgtNG/tdu77YDED2zfl5mO7aUSRyEGIaghGZB0E3P2zKMuMBZLdfShwK/Bo0QYz6wJcCAwDhgAnmFl/4EpgnruPJEhCd+zHeUgttH57DjdOWkDLxvV58LTeGlEkcpCiuULIMrMrgBkE02DviKLMCGAqBMnEzAYV27YaOKnoBjczq0swcmkE8FBkn/eAO8s7SFJSAqmp1bvzMCkpsdqfQ0XZn7rIzivg5lfmkBcK88rPBtGpZaMYR1f59LuxN9XHHrGqi2gSwsUE39bHAguJrlO5CbCt2POQmdVx9wJ3zwc2m1kC8DAwx90Xm1nxMjuIoq8iFAqTlZUdRThVV2pqSrU/h4oSbV0UhsPcMjkD37CDx87oS4t6iTWyDvW7sTfVxx4HUxfp6Y1L3VbuNba7bwbeAd4CXgR2RnHM7UDxoya6e0HREzNLBl6J7HPVPso0BrKiOI7UQs9OD0YU/eboLgzrrBFFIhUlmqkr7gcuAi4HDgP+GsX7TgdOiZQfAswr9n4JBGsszHX3XxabG+mHMsDJwOdRnoPUIlMXbuT5L1dzer/WnH94u3iHI1KjRNNkNMLdjzKzT9z9RTO7MooyE4HjzewLIAG41MzGA0uBJIIZVOub2cmR/W8DngZeNLNpQB5wwf6ejNRs89dt5//edw4/pCm3HKcRRSIVLZqEUCfSxBM2sySg3NlO3b0Q+FWJlxcVe5xcStFxUcQjtVAwoiiD9Eb1+d1pvamrEUUiFS6ahDABmA2kA19GnotUmt35IW6clEFOfognzw34SCoAABEJSURBVO5HaormKBKJhWgSwhaCIaHdgOWRTmaRSlEYDnPXe86STTuZMLYvXVs0jHdIIjVWNAnhbnc/CvhvrIMRKelPX6zk4yWbue7oLgzvohFFIrEUTUIIm9lEwAnmMsLdb49pVCLAB4s28peZq/hJ31ZcMFAjikRiLZqE8HzMoxApYcG67dzz/mIObdeEW47rrhFFIpUgmjWVX6yMQESKbNyRy42TMmieUpeHftKbenU0okikMugvTaqUnPwQN05aQHZeiEfP6EuzlHrxDkmk1oimyUikUhQWhrl7qrNow04eHduHbhpRJFKpdIUgVcYfP13KR4s38+ujOjOya/N4hyNS6yghSJUwJWMDf/hkGWP6tOKngw6JdzgitZKajCTuJs9bz70fLGZI5zRuH60RRSLxoisEias3567l/z5YzOCOzfjTTwdqRJFIHOmvT+Lm1dmZPPjRUkZ2SeORsX1oUC8p3iGJ1GpqMpK4eOHLVTw5bQXHdm/BvWN6avZSkSpACUEqVTgc5rkZK3luxipO7JnOXSf3pE6i+gxEqgIlBKk04XCYJ6et4MWvVnNqn1bccUIPkpQMRKoMJQSpFOFwmMc+/Y6/f72GM/u34ZbR3UjUaCKRKkUJQWKuMBzmoX8v5c256zjv8HaMP6aLhpaKVEFKCBJTocIw93+4mMnzN3DREe25ZmQnJQORKkoJQWKmoDDMXe8t4v1Fm7h8aAcuH9pRyUCkClNCkJjIDxVyx7uL+HjJZq4a0YlLB3eId0giUg4lBKlweQWF3Pp2Bp9/t5Xrj+nCBQM1N5FIdaCEIBUqJz/ETZMzmLnie24+rhvjDm0b75BEJEpKCFJhdueHGD9xPrNXb+OOE7pzer828Q5JRPaDEoJUiJ25BVw/cT7frt3OXScbp/RuFe+QRGQ/KSHIQduek8+1b85n0cad3DemF6MtPd4hicgBUEKQg5KVnc81b87juy27+N1pvTm6m1Y6E6muYpIQzCwReAoYAOQCl7n70hL7pAPTgf7unmNmCUAmsCSyywx3vy0W8UnF2LIrj6v/+S2ZWTk8cnofhnVOi3dIInIQYnWFMBZIdvehZjYEeBQ4vWijmZ0IPAi0LlamK/C1u58Wo5ikAm3ckctV//iWDTtymTC2D0d2bBbvkETkIMUqIYwApgK4+0wzG1RieyEwGphd7LWBQDsz+wTYDVzv7l7WQZKSEkhNTam4qOMgKSmx2p3D2qzdXPnPeWzZlcfzFw/iiE4Vc2VQHesillQfe1N97BGruohVQmgCbCv2PGRmddy9AMDdPwQws+Jl1gEPuPs/zGwE8DJwRFkHCYXCZGVlV2jglS01NaVanUNm1m6u+se37Mgt4A9n9aN7anKFxV/d6iLWVB97U33scTB1kZ7euNRtsVqmajtQ/KiJRcmgDLOASQDuPg1oG+lXkCpixdZsfvn6XLLzQjw1rj/92jaJd0giUoFilRCmA6cARPoQ5kVR5rfAdZEyA4DV7h6OUXyyn5Zt3sUvX59LfijM0+f0p1er0r9liEj1FKsmo4nA8Wb2BZAAXGpm44Gl7j65lDIPAi+b2RigALgkRrHJfvKNO7nmn/Ook5jAU+f0p3NzteOK1EQxSQjuXgj8qsTLi/axX6dij78HxsQiHjlwC9bv4No359GgbhJPj+tP+2YN4h2SiMSIbkyTUs1ds43f/Gs+TRvU5elx/WnbNDneIYlIDMWqD0Gqudmrs/j1m/No3rAez56jZCBSG+gKQX5k5oqt3Dgpg7ZNknlqXD9aNKof75BEpBLoCkH28vmyLYx/awEdmjXgmXP7KxmI1CJKCPKDj5ds5ubJGXRr0ZCnx/UnLaVevEMSkUpUKxPCB4s2MmPFVsJh3eZQ5INFG7n97Qx6tWrMU+P607RB3XiHJCKVrFb2IUyct55Zq7I4skMq1x7dBWvZKN4hxdU7C9bzf+8vZkC7pjx2Rh8a1quVvxYitV6tvEJ44sy+3DCqK75xJz/729fcPdXZsCM33mFVusys3dwz1bln6mIGtU/liTP7KhmI1GK18q+/blIi5x3ejjG9W/HXL1fx2pw1fOibuHDQIVx0xCE1/kNx3fYc/jJzFe8s2ECdxATOH9iOq0Z0pn6dWvn9QEQiavYnXzkaJ9fh2qO7cPahbXlq2nKen7mKt75dxxXDOnJ6vzbUSaxZc+ut357DC1+tZtK89SQkwNkD2nDxke1J10giEaGWJ4QibZsmc++YXpx/eDse/893PPjRUl77eg3XHtWFEV3SSEio3olh085cXvhyNRPnrSMchtP7tebSwR1o1ViJQET2UEIopk+bJjx77gA+W7aFJz5bzvi3FjCwfVN+c3SXajm75+Zdebz01WrenLuWUBhO69OKnw/pQJsmuutYRH5MCaGEhIQEju7WguGd0/jXt+t5bsZKLnp5Dif3aslVIzrRuhp8mG7NzuOlrzL559y1FIQKOaV3kAgOSdXEdCJSOiWEUtRJSuScw9pySu+WvPDVav4+O5N/L97E+QMP4ZIj29OoftWruqzsfP42K5M35qwhL1TISb1a8oshHemgGUpFJApV71OtimlUvw7XjOzM2QPa8PT0FbwY6ZS9fGgHzuzfhjpJ8R+Zs213Pq/OzuS1r9eyOz/ECT3TuWxoRzqlad0CEYmeEkKUWjdJ5u6Te3JepOP54Y+X8fqctfx6ZGeO7tY8Lh3PO3IK+PvXmbw6ew278kKM7pHO5cM60KV5w0qPRUSqPyWE/dSrVWOeHtefad9t5YnPvuOmyRkc2q4J1x3dhT5tKmeN4Z25Bbw+Zw2vzFrDjtwCRnVvweVDO9A9vXbfcS0iB0cJ4QAkJCQwsmtzhnZOY9K8dfzpi5Vc8uo3nGDpXDWyE+2axqbNPjsvxBtz1vDyrEy25RRwVNfmXDG0I9ZKiUBEDp4SwkGok5jAWQPaclKvlrz030xemZXJJ0s3c+5h7bh0cHuaJFfMBHG780P885u1vPTfTLJ25zO8cxpXDOtI79bVbyisiFRdSggVoGG9Olw5vBNn9m/DM9NX8MqsTN6ev55fDO3I2QPaUPcAO55z8kP869t1vPjVarZm5zOkYzOuGNaRfm0rp2lKRGoXJYQK1KpxfX57kv1wx/OET5bxxpw1XDOyM8d2bxF1x3NuQSFvfbuOF75azeZdeRzRIZWHhnVkQLumMT4DEanNlBBioEfLRvzx7H7MWPE9j//nO259eyH92jThumO60L+Mb/d5BYVMnr+ev365io078zjskKbcO6YnA9unVmL0IlJbKSHESEJCAsM6p3Fkx2a8M389z3yxkl/8/RtG92jB1SM773XXcEGokLcXbOD5matYvyOX/m2bcNfJxqD2qdV+HiURqT6UEGKsTmICY/u34YSeLXl51mr+9t9MPl26hXGHtuXiI9vz0Xdb+cPHS1m7LYe+bRrzPyd0Z3DHZkoEIlLplBAqSUq9JK4Y1okz+rfh2S9W8vqcNbz29RrCQK9Wjbj52L4M66xEICLxo4RQydIb1eeOE3pw3mHtmDR/Pcf0bMXhrRsqEYhI3CkhxEm39IbcMKorqakpZGVlxzscEZHYJAQzSwSeAgYAucBl7r60xD7pwHSgv7vnmFkD4GWgJbADuNjdN8UiPhER+bFYTdU5Fkh296HArcCjxTea2YnAB0DrYi9fCcxz95HAS8AdMYpNRET2IVYJYQQwFcDdZwKDSmwvBEYDW/dVBngvsl1ERCpJrPoQmgDbij0PmVkddy8AcPcPAcystDI7gHJvy01KSiA1tXrP+Z+UlFjtz6GiqC72pvrYm+pjj1jVRawSwnag+MxriUXJIMoyjYGs8g4SCoWrfYesOpX3UF3sTfWxN9XHHgdTF+nppU+KGasmo+nAKQBmNgSYtz9lgJOBz2MTmoiI7EusrhAmAseb2RdAAnCpmY0Hlrr75FLKPA28aGbTgDzgghjFJiIi+xCThODuhcCvSry8aB/7dSr2OBsYF4t4RESkfAnhcDjeMRyMTcDKeAchIlKNdATS97WhuicEERGpILHqVBYRkWpGCUFERAAlBBERiVBCEBERQAlBREQilBBERATQAjlxYWZ1geeBTkB94N4y7uCuNcysJTAbON7df3QjY21hZrcBPwHqAU+5+1/iHFLcRP5WXiT4WwkBl9fW3w0zGwz8zt2PMbNuwAtAGJgPXB25Ifig6AohPn4KbIms/XAS8Mc4xxN3kT/8Z4Hd8Y4lnszsGGAYMBw4Gmgf14Di7xSgjrsPA+4B7otzPHFhZjcDfwaSIy9NAO6IfIYkAKdXxHGUEOLjH8CdkccJQHkzwdYGjwDPAGvjHUicnUgwGeRE4G3gnfiGE3eLgTqRVRibAPlxjidelgFnFns+EPhP5HGFrR+jhBAH7r7T3XeYWWPgn9Ty1eHM7BJgk7u/H+9YqoAWBAtKjSOYD+wVM0uIb0hxtZOguWgR8BzwRFyjiRN3f5O9k2GCuxdNMxHV+jHRUEKIEzNrD3wC/M3dX413PHH2c4LZcT8FDgVeMrPWZRepsbYA77t7nrs7kEMp887UEtcT1EcPgjXaXzSz5HLK1AbF+wuiWj8mGupUjgMza0WwpvQ17v7veMcTb+5+VNHjSFL4lbuvj19EcTUN+I2ZTQDaAA0JkkRt9T17vhlvBeoCSfELp8qYY2bHuPunBOvHfFIRb6qEEB+3A82AO82sqC/hZHev1R2qAu7+jpkdBXxFcAV/tbuH4hxWPD0GPG9mnxOMurrd3XfFOaaq4AbgOTOrBywkaHo+aJrtVEREAPUhiIhIhBKCiIgASggiIhKhhCAiIoASgoiIRCghSI1iZslmdtl+7H+Jmf2kjO23mtmRFRNdxTGzT82sZ7zjkJpF9yFITdMauIxgIrByufsL5Wx/sAJiEqkWdB+C1Chm9hxwLsFkeYkEM4c2An4BXEQwT1BzYK67X2pmdwHrCebKuQXIA7oAr7n7fWb2AvAaQaI5BUgBuhJMQ/xC5OrhSYL5ZDYCOe5+SbF46hJM2tc9Es8d7v6pmWUAnwN9CO7APT9y7L9Gjp8ETHD31yPTHv8+Un4NcCHBhGbrgFYEdzOfH4nh9ch+yQR3fH9TEfUqtYOajKSmuQ/IcPd7Is8XRqZOXgN87+7HEySFIWbWrkTZjsBZwBDg5n28d1N3P5VgrYJbI689A1zi7scSzEhZ0mXA5sj0HKcTJA8IEssr7j6CIBn9MvJvUyTe0cC9ZtaCYFrwn7v7YOBdoFfkPd6NHPc94GzgSIJpLk4GriZIFCJRU5OR1HQe+bkbaGlmfyeYQbMRwbw4xc1z9wKgwMz2NY1I0bft1eyZl76tuy+IPP4cOK9EmX7AyMi3fAimcm4B5Lv7Z5HXviD4EC8APgKIzIabQXA10trdF0Ze/wuAmUGwmBAEVzitCRJDd2ASwfw/95ZWKSL7oisEqWkK2fv3umhWyJOB9u5+PsFcUg0I1qIorrz2031tX21mvSOPh+xj+yLg7+5+TCSGfxCZpM3MBkT2GQ4sIJiTZiRAZGr0fsByYK2ZdY+8fouZnVFKPMcA69z9BIJkcH855yOyFyUEqWk2AvXM7HclXv8K6GJmnxFMBPYd0LYCjncVweRrHxE02ZRcwOVZoKeZ/YfgSmBlsaUObzGzaUC7yH5/AppHXvsUuNvdNxI0JT0feY/DgCmlxDIXuCwyY+zDwAMVcH5Si6hTWeQgmNnVwBvuvsnM7gXyivVflFVuBdDT3XNiHKJI1NSHIHJwNgAfmNlOYBtwcZzjETlgukIQERFAfQgiIhKhhCAiIoASgoiIRCghiIgIoIQgIiIR/w+6bYzKUbId7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the reconstruction loss per training epoch\n",
    "plt.plot(range(1, len(epoch_reconstruction_losses)+1), epoch_reconstruction_losses)\n",
    "\n",
    "# set plot title\n",
    "plt.title('AAE training performance')\n",
    "\n",
    "# set plot axis labels\n",
    "plt.xlabel('training epochs')\n",
    "plt.ylabel('reconstruction loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tnHdNC0nBqkA"
   },
   "source": [
    "Let's now evaluate the magnitude of the distinct losses with progressing training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "wkrpELqHBqkA",
    "outputId": "3b8a71cf-5278-4c0f-95a4-da55b3557bb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'reconstruction loss')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the reconstruction loss per training epoch\n",
    "plt.plot(range(1, len(epoch_reconstruction_losses)+1), epoch_reconstruction_losses)\n",
    "\n",
    "# set plot title\n",
    "plt.title('AAE training performance')\n",
    "\n",
    "# set plot axis labels\n",
    "plt.xlabel('training epochs')\n",
    "plt.ylabel('reconstruction loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "e4g9UCw1BqkB",
    "outputId": "6d595937-549b-47a5-d132-68f43d4e148d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'discrimination loss')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the discriminator loss per training epoch\n",
    "plt.plot(range(0, len(epoch_discriminator_losses)), epoch_discriminator_losses)\n",
    "\n",
    "# set plot title\n",
    "plt.title('AENN training performance')\n",
    "\n",
    "# set plot axis labels\n",
    "plt.xlabel('training epochs')\n",
    "plt.ylabel('discrimination loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "xpbcRem9BqkB",
    "outputId": "7510517d-b132-4048-dd8a-1c6c92d8194b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'generation loss')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the generator loss per training epoch\n",
    "plt.plot(range(0, len(epoch_generator_losses)), epoch_generator_losses)\n",
    "\n",
    "# set plot title\n",
    "plt.title('AENN training performance')\n",
    "\n",
    "# set plot axis labels\n",
    "plt.xlabel('training epochs')\n",
    "plt.ylabel('generation loss')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "KDD_2019_Lab.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
